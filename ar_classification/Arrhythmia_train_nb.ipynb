{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saranpan/ECG-Heartbeat-classifier/blob/main/ar_classification/Arrhythmia_train_nb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hardware will be used on this notebook\n",
        "\n",
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjRblvuYrMl_",
        "outputId": "6389e7e4-e183-4475-9bb9-13a5bc615e2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-43ee859f-bd6b-75da-fd03-e374193a0330)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üåè Business Understanding"
      ],
      "metadata": {
        "id": "3m1HhrJVux7l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The healthcare industry is rapidly growing, with the integration of various technologies to help ease the burden on doctors and improve patient outcomes. One technology that stands out is the electrocardiogram (ECG), which is highly effective in checking the electrical activity and rhythm of the heart. By generating a graph of the heart's electrical activity over time, an ECG can accurately detect arrhythmias (‡∏´‡∏±‡∏ß‡πÉ‡∏à‡πÄ‡∏ï‡πâ‡∏ô‡∏ú‡∏¥‡∏î‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏∞). However, not all doctors can diagnose arrhythmias with high accuracy, and real-time diagnosis is challenging given that heart diseases can happen at any time.\n",
        "\n",
        "Arrhythmia is a medical condition characterized by an irregular heartbeat, which can lead to the heart beating too fast, too slow, or with an irregular rhythm. This can result in insufficient blood pumping to the body and cause symptoms such as dizziness, fainting, or related issues. Real-time detection of arrhythmia can significantly improve patient outcomes, but this requires automation with intelligent doctors.\n",
        "\n",
        "To address this issue, our goal is to launch a product for the healthcare industry that uses AI to solve the problem. We will utilize ECG signals to predict the type of arrhythmia and classify irregular heartbeats accurately to determine the appropriate treatment for the patient.\n"
      ],
      "metadata": {
        "id": "JfheQVPqvB38"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üì∞ Data Understanding"
      ],
      "metadata": {
        "id": "lin9u_4HIN5l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "</fieldset>\n",
        "\n",
        "The main objective of this project is to develop a machine learning approach that can detect and diagnose Arrhythmia at an early stage, using ECG heartbeat signals as input. To achieve this, we aim to train the AI to classify the type of Arrhythmia, limiting our scope to five categories:\n",
        "\n",
        "| Key | Category | Annotations |\n",
        "| --- | --- | --- |\n",
        "| 0 | N | Normal |\n",
        "| 1 | S | Supra-ventricular premature |\n",
        "| 2 | V | Ventricular escape |\n",
        "| 3 | F | Fusion of ventricular and normal |\n",
        "| 4| Q | Unclassifiable |\n",
        "\n",
        "\n",
        "The inclusion of the \"Unclassifiable\" category is to allow for further diagnosis of patients whose Arrhythmia type is not immediately recognized.\n",
        "\n",
        "To evaluate the performance of the machine learning model, we will use its ability to accurately classify Arrhythmia types. We will use the weighted F1 score as the criterion for selecting the best model. For training the model, we will use a labeled dataset of ECG heartbeat signals and corresponding Arrhythmia classifications. Once trained, the model will be able to predict the type of Arrhythmia for new ECG heartbeat signals, thus aiding in the early detection and diagnosis of Arrhythmia.\n",
        "\n",
        "In summary, the goal of this project is to accurately classify the type of Arrhythmia by mapping a sequence of ECG heartbeat signals into one of five different categories. The table above shows the categories we will use to classify Arrhythmia, with the performance of the machine learning model being evaluated using the weighted F1 score.\n",
        "\n",
        "\n",
        "</fieldset>"
      ],
      "metadata": {
        "id": "5WZnOX-NIP3W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To develop a machine learning model for ECG analysis, and satisfy the data needed condition which discussed on Data Understanding section, we needed to collect a dataset with ECG heartbeat signals as predictors and mult-labels indicating the various of heart arrhythmia as the target. One such dataset we found on [Kaggle](https://www.kaggle.com/datasets/shayanfazeli/heartbeat) was scraped from a [research paper](https://arxiv.org/abs/1805.00794) , which in turn was scraped from the [MIT-BIH Arrhythmia Database](https://www.physionet.org/content/mitdb/1.0.0/). However, the dataset was downsampled, resulting in a reduced number of rows. It is important to note that the trained model cannot be applied universally as it has limitations arising from the dataset used to train it. Therefore, it is worth reviewing some metadata of the MIT-BIH Arrhythmia Database, which we used to train the model.\n",
        "\n",
        "The summary of the limitations of this dataset are as follows:\n",
        "\n",
        "The limitations of the MIT-BIH Arrhythmia Database include:\n",
        "\n",
        "> Limited Sample Size: The database contains only 48 half-hour excerpts of ECG recordings from 47 subjects, which might not be enough to represent the full diversity of arrhythmias in a larger population.\n",
        "\n",
        "> Outdated Data: The ECG recordings were obtained between 1975 and 1979. Advances in recording technology, treatment, and demographic changes since then may affect the applicability of the dataset to current clinical practice.\n",
        "\n",
        "> Lack of demographic information: The dataset does not provide detailed demographic information about the subjects, such as age, gender, ethnicity, or medical history, which could be essential for understanding the variations in ECG signals and arrhythmias.\n",
        "\n",
        "> Imbalanced Data: The dataset was selected to include less common but clinically significant arrhythmias, which might result in an imbalanced dataset that could affect the performance of machine learning models.\n",
        "\n",
        "> Digitization Limitations: The recordings were digitized at 360 samples per second per channel with an 11-bit resolution. While this resolution is adequate for most purposes, it may not be sufficient for detecting subtle variations in ECG signals.\n",
        "\n",
        "> Annotation Disagreements: Although two or more cardiologists independently annotated each record, and disagreements were resolved to obtain the reference annotations, the possibility of human error or subjectivity in the annotations cannot be ruled out.\n",
        "\n",
        "Despite these limitations, the MIT-BIH Arrhythmia Database has been widely used in research and has contributed to the development of numerous arrhythmia detection algorithms.\n"
      ],
      "metadata": {
        "id": "CufCg_42woHE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Moreover, the data from the [MIT-BIH Arrhythmia Database](https://www.physionet.org/content/mitdb/1.0.0/) is not exactly the same used for modeling in the [research paper](https://arxiv.org/abs/1805.00794), the author of paper have preprocessed in the following steps\n",
        "\n",
        "1. Splitting the continuous ECG signal to 10s windows and select a 10s window from an ECG signal. \n",
        "\n",
        "2. Normalizing the amplitude values to the range of between zero and one. \n",
        "\n",
        "3. Finding the set of all local maximums based on zerocrossings of the first derivative. \n",
        "\n",
        "4. Finding the set of ECG R-peak candidates by applying a threshold of 0.9 on the normalized value of the local maximums. \n",
        "\n",
        "5. Finding the median of R-R time intervals as the nominal heartbeat period of that window (T). \n",
        "\n",
        "6. For each R-peak, selecting a signal part with the length equal to 1.2T. \n",
        "\n",
        "7. Padding each selected part with zeros to make its length equal to a predefined fixed length.\n",
        "\n",
        "The size of the whole dataset is approximately 100,000 rows, That is an overview of the metadata for this dataset. Moving forward, we will import the dataset and conduct exploratory analysis to gain a more comprehensive understanding of its contents."
      ],
      "metadata": {
        "id": "oAMplj4CU3yr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNkgyvwt5sAR",
        "outputId": "b9a67dfb-4223-4dcd-fd19-b154e60ba77e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "collapsed": true,
        "id": "U4qsj7C55R7q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e92ef15-1eea-427b-b187-6b452339a4a7"
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "import random\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print('setup libraries completed')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "setup libraries completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Arrhythmia Data \n",
        "\n",
        "Via kaggle API"
      ],
      "metadata": {
        "id": "hnjpmqgLjS2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install kora kaggle "
      ],
      "metadata": {
        "id": "99-hp_Vy5i3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kora import kaggle\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def import_kaggle_dataset():\n",
        "    # If failed, download Kaggle API to your drive first\n",
        "    kaggle.download('shayanfazeli/heartbeat')\n",
        "    print('The Kaggle Dataset was downloaded into your directory')\n",
        "\n",
        "def create_arrhythmia_dataset():\n",
        "    train = pd.read_csv('/content/mitbih_train.csv', header=None)\n",
        "    test = pd.read_csv('/content/mitbih_test.csv', header=None)\n",
        "    return train, test\n",
        "\n",
        "def check_null(df):\n",
        "    if df.isnull().values.any():\n",
        "        print(\"The dataset contains null values\")\n",
        "    else:\n",
        "        print(\"The dataset contains NO null values\")\n",
        "\n",
        "def get_proportion_train_test(train,test):\n",
        "    total = len(train) + len(test)\n",
        "\n",
        "    train_prop = len(train) / total \n",
        "    test_prop = len(test) / total \n",
        "\n",
        "    return f'train:test proportion = {train_prop:.2f} : {test_prop:.2f}'"
      ],
      "metadata": {
        "id": "QQh5H7Nf5XqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import_kaggle_dataset()\n",
        "#  <- Check the data files in your directory\n",
        "train, test = create_arrhythmia_dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9F5k34uX57Wo",
        "outputId": "0fd51aa6-199c-45bb-83e9-8a5940592022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading heartbeat.zip to /content\n",
            " 89% 88.0M/98.8M [00:00<00:00, 167MB/s]\n",
            "100% 98.8M/98.8M [00:00<00:00, 150MB/s]\n",
            "The Kaggle Dataset was downloaded into your directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( f' Arrhythmia : {get_proportion_train_test(train,test)}' )"
      ],
      "metadata": {
        "id": "Lcn_zmAHfsJ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaa33348-d32c-4834-ddc6-0d021c06691d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Arrhythmia : train:test proportion = 0.80 : 0.20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check null\n",
        "check_null(train)\n",
        "check_null(test)"
      ],
      "metadata": {
        "id": "zviUvjpTDUdG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9b7322f-2796-4b86-b7c5-255d90040a4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset contains NO null values\n",
            "The dataset contains NO null values\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Originally, Only train and test dataset were already splitted by kaggle, \n",
        "# we need to further split train into train and val where the size is equal to test\n",
        "# goal : train-test : 80-20 into train-val-test : 60-20-20\n",
        "# since 25% of 80% is 20%, hence, we will split the train into train-val by 75:25\n",
        "\n",
        "seed = 42\n",
        "train, val = train_test_split(train, test_size=0.25, random_state=seed, stratify=train[187])"
      ],
      "metadata": {
        "id": "QkqIHiRpGPpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "425c4b7abe39a14c6f81f8a71094cc1024276935",
        "id": "UhmypdrO5R7z"
      },
      "cell_type": "markdown",
      "source": [
        "## Simple EDA\n",
        "\n",
        "- check the distribution of type of Arrhythmia for train/test set\n",
        "- visualize the ecg heartbeat signal "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "def plot_class(train,test,title='Value counts for each class of ..'):\n",
        "    # Create a bar plot for train and test set for each class\n",
        "    train_value_counts = train[187].value_counts()\n",
        "    test_value_counts = test[187].value_counts()\n",
        "\n",
        "    fig = go.Figure(go.Bar(\n",
        "                x=train_value_counts.index,\n",
        "                y=train_value_counts.values,\n",
        "                text=train_value_counts.values,\n",
        "                textposition='auto',\n",
        "                name='Train Set'\n",
        "            ))\n",
        "    \n",
        "    fig.add_trace(go.Bar(\n",
        "            x=test_value_counts.index,\n",
        "            y=test_value_counts.values,\n",
        "            text=test_value_counts.values,\n",
        "            textposition='auto',\n",
        "            name='Test Set'\n",
        "        ))\n",
        "    \n",
        "    # Set plot title and axis labels\n",
        "    fig.update_layout(title=title,\n",
        "                    xaxis_title=\"Class\",\n",
        "                    yaxis_title=\"Count\")\n",
        "\n",
        "    # Display the plot\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "nYlRXYZ2sVr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_class(train,test, title='Value counts for each class  in train/test set of MLT-BLH dataset')"
      ],
      "metadata": {
        "id": "4kviwSs8sdwk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "eba74bc3-9907-48da-bb0f-563c2b1015c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"81d88b4c-f60c-4b78-a9d2-cded590d71c2\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"81d88b4c-f60c-4b78-a9d2-cded590d71c2\")) {                    Plotly.newPlot(                        \"81d88b4c-f60c-4b78-a9d2-cded590d71c2\",                        [{\"name\":\"Train Set\",\"text\":[54353.0,4823.0,4341.0,1667.0,481.0],\"textposition\":\"auto\",\"x\":[0.0,4.0,2.0,1.0,3.0],\"y\":[54353,4823,4341,1667,481],\"type\":\"bar\"},{\"name\":\"Test Set\",\"text\":[18118.0,1608.0,1448.0,556.0,162.0],\"textposition\":\"auto\",\"x\":[0.0,4.0,2.0,1.0,3.0],\"y\":[18118,1608,1448,556,162],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Value counts for each class  in train/test set of MLT-BLH dataset\"},\"xaxis\":{\"title\":{\"text\":\"Class\"}},\"yaxis\":{\"title\":{\"text\":\"Count\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('81d88b4c-f60c-4b78-a9d2-cded590d71c2');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clearly, It is imbalanced in targets y. Moreover, the distribution of train and test share the similar proportion of the classes \n",
        "\n",
        "The majority of class is Normal (0), and the notable minority class is F (4)\n",
        "\n",
        "Imbalanced, then what? : If we use the plain loss function (say cross entropy loss function which is the loss for multi-class), it is very likely that the model will optimize the loss by guessing every class as the majority class. This will lead us to carefully choosing the right loss function to prevent undesirable output"
      ],
      "metadata": {
        "id": "kuxe2XsAvBCA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the paper we obtained the dataset from, the classes we have are shown as the following"
      ],
      "metadata": {
        "id": "UKaPIM1qWMCa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we wouldl like to observe the random heartbeat of each class of all types of arrhythmias"
      ],
      "metadata": {
        "id": "c_S5pv4p5nzv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "def plot_individual_class(df):\n",
        "\n",
        "    # randomly sample one row per class\n",
        "    df_sampled = df.groupby(187).apply(lambda x: x.sample(n=1)).reset_index(drop=True)\n",
        "\n",
        "\n",
        "    # melt the dataframe to convert it from wide to long format\n",
        "    df_melted = df_sampled.melt(id_vars=187, var_name='timestep')\n",
        "\n",
        "    class_names = {0: 'Normal (0)', 1: 'Supra-ventricular premature (1)', 2: 'Ventricular escape (2)', 3: 'Fusion of ventricular (3)', 4: 'Unclassifiable (4)'}\n",
        "\n",
        "    # replace the class numbers with their corresponding names\n",
        "    df_melted['class'] = df_melted[187].map(class_names)\n",
        "\n",
        "    # create the line plot with Plotly\n",
        "    fig = px.line(df_melted, x='timestep', y='value', color='class')\n",
        "\n",
        "    # update the layout of the plot\n",
        "    fig.update_layout(title='1-beat ECG for each category',\n",
        "                    xaxis_title='Timestep',\n",
        "                    yaxis_title='Normalized Value')\n",
        "\n",
        "    # display the plot\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "GcBhDZL0RG0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_individual_class(train)\n",
        "\n",
        "# Re-run to see new random observations for each class "
      ],
      "metadata": {
        "id": "TLgFgWjSRa4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "5362b4bb-c2de-4aa0-8732-eb5721b9e886"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"fd229964-7508-4cc9-9ef9-10e1e28d49ad\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"fd229964-7508-4cc9-9ef9-10e1e28d49ad\")) {                    Plotly.newPlot(                        \"fd229964-7508-4cc9-9ef9-10e1e28d49ad\",                        [{\"hovertemplate\":\"class=Normal (0)<br>timestep=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"Normal (0)\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"Normal (0)\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186],\"xaxis\":\"x\",\"y\":[0.9888268113136292,0.826815664768219,0.6648044586181641,0.46368715167045593,0.3072625696659088,0.18994413316249847,0.08100558817386627,0.06145251542329788,0.05027933046221733,0.02793296054005623,0.03351955488324165,0.04469273611903191,0.041899442672729485,0.04748603329062462,0.04469273611903191,0.05027933046221733,0.04748603329062462,0.041899442672729485,0.04469273611903191,0.03351955488324165,0.04469273611903191,0.03910614550113677,0.041899442672729485,0.03910614550113677,0.04469273611903191,0.06145251542329788,0.06983239948749542,0.09497206658124925,0.10335195809602736,0.14525139331817627,0.16201117634773254,0.18715083599090576,0.20670391619205475,0.2262569814920425,0.22905027866363523,0.21229049563407895,0.20111732184886927,0.19553072750568387,0.1759776473045349,0.17877094447612762,0.17877094447612762,0.15642458200454712,0.17877094447612762,0.15921787917613983,0.1340782195329666,0.16201117634773254,0.15642458200454712,0.14804469048976898,0.13966479897499084,0.15083798766136167,0.13966479897499084,0.15642458200454712,0.14804469048976898,0.14804469048976898,0.14245809614658356,0.17039106786251068,0.15642458200454712,0.15921787917613983,0.1536312848329544,0.15921787917613983,0.15083798766136167,0.15083798766136167,0.1731843501329422,0.20391061902046204,0.19553072750568387,0.20670391619205475,0.24022346735000608,0.26536312699317927,0.2681564390659332,0.2430167645215988,0.231843575835228,0.1536312848329544,0.09776536375284195,0.11173184216022491,0.10055866092443466,0.12011173367500304,0.11731843650341033,0.11731843650341033,0.11731843650341033,0.1284916251897812,0.12290503084659576,0.11173184216022491,0.12011173367500304,0.33240222930908203,0.6033519506454468,0.8770949840545654,1.0,0.8156424760818481,0.575419008731842,0.3966480493545532,0.26536312699317927,0.14245809614658356,0.05586592108011246,0.03072625771164894,0.0,0.008379888720810413,0.002793296007439494,0.005586592014878988,0.008379888720810413,0.02793296054005623,0.025139665231108665,0.025139665231108665,0.025139665231108665,0.04469273611903191,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"class=Supra-ventricular premature (1)<br>timestep=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"Supra-ventricular premature (1)\",\"line\":{\"color\":\"#EF553B\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"Supra-ventricular premature (1)\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186],\"xaxis\":\"x\",\"y\":[0.9473684430122375,0.6746411323547363,0.05263157933950424,0.023923445492982864,0.13875597715377808,0.11961722373962402,0.10526315867900848,0.17703349888324735,0.17224881052970886,0.1483253538608551,0.15789473056793213,0.21531100571155548,0.2775119543075561,0.2679425776004791,0.2631579041481018,0.2870813310146332,0.30622008442878723,0.27272728085517883,0.23923444747924805,0.2583732008934021,0.2583732008934021,0.23923444747924805,0.24880382418632507,0.22966507077217105,0.22966507077217105,0.24401913583278656,0.24401913583278656,0.27272728085517883,0.3349282443523407,0.35406699776649475,0.37799042463302607,0.41148325800895685,0.4593301415443421,0.4880382716655731,0.4880382716655731,0.5119616985321045,0.5215311050415039,0.5167464017868042,0.5071770548820496,0.5071770548820496,0.4688995182514191,0.43062201142311096,0.36842104792594904,0.35885167121887207,0.35406699776649475,0.31578946113586426,0.2775119543075561,0.2583732008934021,0.27272728085517883,0.2870813310146332,0.2679425776004791,0.24880382418632507,0.2775119543075561,0.2535885274410248,0.2631579041481018,0.2679425776004791,0.2631579041481018,0.24880382418632507,0.220095694065094,0.24401913583278656,0.2631579041481018,0.27272728085517883,0.24880382418632507,0.2775119543075561,0.320574164390564,0.33014354109764094,0.2966507077217102,0.320574164390564,0.3014354109764099,0.2631579041481018,0.23923444747924805,0.2966507077217102,0.3253588378429413,0.2870813310146332,0.2775119543075561,0.2966507077217102,0.33014354109764094,0.3253588378429413,0.2966507077217102,0.3014354109764099,0.31578946113586426,0.33014354109764094,0.33014354109764094,0.34928229451179504,0.35406699776649475,0.3827751278877258,0.46411484479904175,0.7464115023612976,1.0,0.6411483287811279,0.06698564440011978,0.0,0.10526315867900848,0.13875597715377808,0.09090909361839294,0.17703349888324735,0.23444975912570956,0.16746412217617035,0.15789473056793213,0.23923444747924805,0.3349282443523407,0.31578946113586426,0.2918660342693329,0.31578946113586426,0.339712917804718,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"class=Ventricular escape (2)<br>timestep=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"Ventricular escape (2)\",\"line\":{\"color\":\"#00cc96\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"Ventricular escape (2)\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186],\"xaxis\":\"x\",\"y\":[0.8482142686843872,0.9241071343421936,0.8683035969734192,0.8125,0.78125,0.7790178656578064,0.7767857313156128,0.765625,0.6116071343421936,0.3392857015132904,0.1763392835855484,0.1205357164144516,0.0982142835855484,0.08035714179277421,0.0647321417927742,0.0513392873108387,0.05357142910361289,0.03794642910361289,0.0357142873108387,0.0245535708963871,0.011160714551806448,0.015625,0.011160714551806448,0.008928571827709673,0.0044642859138548366,0.0,0.0066964286379516125,0.013392857275903223,0.015625,0.03794642910361289,0.05357142910361289,0.078125,0.1138392835855484,0.1473214328289032,0.1808035671710968,0.1986607164144516,0.203125,0.2142857164144516,0.2232142835855484,0.2209821492433548,0.2098214328289032,0.2053571492433548,0.2075892835855484,0.2120535671710968,0.2075892835855484,0.2075892835855484,0.2008928507566452,0.2142857164144516,0.2165178507566452,0.2165178507566452,0.2165178507566452,0.2142857164144516,0.2098214328289032,0.2232142835855484,0.2232142835855484,0.2276785671710968,0.2299107164144516,0.2299107164144516,0.234375,0.2299107164144516,0.2299107164144516,0.2299107164144516,0.2299107164144516,0.2433035671710968,0.2410714328289032,0.2433035671710968,0.2410714328289032,0.2366071492433548,0.2410714328289032,0.2433035671710968,0.25,0.2455357164144516,0.234375,0.25,0.2522321343421936,0.2544642984867096,0.2589285671710968,0.2745535671710968,0.2790178656578064,0.296875,0.3035714328289032,0.3058035671710968,0.28125,0.28125,0.2767857015132904,0.2589285671710968,0.2522321343421936,0.2433035671710968,0.2388392835855484,0.25,0.2455357164144516,0.2455357164144516,0.2544642984867096,0.2566964328289032,0.2544642984867096,0.2879464328289032,0.4464285671710968,0.7388392686843872,1.0,0.7008928656578064,0.3504464328289032,0.265625,0.2678571343421936,0.2589285671710968,0.2544642984867096,0.2522321343421936,0.25,0.2566964328289032,0.2522321343421936,0.2522321343421936,0.2633928656578064,0.265625,0.2723214328289032,0.265625,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"class=Fusion of ventricular (3)<br>timestep=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"Fusion of ventricular (3)\",\"line\":{\"color\":\"#ab63fa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"Fusion of ventricular (3)\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186],\"xaxis\":\"x\",\"y\":[1.0,0.8097826242446899,0.48097825050354,0.2581521868705749,0.15896739065647125,0.20788043737411496,0.21739129722118375,0.18614129722118375,0.18478260934352875,0.18206521868705747,0.167119562625885,0.16847826540470123,0.16032609343528748,0.15353260934352875,0.16576087474822998,0.17119565606117249,0.19021739065647125,0.20380434393882751,0.20788043737411496,0.22826087474823,0.25135868787765503,0.26222825050354004,0.2894021868705749,0.32472825050354004,0.3478260934352875,0.37364131212234497,0.3913043439388275,0.41847825050354,0.4510869681835175,0.4538043439388275,0.46195653080940247,0.46467390656471247,0.4660325944423676,0.44972825050354,0.42798912525177,0.4103260934352874,0.4116847813129425,0.38722825050354,0.35326087474823,0.33559781312942505,0.30298912525177,0.26766303181648254,0.26222825050354004,0.24320651590824127,0.229619562625885,0.22418478131294248,0.22282609343528748,0.229619562625885,0.23097826540470123,0.25,0.28125,0.29483696818351746,0.3165760934352875,0.3165760934352875,0.28260868787765503,0.24592390656471247,0.22282609343528748,0.20923912525177,0.21059782803058624,0.21195651590824127,0.21331521868705747,0.21467390656471247,0.20923912525177,0.21467390656471247,0.20380434393882751,0.22010870277881625,0.43070653080940247,0.75,0.942934811115265,0.7105978131294249,0.31929346919059753,0.05298912897706032,0.0,0.09375,0.135869562625885,0.11956521868705748,0.11277174204587936,0.114130437374115,0.10054347664117812,0.10326086729764938,0.114130437374115,0.11277174204587936,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"class=Unclassifiable (4)<br>timestep=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"Unclassifiable (4)\",\"line\":{\"color\":\"#FFA15A\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"Unclassifiable (4)\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186],\"xaxis\":\"x\",\"y\":[0.9989058971405027,0.9474835991859437,0.9070022106170654,0.8577680587768554,0.8008752465248109,0.7056892514228821,0.6072210073471069,0.5087527632713318,0.4124726355075836,0.3435448706150055,0.3052516281604767,0.1947483569383621,0.08424507826566696,0.0,0.037199124693870544,0.12691466510295868,0.1695842444896698,0.181619256734848,0.19693654775619504,0.19365426898002625,0.22428883612155917,0.2614879608154297,0.2986871004104614,0.33698031306266785,0.3807439804077149,0.4091903865337372,0.43107220530509943,0.42560175061225886,0.426695853471756,0.43873086571693426,0.45404812693595886,0.46280086040496826,0.4792122542858124,0.5076586604118347,0.5098468065261841,0.5361050367355347,0.5557987093925476,0.5645514130592345,0.5864332318305969,0.6094092130661011,0.6247264742851257,0.6214442253112793,0.6214442253112793,0.6269146800041199,0.6094092130661011,0.5962800979614258,0.5864332318305969,0.5415754914283752,0.52078777551651,0.502188205718994,0.46717724204063416,0.4463894963264465,0.42122536897659296,0.40153172612190247,0.39059081673622126,0.3763676285743713,0.3643326163291931,0.3566739559173584,0.34573304653167725,0.3588621318340301,0.34573304653167725,0.34792122244834894,0.3512035012245178,0.34682711958885193,0.34573304653167725,0.3522976040840149,0.3424507677555084,0.3446389436721802,0.35010939836502075,0.34573304653167725,0.3435448706150055,0.3512035012245178,0.3522976040840149,0.35557988286018366,0.3588621318340301,0.3588621318340301,0.3577680587768554,0.3522976040840149,0.3522976040840149,0.35557988286018366,0.35448578000068665,0.36542668938636774,0.3566739559173584,0.3413566648960113,0.34901532530784607,0.3588621318340301,0.37199124693870544,0.3796498775482178,0.3873085379600525,0.4124726355075836,0.41903719305992126,0.4354485869407654,0.43107220530509943,0.4157549142837525,0.4332603812217712,0.42778992652893066,0.42778992652893066,0.42122536897659296,0.4048140048980713,0.3993435502052307,0.38621443510055536,0.40153172612190247,0.5054704546928406,0.8796498775482178,1.0,0.9595186114311217,0.9070022106170654,0.8479212522506714,0.7943107485771179,0.7341356873512269,0.6455142498016356,0.54923415184021,0.45951861143112177,0.3894967138767242,0.3435448706150055,0.32056891918182373,0.274617075920105,0.18271334469318387,0.09190371632575987,0.05142232030630112,0.08752734959125519,0.152078777551651,0.1783369779586792,0.181619256734848,0.18708971142768857,0.18490153551101685,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Timestep\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Normalized Value\"}},\"legend\":{\"title\":{\"text\":\"class\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"text\":\"1-beat ECG for each category\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('fd229964-7508-4cc9-9ef9-10e1e28d49ad');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see that not all beats are fully recorded for 187 timesteps, instead they do zero padding.\n",
        "\n",
        "Next we are going to check the only signal whichhave a full record"
      ],
      "metadata": {
        "id": "T_ydw7MiK_cv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "complete = train[train[186] != 0]\n",
        "\n",
        "print(f'only {len(complete)} beat(s) are fully record for 187 timesteps')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzzsoLG4LRN_",
        "outputId": "ef658e54-c3d8-4f6c-d4e3-e2f538e5f16b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "only 583 beat(s) are fully record for 187 timesteps\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_individual_class(complete)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "MyXsu6KIMWIc",
        "outputId": "c4b4d08f-5cfd-4a12-cf1a-407ed73e8433"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"bbe1e525-537c-4f92-8769-d1536cbf66ec\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"bbe1e525-537c-4f92-8769-d1536cbf66ec\")) {                    Plotly.newPlot(                        \"bbe1e525-537c-4f92-8769-d1536cbf66ec\",                        [{\"hovertemplate\":\"class=Normal (0)<br>timestep=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"Normal (0)\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"Normal (0)\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186],\"xaxis\":\"x\",\"y\":[1.0,0.9681274890899657,0.2908366620540619,0.0,0.0996015965938568,0.13545817136764526,0.09561753273010254,0.17928287386894226,0.21115538477897644,0.14741036295890808,0.14741036295890808,0.20318725705146787,0.262948215007782,0.29482072591781616,0.28286853432655334,0.29482072591781616,0.3027888536453247,0.29482072591781616,0.2788844704627991,0.2908366620540619,0.3027888536453247,0.31075698137283325,0.31075698137283325,0.32270917296409607,0.3346613645553589,0.3346613645553589,0.32270917296409607,0.33864542841911316,0.38247013092041016,0.3904382586479187,0.41035857796669006,0.43824702501297,0.47011953592300415,0.47011953592300415,0.4900398552417755,0.5059760808944702,0.5298804640769958,0.5338645577430725,0.5219123363494873,0.525896430015564,0.5179283022880553,0.47011953592300415,0.4262948334217072,0.4023904502391815,0.3705179393291473,0.350597620010376,0.32669323682785034,0.32669323682785034,0.3346613645553589,0.3147410452365875,0.2868525981903076,0.2908366620540619,0.3027888536453247,0.29482072591781616,0.2868525981903076,0.29880478978157043,0.32270917296409607,0.29482072591781616,0.2908366620540619,0.306772917509079,0.31075698137283325,0.31075698137283325,0.3027888536453247,0.306772917509079,0.32669323682785034,0.31075698137283325,0.2908366620540619,0.3027888536453247,0.32270917296409607,0.31075698137283325,0.2908366620540619,0.3027888536453247,0.29482072591781616,0.29880478978157043,0.28286853432655334,0.28286853432655334,0.306772917509079,0.29482072591781616,0.2749004065990448,0.2908366620540619,0.306772917509079,0.2908366620540619,0.28286853432655334,0.28286853432655334,0.2908366620540619,0.29880478978157043,0.2868525981903076,0.2908366620540619,0.31872510910034174,0.2868525981903076,0.2788844704627991,0.2908366620540619,0.3147410452365875,0.3027888536453247,0.29482072591781616,0.31075698137283325,0.31872510910034174,0.29482072591781616,0.29482072591781616,0.306772917509079,0.32270917296409607,0.3027888536453247,0.29880478978157043,0.3147410452365875,0.3147410452365875,0.31075698137283325,0.3027888536453247,0.3027888536453247,0.32270917296409607,0.3306773006916046,0.32669323682785034,0.32270917296409607,0.3306773006916046,0.31872510910034174,0.306772917509079,0.31075698137283325,0.33864542841911316,0.32669323682785034,0.31075698137283325,0.3147410452365875,0.3147410452365875,0.3027888536453247,0.29880478978157043,0.29482072591781616,0.31872510910034174,0.31872510910034174,0.29482072591781616,0.31872510910034174,0.31872510910034174,0.29880478978157043,0.2908366620540619,0.3027888536453247,0.32270917296409607,0.31872510910034174,0.3147410452365875,0.3306773006916046,0.32270917296409607,0.32270917296409607,0.3147410452365875,0.3147410452365875,0.32270917296409607,0.3306773006916046,0.31075698137283325,0.31872510910034174,0.32270917296409607,0.3147410452365875,0.2908366620540619,0.306772917509079,0.306772917509079,0.3147410452365875,0.32669323682785034,0.31075698137283325,0.3306773006916046,0.29880478978157043,0.29482072591781616,0.3147410452365875,0.31872510910034174,0.31075698137283325,0.3027888536453247,0.306772917509079,0.3147410452365875,0.3027888536453247,0.29482072591781616,0.3027888536453247,0.31075698137283325,0.31075698137283325,0.29482072591781616,0.306772917509079,0.306772917509079,0.306772917509079,0.3027888536453247,0.3027888536453247,0.3147410452365875,0.3147410452365875,0.3147410452365875,0.31075698137283325,0.3147410452365875,0.2908366620540619,0.29482072591781616,0.31075698137283325,0.3147410452365875,0.31872510910034174,0.31075698137283325,0.306772917509079,0.31075698137283325,0.29880478978157043,0.2908366620540619],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"class=Supra-ventricular premature (1)<br>timestep=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"Supra-ventricular premature (1)\",\"line\":{\"color\":\"#EF553B\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"Supra-ventricular premature (1)\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186],\"xaxis\":\"x\",\"y\":[0.8552631735801696,0.7894737124443054,0.16228070855140686,0.0,0.07456140220165251,0.08771929889917372,0.07017543911933899,0.1315789520740509,0.18421052396297452,0.15789473056793213,0.18421052396297452,0.21491228044033048,0.23684211075305936,0.3070175349712372,0.3464912176132202,0.3552631437778473,0.35087719559669495,0.3333333432674408,0.3464912176132202,0.3552631437778473,0.34210526943206787,0.35087719559669495,0.3333333432674408,0.3114035129547119,0.2982456088066101,0.32017543911933893,0.36842104792594904,0.3947368562221527,0.3947368562221527,0.3859649002552032,0.4385964870452881,0.45614033937454224,0.48245614767074574,0.5219298005104065,0.5526315569877625,0.5701754093170166,0.5614035129547119,0.5350877046585083,0.5350877046585083,0.5219298005104065,0.4780701696872711,0.4429824650287628,0.4166666567325592,0.3947368562221527,0.33771929144859314,0.32017543911933893,0.3464912176132202,0.3333333432674408,0.28947368264198303,0.2763157784938812,0.28070175647735596,0.2675438523292541,0.30263158679008484,0.30263158679008484,0.2850877046585083,0.28070175647735596,0.30263158679008484,0.28947368264198303,0.32017543911933893,0.3070175349712372,0.31578946113586426,0.32017543911933893,0.3070175349712372,0.3114035129547119,0.32456141710281367,0.3114035129547119,0.31578946113586426,0.2982456088066101,0.2850877046585083,0.2850877046585083,0.32017543911933893,0.34210526943206787,0.29385966062545776,0.2850877046585083,0.3114035129547119,0.29385966062545776,0.2982456088066101,0.3070175349712372,0.3114035129547119,0.28947368264198303,0.2719298303127289,0.29385966062545776,0.2982456088066101,0.3333333432674408,0.2850877046585083,0.24122807383537287,0.2763157784938812,0.31578946113586426,0.3114035129547119,0.3114035129547119,0.2850877046585083,0.2763157784938812,0.25,0.2456140369176865,0.2850877046585083,0.2982456088066101,0.28070175647735596,0.2719298303127289,0.2850877046585083,0.29385966062545776,0.30263158679008484,0.2587719261646271,0.2675438523292541,0.29385966062545776,0.2675438523292541,0.2587719261646271,0.29385966062545776,0.2982456088066101,0.28070175647735596,0.28070175647735596,0.2982456088066101,0.3114035129547119,0.2719298303127289,0.2675438523292541,0.30263158679008484,0.28947368264198303,0.2763157784938812,0.2719298303127289,0.29385966062545776,0.2850877046585083,0.2719298303127289,0.29385966062545776,0.28947368264198303,0.30263158679008484,0.29385966062545776,0.2675438523292541,0.3070175349712372,0.29385966062545776,0.2850877046585083,0.28070175647735596,0.28070175647735596,0.3070175349712372,0.2982456088066101,0.2982456088066101,0.3114035129547119,0.31578946113586426,0.28070175647735596,0.2763157784938812,0.2850877046585083,0.32017543911933893,0.31578946113586426,0.2850877046585083,0.2850877046585083,0.2850877046585083,0.2850877046585083,0.28070175647735596,0.30263158679008484,0.32017543911933893,0.2850877046585083,0.2763157784938812,0.2850877046585083,0.2982456088066101,0.28070175647735596,0.2763157784938812,0.30263158679008484,0.30263158679008484,0.28947368264198303,0.2850877046585083,0.32017543911933893,0.3114035129547119,0.3070175349712372,0.2982456088066101,0.2850877046585083,0.2850877046585083,0.28070175647735596,0.30263158679008484,0.2982456088066101,0.2850877046585083,0.28947368264198303,0.2763157784938812,0.2850877046585083,0.3333333432674408,0.32017543911933893,0.2982456088066101,0.2850877046585083,0.28070175647735596,0.30263158679008484,0.28947368264198303,0.2982456088066101,0.2850877046585083,0.29385966062545776,0.2850877046585083,0.3114035129547119,0.32456141710281367,0.29385966062545776,0.28947368264198303,0.2982456088066101],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"class=Ventricular escape (2)<br>timestep=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"Ventricular escape (2)\",\"line\":{\"color\":\"#00cc96\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"Ventricular escape (2)\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186],\"xaxis\":\"x\",\"y\":[0.5345911979675293,0.45283019542694086,0.2987421452999115,0.022012578323483467,0.0,0.07232704758644104,0.09433962404727936,0.056603774428367615,0.05974842607975006,0.04716981202363968,0.04716981202363968,0.069182388484478,0.1761006265878677,0.29559749364852905,0.3113207519054413,0.31446540355682373,0.3333333432674408,0.3270440399646759,0.3459119498729706,0.3396226465702057,0.3584905564785004,0.3584905564785004,0.38050314784049993,0.3867924511432648,0.39937105774879456,0.4088050425052642,0.43081760406494146,0.4433962404727936,0.4654088020324707,0.4874213933944702,0.5220125913619995,0.544025182723999,0.5660377144813538,0.6037735939025879,0.6383647918701172,0.6666666865348816,0.7044025063514708,0.7201257944107056,0.7452830076217651,0.7389937043190001,0.7232704162597656,0.6823899149894713,0.6415094137191772,0.5849056839942932,0.544025182723999,0.48113209009170527,0.4433962404727936,0.39622640609741205,0.3710691928863525,0.34276729822158813,0.33647799491882324,0.31446540355682373,0.3176100552082062,0.30817610025405884,0.3050314486026764,0.2987421452999115,0.30817610025405884,0.2987421452999115,0.3050314486026764,0.29559749364852905,0.30817610025405884,0.30188679695129395,0.30817610025405884,0.30188679695129395,0.2987421452999115,0.2924528419971466,0.2924528419971466,0.2924528419971466,0.29559749364852905,0.27987420558929443,0.28616350889205927,0.27987420558929443,0.28616350889205927,0.2704402506351471,0.27987420558929443,0.2610062956809997,0.2641509473323822,0.2610062956809997,0.27358490228652954,0.26729559898376465,0.27358490228652954,0.2515723407268524,0.2610062956809997,0.25471699237823486,0.2641509473323822,0.2515723407268524,0.25786164402961725,0.2515723407268524,0.25786164402961725,0.24528302252292636,0.25471699237823486,0.25471699237823486,0.2610062956809997,0.25471699237823486,0.2641509473323822,0.2515723407268524,0.25471699237823486,0.24528302252292636,0.25471699237823486,0.25471699237823486,0.25471699237823486,0.2484276741743088,0.2610062956809997,0.25471699237823486,0.2610062956809997,0.2515723407268524,0.25471699237823486,0.24528302252292636,0.2641509473323822,0.25471699237823486,0.25786164402961725,0.25786164402961725,0.26729559898376465,0.2610062956809997,0.2641509473323822,0.25471699237823486,0.25786164402961725,0.25786164402961725,0.26729559898376465,0.25471699237823486,0.2641509473323822,0.25471699237823486,0.26729559898376465,0.2641509473323822,0.27358490228652954,0.2641509473323822,0.26729559898376465,0.2704402506351471,0.27358490228652954,0.2641509473323822,0.27358490228652954,0.2704402506351471,0.26729559898376465,0.2704402506351471,0.28930819034576416,0.27987420558929443,0.2987421452999115,0.3113207519054413,0.323899358510971,0.33018869161605835,0.3396226465702057,0.3333333432674408,0.3553459048271179,0.33018869161605835,0.33647799491882324,0.3176100552082062,0.30817610025405884,0.28616350889205927,0.28616350889205927,0.2704402506351471,0.27358490228652954,0.26729559898376465,0.27987420558929443,0.2641509473323822,0.2610062956809997,0.2610062956809997,0.276729553937912,0.27358490228652954,0.2830188572406769,0.30817610025405884,0.3553459048271179,0.446540892124176,0.650943398475647,0.8301886916160582,1.0,0.8364779949188232,0.4937106966972351,0.30817610025405884,0.3207547068595886,0.31446540355682373,0.2987421452999115,0.28616350889205927,0.2830188572406769,0.27358490228652954,0.2830188572406769,0.276729553937912,0.2924528419971466,0.27358490228652954,0.28930819034576416,0.2830188572406769,0.30188679695129395,0.2987421452999115,0.31446540355682373,0.3113207519054413,0.3270440399646759,0.3270440399646759,0.33647799491882324],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Timestep\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Normalized Value\"}},\"legend\":{\"title\":{\"text\":\"class\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"text\":\"1-beat ECG for each category\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('bbe1e525-537c-4f92-8769-d1536cbf66ec');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What's about test set\n",
        "\n",
        "complete = test[test[186] != 0]\n",
        "\n",
        "print(f'only {len(complete)} beat(s) are fully record for 187 timesteps')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgkhyMD_NsVn",
        "outputId": "256a1b17-9d42-4572-a2a5-0e0c64ac9aed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "only 188 beat(s) are fully record for 187 timesteps\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Beats of Test set \n",
        "\n",
        "plot_individual_class(complete)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "KsSGM1c2Nt0m",
        "outputId": "d730e82e-eaa2-400b-d427-d029d466718b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"261d550b-c92d-40bd-bb4a-48a42d58558f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"261d550b-c92d-40bd-bb4a-48a42d58558f\")) {                    Plotly.newPlot(                        \"261d550b-c92d-40bd-bb4a-48a42d58558f\",                        [{\"hovertemplate\":\"class=Normal (0)<br>timestep=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"Normal (0)\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"Normal (0)\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186],\"xaxis\":\"x\",\"y\":[0.9460431933403016,0.9856114983558655,0.48381295800209045,0.010791366919875143,0.12410072237253188,0.27697840332984924,0.2877697944641113,0.31474819779396057,0.32374101877212524,0.30755394697189326,0.31834533810615534,0.3255395591259002,0.31834533810615534,0.31474819779396057,0.31474819779396057,0.31834533810615534,0.316546767950058,0.31294962763786316,0.3201438784599304,0.3273381292819977,0.32194244861602783,0.31294962763786316,0.3201438784599304,0.33093523979187006,0.3291366994380951,0.32374101877212524,0.33633092045784,0.34712231159210205,0.3525179922580719,0.35611510276794434,0.36510792374610895,0.38848921656608576,0.4028776884078979,0.41187050938606257,0.433453232049942,0.4496402740478516,0.4622302055358887,0.46762588620185846,0.482014387845993,0.5071942210197449,0.5017985701560974,0.4874100685119629,0.4730215966701508,0.4640287756919861,0.42805755138397217,0.40107914805412287,0.383093535900116,0.3741007149219513,0.3615107834339142,0.34712231159210205,0.34712231159210205,0.35431653261184687,0.3435251712799072,0.3381294906139374,0.3417266309261322,0.3417266309261322,0.3381294906139374,0.33093523979187006,0.33453238010406494,0.3399280607700348,0.3399280607700348,0.33093523979187006,0.3381294906139374,0.3435251712799072,0.3381294906139374,0.3435251712799072,0.3381294906139374,0.3489208519458771,0.3489208519458771,0.3417266309261322,0.3435251712799072,0.34712231159210205,0.34712231159210205,0.3381294906139374,0.3381294906139374,0.3435251712799072,0.3399280607700348,0.3291366994380951,0.33093523979187006,0.33633092045784,0.3291366994380951,0.3255395591259002,0.3273381292819977,0.3291366994380951,0.3255395591259002,0.31834533810615534,0.3255395591259002,0.33453238010406494,0.32194244861602783,0.31474819779396057,0.31834533810615534,0.3273381292819977,0.3201438784599304,0.3201438784599304,0.31834533810615534,0.31834533810615534,0.31294962763786316,0.3057554066181183,0.31474819779396057,0.3201438784599304,0.31294962763786316,0.31115108728408813,0.31834533810615534,0.3255395591259002,0.316546767950058,0.3093525171279907,0.31115108728408813,0.316546767950058,0.31834533810615534,0.30755394697189326,0.30755394697189326,0.31834533810615534,0.3039568364620209,0.3093525171279907,0.3039568364620209,0.31294962763786316,0.31294962763786316,0.2967625856399536,0.3039568364620209,0.316546767950058,0.30755394697189326,0.3039568364620209,0.3057554066181183,0.3057554066181183,0.30755394697189326,0.30035972595214844,0.30755394697189326,0.31474819779396057,0.31294962763786316,0.3039568364620209,0.3093525171279907,0.316546767950058,0.3093525171279907,0.30755394697189326,0.30215826630592346,0.32374101877212524,0.3255395591259002,0.3291366994380951,0.34532374143600464,0.3633093535900116,0.3615107834339142,0.37050360441207886,0.3597122430801392,0.3489208519458771,0.3435251712799072,0.33093523979187006,0.3201438784599304,0.31294962763786316,0.28956833481788635,0.28057554364204407,0.2841726541519165,0.2931654751300812,0.2877697944641113,0.2841726541519165,0.2949640154838562,0.30215826630592346,0.2967625856399536,0.2931654751300812,0.2949640154838562,0.30755394697189326,0.3201438784599304,0.31834533810615534,0.366906464099884,0.5593525171279907,0.8003597259521484,1.0,0.7446042895317077,0.1744604259729385,0.0,0.183453232049942,0.25359711050987244,0.2877697944641113,0.30755394697189326,0.298561155796051,0.30035972595214844,0.31115108728408813,0.30755394697189326,0.298561155796051,0.3039568364620209,0.3039568364620209,0.30215826630592346,0.2967625856399536,0.3057554066181183,0.3201438784599304,0.31474819779396057,0.30035972595214844,0.3039568364620209],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"class=Supra-ventricular premature (1)<br>timestep=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"Supra-ventricular premature (1)\",\"line\":{\"color\":\"#EF553B\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"Supra-ventricular premature (1)\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186],\"xaxis\":\"x\",\"y\":[1.0,0.8669950962066649,0.2019704431295395,0.0,0.09359605610370639,0.15270936489105225,0.1231527104973793,0.15763546526432037,0.25123152136802673,0.19704432785511017,0.18719211220741272,0.23645320534706116,0.32019704580307007,0.3793103396892548,0.37438422441482544,0.35960590839385986,0.3694581389427185,0.35960590839385986,0.35467979311943054,0.3793103396892548,0.39408865571022034,0.3793103396892548,0.35960590839385986,0.37438422441482544,0.39901477098464966,0.3793103396892548,0.39901477098464966,0.45320197939872736,0.45320197939872736,0.4581280648708344,0.46798029541969294,0.517241358757019,0.5615763664245604,0.5566502213478088,0.5812807679176331,0.6305418610572815,0.6502463221549988,0.6551724076271057,0.6453201770782471,0.6157635450363159,0.5714285969734192,0.517241358757019,0.48275861144065857,0.46798029541969294,0.43349754810333246,0.4088670015335083,0.38916257023811346,0.37438422441482544,0.3694581389427185,0.33497536182403564,0.3448275923728943,0.33990147709846497,0.33497536182403564,0.35467979311943054,0.37438422441482544,0.3793103396892548,0.39901477098464966,0.38916257023811346,0.35467979311943054,0.3694581389427185,0.39901477098464966,0.38916257023811346,0.38916257023811346,0.37438422441482544,0.37438422441482544,0.3694581389427185,0.33990147709846497,0.33990147709846497,0.37438422441482544,0.35960590839385986,0.35467979311943054,0.3694581389427185,0.3694581389427185,0.37438422441482544,0.33497536182403564,0.35960590839385986,0.3448275923728943,0.33497536182403564,0.3448275923728943,0.35467979311943054,0.3645320236682892,0.35960590839385986,0.3300492465496063,0.3300492465496063,0.3645320236682892,0.35467979311943054,0.32019704580307007,0.33990147709846497,0.3694581389427185,0.35960590839385986,0.33497536182403564,0.3497537076473236,0.3497537076473236,0.3497537076473236,0.33990147709846497,0.35467979311943054,0.3793103396892548,0.33497536182403564,0.3103448152542114,0.33497536182403564,0.3645320236682892,0.3694581389427185,0.33990147709846497,0.33990147709846497,0.35960590839385986,0.3497537076473236,0.33497536182403564,0.35467979311943054,0.35960590839385986,0.3645320236682892,0.3448275923728943,0.3448275923728943,0.3694581389427185,0.3694581389427185,0.33990147709846497,0.35467979311943054,0.3694581389427185,0.35960590839385986,0.35960590839385986,0.35960590839385986,0.3694581389427185,0.3694581389427185,0.3448275923728943,0.3497537076473236,0.3645320236682892,0.35467979311943054,0.35960590839385986,0.37438422441482544,0.38916257023811346,0.3694581389427185,0.35467979311943054,0.3448275923728943,0.3694581389427185,0.3793103396892548,0.3448275923728943,0.3497537076473236,0.38916257023811346,0.3448275923728943,0.3300492465496063,0.3497537076473236,0.3645320236682892,0.35467979311943054,0.3448275923728943,0.35960590839385986,0.35960590839385986,0.33990147709846497,0.35467979311943054,0.33990147709846497,0.33990147709846497,0.3448275923728943,0.33990147709846497,0.35467979311943054,0.35467979311943054,0.3300492465496063,0.32019704580307007,0.35960590839385986,0.3645320236682892,0.33990147709846497,0.3300492465496063,0.33990147709846497,0.35960590839385986,0.3645320236682892,0.3448275923728943,0.35960590839385986,0.33497536182403564,0.33990147709846497,0.3103448152542114,0.29556649923324585,0.33497536182403564,0.3497537076473236,0.33497536182403564,0.31527093052864075,0.33497536182403564,0.33990147709846497,0.3054187297821045,0.3300492465496063,0.32512316107749933,0.3300492465496063,0.33497536182403564,0.3448275923728943,0.35960590839385986,0.3497537076473236,0.32019704580307007,0.31527093052864075,0.33990147709846497,0.3645320236682892,0.3448275923728943],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"class=Ventricular escape (2)<br>timestep=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"Ventricular escape (2)\",\"line\":{\"color\":\"#00cc96\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"Ventricular escape (2)\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186],\"xaxis\":\"x\",\"y\":[1.0,0.9356984496116638,0.8625277280807494,0.7716186046600341,0.7605321407318115,0.6097561120986937,0.4013303816318512,0.2705099880695343,0.21286031603813169,0.16629712283611295,0.1330377012491226,0.0886917933821678,0.06873614341020584,0.07095343619585037,0.07095343619585037,0.05321507900953293,0.07317072898149489,0.06651885062456131,0.06430155038833618,0.05321507900953293,0.0509977824985981,0.033259425312280655,0.024390242993831635,0.013303769752383232,0.006651884876191616,0.0,0.017738359048962593,0.015521064400672913,0.035476718097925186,0.05321507900953293,0.0798226147890091,0.10421285778284071,0.12195122241973876,0.15077605843544006,0.17294900119304657,0.190687358379364,0.21507760882377625,0.22616407275199887,0.23725055158138275,0.23946784436702728,0.25277161598205566,0.25055432319641113,0.2638580799102783,0.26164078712463373,0.26829269528388977,0.27272728085517883,0.2793791592121124,0.27272728085517883,0.2793791592121124,0.27494457364082336,0.2815964519977569,0.2904656231403351,0.2793791592121124,0.2904656231403351,0.27272728085517883,0.27494457364082336,0.27494457364082336,0.2705099880695343,0.27272728085517883,0.26607540249824524,0.26164078712463373,0.25055432319641113,0.25942349433898926,0.2483370304107666,0.25498890876770014,0.25055432319641113,0.26164078712463373,0.24390244483947757,0.25055432319641113,0.24611973762512207,0.2483370304107666,0.24611973762512207,0.24390244483947757,0.2483370304107666,0.25055432319641113,0.2416851371526718,0.25498890876770014,0.24611973762512207,0.25498890876770014,0.2416851371526718,0.25055432319641113,0.2483370304107666,0.25942349433898926,0.24390244483947757,0.25055432319641113,0.25055432319641113,0.25498890876770014,0.2483370304107666,0.25498890876770014,0.25055432319641113,0.25942349433898926,0.2416851371526718,0.26164078712463373,0.25498890876770014,0.25498890876770014,0.25498890876770014,0.25942349433898926,0.26607540249824524,0.26164078712463373,0.26607540249824524,0.26829269528388977,0.26164078712463373,0.26829269528388977,0.26607540249824524,0.26829269528388977,0.26607540249824524,0.2815964519977569,0.26829269528388977,0.2638580799102783,0.26829269528388977,0.26829269528388977,0.27272728085517883,0.2793791592121124,0.2771618664264679,0.2815964519977569,0.27272728085517883,0.286031037569046,0.2815964519977569,0.2838137447834015,0.2815964519977569,0.2771618664264679,0.2815964519977569,0.2904656231403351,0.27272728085517883,0.2838137447834015,0.2793791592121124,0.2838137447834015,0.2815964519977569,0.2904656231403351,0.2882483303546905,0.2926829159259796,0.2882483303546905,0.29490020871162415,0.2838137447834015,0.29711753129959106,0.2882483303546905,0.30155211687088007,0.29490020871162415,0.2993348240852356,0.29711753129959106,0.30820399522781367,0.3059867024421692,0.31042128801345825,0.3126385807991028,0.32594233751297,0.32372504472732544,0.34811529517173767,0.37028825283050537,0.40576496720314026,0.4478935599327088,0.4545454680919647,0.45676276087760925,0.44567626714706415,0.4013303816318512,0.3725055456161499,0.35254988074302673,0.34811529517173767,0.34811529517173767,0.35476717352867126,0.3636363744735718,0.41906872391700734,0.6319290399551392,0.95343679189682,0.9955654144287107,0.7117516398429872,0.30155211687088007,0.32150775194168085,0.30820399522781367,0.3192904591560364,0.2993348240852356,0.30376940965652466,0.2926829159259796,0.2926829159259796,0.2926829159259796,0.2993348240852356,0.29711753129959106,0.2926829159259796,0.2993348240852356,0.30155211687088007,0.3059867024421692,0.32150775194168085,0.32372504472732544,0.337028831243515,0.3414634168148041,0.35698446631431574,0.3636363744735718,0.38359200954437256],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Timestep\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Normalized Value\"}},\"legend\":{\"title\":{\"text\":\"class\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"text\":\"1-beat ECG for each category\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('261d550b-c92d-40bd-bb4a-48a42d58558f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "None of the fusion of ventricular and unclassfier are fully recorded, \n",
        "\n",
        "thus, this MIGHT be a pattern the model is learning to classify them as fusion of ventricular and unclassfier if they found the zero padding.\n",
        "\n",
        "Personally, it might make the model archeive high score in this dataset, but in practical, this is not always the case."
      ],
      "metadata": {
        "id": "0NEWjd_INCKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# No longer used\n",
        "\n",
        "del complete"
      ],
      "metadata": {
        "id": "l1mdaRjqMfsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîç Data Preparation"
      ],
      "metadata": {
        "id": "jnfuwoEyPEy5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before doing anything, it's good to set deteministic seed, so, we can reproduce the result\n",
        "\n",
        "Although, it's not possible to fully reproduce, but we can minimize the variance of the result"
      ],
      "metadata": {
        "id": "3n_GbNwW7e-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Set up reproducible seed\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)"
      ],
      "metadata": {
        "id": "wrhV7vMD7dD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c269ab78773e4b5a960a5e55d2b48c53d5f9c446",
        "id": "Qgn4MREd5R73"
      },
      "cell_type": "markdown",
      "source": [
        "## Data augmentation\n",
        "\n",
        "Since I'm not currently an domain expert about heartbeat signal, I'm not confident enough to do data augmentation.\n",
        "\n",
        "If I have more time, i will consider read this paper, so, I will have the idea on data augmentation for heartbeat signal (https://arxiv.org/pdf/2202.00569)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Skip"
      ],
      "metadata": {
        "id": "3lsE3v6_FClA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Torch Dataset\n",
        "\n",
        "In this notebook, I (Run) decided to use Pytorch Framework, so, we need to transform train, val, test into torch dataset object"
      ],
      "metadata": {
        "id": "kY4AT_W6DVpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pandas to numpy \n",
        "\n",
        "X_train = train.values[:, :-1] \n",
        "y_train = train.values[:, -1].astype(int)\n",
        "\n",
        "X_val = val.values[:, :-1]\n",
        "y_val = val.values[:, -1].astype(int)\n",
        "\n",
        "X_test = test.values[:, :-1]\n",
        "y_test = test.values[:, -1].astype(int)"
      ],
      "metadata": {
        "id": "F_NP4Zee_Dk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn to one-hot first\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "y_train=to_categorical(y_train)\n",
        "y_val=to_categorical(y_val)\n",
        "y_test=to_categorical(y_test)"
      ],
      "metadata": {
        "id": "OQgGbSgoD8C4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class Arrhythmias_Dataset(Dataset):\n",
        "    def __init__(self, X, y, transforms=None):\n",
        "        assert y.shape[1] == 5\n",
        "        assert X.shape[1] == 187\n",
        "        assert X.ndim == 2\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.transforms = transforms\n",
        "        self._process()\n",
        "\n",
        "    def _process(self):\n",
        "        pass\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self,index):\n",
        "        \n",
        "        X = torch.tensor( self.X[index] , dtype=torch.float32)\n",
        "        X = X.unsqueeze(0)\n",
        "        y = torch.tensor( self.y[index] , dtype = torch.float32)#.long()\n",
        "\n",
        "        if self.transforms:\n",
        "            X = self.transforms(X)\n",
        "\n",
        "\n",
        "        return X, y"
      ],
      "metadata": {
        "id": "aMmHjwbdDkQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup\n",
        "\n",
        "train_set = Arrhythmias_Dataset(X_train,y_train)\n",
        "val_set = Arrhythmias_Dataset(X_val,y_val)\n",
        "test_set = Arrhythmias_Dataset(X_test,y_test)"
      ],
      "metadata": {
        "id": "HuggPz76ER6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As well as dataloader, since we decided to do mini-batches GD. in order to overcome the out-of-memory issue in RAM. Batch_size for val_set is arbitrary, but cannot be full-batch size, otherwise, it will be out-of-memory \n",
        "\n",
        "Doing Mini-batch also make a set of parameter of the model converges faster, and generalize better than batch GD."
      ],
      "metadata": {
        "id": "Hnz-ElUalGyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def get_loader(train_set,val_set,test_set,train_batch_size = 256):\n",
        "    \"\"\"\n",
        "    Return train_loader and val_loader given wandb.config\n",
        "    !Warning : Make sure to declare p_train, p_val as global variable before\n",
        "\n",
        "    \"\"\"\n",
        "    # Dependence Config : architecture, batch_size, transform\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=train_batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_set, batch_size=1024, shuffle=False) # Val set should not be fine tuned, since they always give the same score regardless the batch size\n",
        "    test_loader = DataLoader(test_set, batch_size=1024, shuffle=False) # Val set should not be fine tuned, since they always give the same score regardless the batch size\n",
        "\n",
        "    return train_loader, val_loader, test_loader"
      ],
      "metadata": {
        "id": "jN0G5ObRHMJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, val_loader, test_loader = get_loader(train_set,val_set,test_set,train_batch_size = 256) # Train batch_size"
      ],
      "metadata": {
        "id": "jAtdOvUxH2HQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üëâ Modelling"
      ],
      "metadata": {
        "id": "aDTNwBRDrV1t"
      }
    },
    {
      "metadata": {
        "_uuid": "c4de23b85abe34a726eab268171da0e827bafa35",
        "id": "IPqcx5xa5R76"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup all architecture\n",
        "\n",
        "Although sequence is not arbitrary due to zero padding, but order still need to be preserved, so we will give up on non-sequence model due to bad representation of human intelligence. Hence, all candidates we choose will be the most common architectures that are appropriate with our task; sequence model\n",
        "However, just one non-sequence model to prove that the order matters\n",
        "\n",
        "- Logistic regression\n",
        "\n",
        "\n",
        "I would like to divide categories of architecture into 2 groups: RNN-based and CNN-based\n",
        "\n",
        "RNN-based is the default choice for sequence data,\n",
        "\n",
        "- GRU \n",
        "- LSTM \n",
        "\n",
        "Note that These above architecture can have more than 1 layers\n",
        "\n",
        "The thing I worry is that the zero padding may reduce the performance of them. In future, If possible, we will mask those zero padding, so, it could show the true performance.\n",
        "\n",
        "However, CNN with conv1d layer still is able to do so. Moreover, it can be used as transfer learning due to the feature extraction layer. We may transfer them into another task on Myocardial infarction which might suffer from relatively low data \n",
        "\n",
        "Due to a limited time, I plan to implement a reliable convolutional neural network (CNN) architecture for our task. We will base our model on a research paper that we obtained the data from, which uses a Conv1d-based architecture with residual blocks.\n",
        "\n",
        "- Deep_ResCNN\n",
        "\n",
        "The proposed CNN architecture will have multiple convolutional layers, each with 32 channels, a stride of 5, and same padding. This ensures that the addition in the residual blocks can be performed on units with the same number of channels without having to map them to the same unit using weight dot products. We will incorporate 5 residual connection blocks over the plain convolutional layers, which helps to accelerate learning by addressing the vanishing gradient problem. Finally, we will add three fully connected layers with the ReLU activation function for the hidden layers and softmax for the output layer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "mQi3DCbkbv0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LogisticRegression(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        self.linear = nn.Linear(187, 5)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x= x.squeeze(1)\n",
        "        out = self.linear(x)\n",
        "        return out\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    x = torch.rand(32,1,187)\n",
        "    # Test 1 layer of GRU with hidden size 32x32\n",
        "    logistic_model = LogisticRegression()\n",
        "    out = logistic_model(x)\n",
        "    print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac0nNgrYStPe",
        "outputId": "9aa36917-f0d0-4f6a-c96a-fd2a204adb77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# GRU model # Many-to-one\n",
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, hidden_size, num_layers, device = device):\n",
        "        super(GRUModel,self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.gru = nn.GRU(1, hidden_size, num_layers, batch_first=True).to(device) # batch_first=True : Optional, but I prefer the first axis of data shape to be batch\n",
        "        self.fc = nn.Linear(hidden_size,5).to(device)\n",
        "\n",
        "        self.device = device\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        h0 = torch.zeros(self.num_layers, x.shape[0], self.hidden_size).to(self.device)\n",
        "        out, _ = self.gru(x, h0)\n",
        "        out = out[:,-1,:] # Take only the last timestep of the output layer\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    x = torch.rand(32,1,187).to(device)\n",
        "\n",
        "    # Test 1 layer of GRU with hidden size 32x32\n",
        "    gru_model = GRUModel(hidden_size=32,num_layers = 1)\n",
        "    gru_model2 = GRUModel(hidden_size=32,num_layers = 2)\n",
        "    out = gru_model(x)\n",
        "    out2 = gru_model2(x)\n",
        "    print(out.shape)\n",
        "    print(out2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maSBaOWl0fUi",
        "outputId": "46f4c94a-c6c8-4887-9562-d0d4033fef6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 5])\n",
            "torch.Size([32, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM model # Many-to-one\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, hidden_size, num_layers, device = device):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(1, hidden_size, num_layers, batch_first=True).to(device) # batch_first=True : Optional, but I prefer the first axis of data shape to be batch\n",
        "        self.fc = nn.Linear(hidden_size,5).to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = x.permute(0, 2, 1)\n",
        "        h0 = torch.zeros(self.num_layers, x.shape[0], self.hidden_size).to(device) #short term\n",
        "        c0 = torch.zeros(self.num_layers, x.shape[0], self.hidden_size).to(device) #long term\n",
        "\n",
        "        out, _ = self.lstm(x, (h0,c0))\n",
        "        out = out[:,-1,:] # Take only the last timestep of the output layer\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    x = torch.rand(32,1,187).to(device)\n",
        "\n",
        "    # Test 1 layer of GRU with hidden size 32x32\n",
        "    lstm_model = LSTMModel(hidden_size=32,num_layers = 1)\n",
        "    lstm_model2 = LSTMModel(hidden_size=32,num_layers = 2)\n",
        "    out = lstm_model(x)\n",
        "    out2 = lstm_model2(x)\n",
        "    print(out.shape)\n",
        "    print(out2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDK3QK5U7SPZ",
        "outputId": "f1dfbfa3-74bd-43ca-f356-ea76d7892d77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 5])\n",
            "torch.Size([32, 5])\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e70fab0b07290e042ba9cd7c6cba37462a457b03",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFjBfiBY5R76",
        "outputId": "b6970507-6d82-4817-8565-6a533238341a"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Deep_ResCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Deep_ResCNN, self).__init__()\n",
        "        # kernel size : (5,), number of channel : 32\n",
        "        self.conv1 = nn.Conv1d(1, 32, 5)\n",
        "        \n",
        "        self.conv2_1 = nn.Conv1d(32, 32, 5, padding=2)\n",
        "        self.conv2_2 = nn.Conv1d(32, 32, 5, padding=2)\n",
        "        \n",
        "        self.conv3_1 = nn.Conv1d(32, 32, 5, padding=2)\n",
        "        self.conv3_2 = nn.Conv1d(32, 32, 5, padding=2)\n",
        "        \n",
        "        self.conv4_1 = nn.Conv1d(32, 32, 5, padding=2)\n",
        "        self.conv4_2 = nn.Conv1d(32, 32, 5, padding=2)\n",
        "        \n",
        "        self.conv5_1 = nn.Conv1d(32, 32, 5, padding=2)\n",
        "        self.conv5_2 = nn.Conv1d(32, 32, 5, padding=2)\n",
        "        \n",
        "        self.fc1 = nn.Linear(32*8, 32)\n",
        "        self.fc2 = nn.Linear(32, 32)\n",
        "        self.fc3 = nn.Linear(32, 5)\n",
        "        \n",
        "        self._init_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        \n",
        "        x1 = F.relu(self.conv2_1(x))\n",
        "        x1 = self.conv2_2(x1)\n",
        "        x = F.relu(x + x1)\n",
        "        x = F.max_pool1d(x, kernel_size=5, stride=2)\n",
        "        \n",
        "        x1 = F.relu(self.conv3_1(x))\n",
        "        x1 = self.conv3_2(x1)\n",
        "        x = F.relu(x + x1)\n",
        "        x = F.max_pool1d(x, kernel_size=5, stride=2)\n",
        "        \n",
        "        x1 = F.relu(self.conv4_1(x))\n",
        "        x1 = self.conv4_2(x1)\n",
        "        x = F.relu(x + x1)\n",
        "        x = F.max_pool1d(x, kernel_size=5, stride=2)\n",
        "        \n",
        "        x1 = F.relu(self.conv5_1(x))\n",
        "        x1 = self.conv5_2(x1)\n",
        "        x = F.relu(x + x1)\n",
        "        x = F.max_pool1d(x, kernel_size=5, stride=2)\n",
        "        \n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv1d) or isinstance(m, nn.Linear):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    x = torch.rand(32,1,187)\n",
        "    res_model = Deep_ResCNN()\n",
        "    print(res_model)\n",
        "    out = res_model(x)\n",
        "    print(out.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deep_ResCNN(\n",
            "  (conv1): Conv1d(1, 32, kernel_size=(5,), stride=(1,))\n",
            "  (conv2_1): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "  (conv2_2): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "  (conv3_1): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "  (conv3_2): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "  (conv4_1): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "  (conv4_2): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "  (conv5_1): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "  (conv5_2): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "  (fc1): Linear(in_features=256, out_features=32, bias=True)\n",
            "  (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
            "  (fc3): Linear(in_features=32, out_features=5, bias=True)\n",
            ")\n",
            "torch.Size([32, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_architecture(name, device ,**kwargs):\n",
        "\n",
        "    if name in ['gru','lstm']:\n",
        "        hidden_size = kwargs.get('hidden_size')\n",
        "        num_layers = kwargs.get('num_layers')\n",
        "        assert hidden_size, 'gru or lstm requires argument hidden_size'\n",
        "        assert num_layers, 'gru or lstm requires argument num_layers'\n",
        "\n",
        "    if name == 'gru':\n",
        "        model = GRUModel(hidden_size=hidden_size,num_layers = num_layers).to(device)\n",
        "    elif name == 'lstm':\n",
        "        model = LSTMModel(hidden_size=hidden_size,num_layers=num_layers).to(device)\n",
        "    elif name == 'deep_rescnn':\n",
        "        model = Deep_ResCNN().to(device)\n",
        "    elif name == 'log_reg':\n",
        "        model = LogisticRegression().to(device)\n",
        "    else:\n",
        "        raise ValueError('unknown architecture')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "JkRRYEX_IcRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Baseline\n",
        "\n",
        "We never know Is our proposed model actually better than random-guessing model, or predict everything as majority class.\n",
        "\n",
        "To prove that I would like to introduce ZeroR as guessing everything as majority class"
      ],
      "metadata": {
        "id": "7Eil2FydX4vi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "def get_zero_baseline(train_set,val_set,test_set): \n",
        "    \"\"\"\n",
        "    Baseline model where we predict every heartbeat signal as majority class\n",
        "    \"\"\"\n",
        "    torch.manual_seed(seed)\n",
        "    \n",
        "    train_targets = torch.tensor(train_set.y).long()\n",
        "    val_targets = torch.tensor(val_set.y).long()\n",
        "    test_targets = torch.tensor(test_set.y).long()\n",
        "\n",
        "    num_classes = train_targets.shape[1]\n",
        "\n",
        "    train_preds = torch.zeros_like(train_targets)\n",
        "    train_preds[:, 0] = 1\n",
        "    val_preds = torch.zeros_like(val_targets)\n",
        "    val_preds[:, 0] = 1\n",
        "    test_preds = torch.zeros_like(test_targets)\n",
        "    test_preds[:, 0] = 1\n",
        "\n",
        "    sets = ['train', 'val', 'test']\n",
        "    preds = [train_preds, val_preds, test_preds]\n",
        "    targets = [train_targets, val_targets, test_targets]\n",
        "\n",
        "    metric = {}\n",
        "    for set_, pred, target in zip(sets, preds, targets):\n",
        "\n",
        "        recall = recall_score(target, pred, average='weighted')\n",
        "        precision = precision_score(target, pred, average='weighted')\n",
        "        f1 = f1_score(target, pred, average='weighted')\n",
        "\n",
        "        metric.update({f'best_{set_}_recall': recall,\n",
        "                       f'best_{set_}_precision': precision,\n",
        "                       f'best_{set_}_f1': f1}\n",
        "                      )\n",
        "\n",
        "    return metric"
      ],
      "metadata": {
        "id": "lvPehs1rzMK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = get_zero_baseline(train_set,val_set,test_set)\n",
        "\n",
        "benchmark = pd.DataFrame({'model_name':'zero_baseline', 'hyperparameter' : 'seed=42','best_epoch' : 1,\n",
        "                                'best_train_cost' : None, 'best_val_cost' : None } | result,\n",
        "                                index=[0])"
      ],
      "metadata": {
        "id": "bWkEEF5PViLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "cEqA7pX4V1L4",
        "outputId": "5cc4d696-cd44-4357-94e3-da0e75c57278"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      model_name hyperparameter  best_epoch best_train_cost best_val_cost  \\\n",
              "0  zero_baseline        seed=42           1            None          None   \n",
              "\n",
              "   best_train_recall  best_train_precision  best_train_f1  best_val_recall  \\\n",
              "0           0.827732               0.68514       0.749716         0.827722   \n",
              "\n",
              "   best_val_precision  best_val_f1  best_test_recall  best_test_precision  \\\n",
              "0            0.685123     0.749702          0.827608             0.684935   \n",
              "\n",
              "   best_test_f1  \n",
              "0      0.749543  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b582979-cbde-4796-bdff-cb530669216c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>hyperparameter</th>\n",
              "      <th>best_epoch</th>\n",
              "      <th>best_train_cost</th>\n",
              "      <th>best_val_cost</th>\n",
              "      <th>best_train_recall</th>\n",
              "      <th>best_train_precision</th>\n",
              "      <th>best_train_f1</th>\n",
              "      <th>best_val_recall</th>\n",
              "      <th>best_val_precision</th>\n",
              "      <th>best_val_f1</th>\n",
              "      <th>best_test_recall</th>\n",
              "      <th>best_test_precision</th>\n",
              "      <th>best_test_f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>zero_baseline</td>\n",
              "      <td>seed=42</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>0.827732</td>\n",
              "      <td>0.68514</td>\n",
              "      <td>0.749716</td>\n",
              "      <td>0.827722</td>\n",
              "      <td>0.685123</td>\n",
              "      <td>0.749702</td>\n",
              "      <td>0.827608</td>\n",
              "      <td>0.684935</td>\n",
              "      <td>0.749543</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b582979-cbde-4796-bdff-cb530669216c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1b582979-cbde-4796-bdff-cb530669216c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1b582979-cbde-4796-bdff-cb530669216c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/99dac6621f6ae8c4/data_table.js\";\n\n      window.createDataTable({\n        data: [[{\n            'v': 0,\n            'f': \"0\",\n        },\n\"zero_baseline\",\n\"seed=42\",\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': 0.8277316683164547,\n            'f': \"0.8277316683164547\",\n        },\n{\n            'v': 0.6851397147339414,\n            'f': \"0.6851397147339414\",\n        },\n{\n            'v': 0.7497158654202581,\n            'f': \"0.7497158654202581\",\n        },\n{\n            'v': 0.8277216866919457,\n            'f': \"0.8277216866919457\",\n        },\n{\n            'v': 0.6851231906201596,\n            'f': \"0.6851231906201596\",\n        },\n{\n            'v': 0.7497018781455581,\n            'f': \"0.7497018781455581\",\n        },\n{\n            'v': 0.8276082587246483,\n            'f': \"0.8276082587246483\",\n        },\n{\n            'v': 0.6849354299092444,\n            'f': \"0.6849354299092444\",\n        },\n{\n            'v': 0.7495429358446977,\n            'f': \"0.7495429358446977\",\n        }]],\n        columns: [[\"number\", \"index\"], [\"string\", \"model_name\"], [\"string\", \"hyperparameter\"], [\"number\", \"best_epoch\"], [\"number\", \"best_train_cost\"], [\"number\", \"best_val_cost\"], [\"number\", \"best_train_recall\"], [\"number\", \"best_train_precision\"], [\"number\", \"best_train_f1\"], [\"number\", \"best_val_recall\"], [\"number\", \"best_val_precision\"], [\"number\", \"best_val_f1\"], [\"number\", \"best_test_recall\"], [\"number\", \"best_test_precision\"], [\"number\", \"best_test_f1\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: \"0\",\n      });\n    "
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter new user, if new, then initiate new benchmark\n",
        "\n",
        "try:\n",
        "    benchmark = pd.read_csv('/content/drive/MyDrive/arrhythmia_classification/benchmark.csv')\n",
        "except FileNotFoundError:\n",
        "    benchmark = pd.DataFrame({'model_name':'zero_baseline', 'hyperparameter' : 'seed=42','best_epoch' : 1,\n",
        "                                'best_train_cost' : None, 'best_val_cost' : None } | result,\n",
        "                                index=[0])"
      ],
      "metadata": {
        "id": "NMPILDDTORx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The f1 score of the zero baseline seems to be relatively high, which highlights the need to avoid the trap of training the model to perform no better than guessing everything as the majority class (normal). To be considered effective, our model's f1 score must surpass the threshold of approximately 74.9%.\n",
        "\n",
        "In the next section, we will explore how to overcome this issue and train our model to achieve better performance by avoiding the trap of overfitting to the majority class."
      ],
      "metadata": {
        "id": "Dl_AN58mmRkF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cost function for imbalanced dataset\n",
        "\n",
        "- we use weight cross entropy over plain"
      ],
      "metadata": {
        "id": "5nlIBYrtmw2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_weighted_for_ce(y_train):\n",
        "    class_counts = y_train.sum(axis=0)\n",
        "    class_counts = torch.tensor(class_counts)\n",
        "    class_weights = class_counts / class_counts.sum()\n",
        "    class_weights_normalized = 1.0 / class_weights\n",
        "    return class_weights_normalized"
      ],
      "metadata": {
        "id": "psj9UbQJmMh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model selection"
      ],
      "metadata": {
        "id": "BldJJG_Km2i9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from copy import deepcopy\n",
        "import math\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def train(model, optimizer, scheduler, criterion, train_loader, val_loader, num_epochs):\n",
        "    best_val_f1 = 0.0\n",
        "    best_val_recall = 0.0\n",
        "    best_val_precision = 0.0\n",
        "    best_train_f1 = 0.0\n",
        "    best_train_recall = 0.0\n",
        "    best_train_precision = 0.0\n",
        "    best_model = None\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        model.train()\n",
        "        train_loss, train_acc, train_recall, train_precision, train_f1 = train_epoch(model, optimizer, criterion, train_loader, scheduler)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss, val_acc, val_recall, val_precision, val_f1 = eval_epoch(model, criterion, val_loader)\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}\")\n",
        "\n",
        "        # Save the best model based on validation F1 score\n",
        "        if val_f1 > best_val_f1:\n",
        "            best_epoch = epoch+1\n",
        "            best_train_cost = train_loss\n",
        "            best_train_f1 = train_f1\n",
        "            best_train_recall = train_recall\n",
        "            best_train_precision = train_precision\n",
        "            best_val_cost = val_loss\n",
        "            best_val_f1 = val_f1\n",
        "            best_val_recall = val_recall\n",
        "            best_val_precision = val_precision\n",
        "            best_model = deepcopy(model.state_dict())\n",
        "\n",
        "    # Load the best model parameters and return the trained model\n",
        "\n",
        "    model.load_state_dict(best_model)\n",
        "    model_stat = {'best_epoch' : best_epoch,\n",
        "                  'best_train_cost' : best_train_cost,\n",
        "                'best_train_f1': best_train_f1,\n",
        "                'best_train_recall': best_train_recall,\n",
        "                'best_train_precision': best_train_precision,\n",
        "                'best_val_cost' : best_val_cost,\n",
        "                'best_val_f1': best_val_f1,\n",
        "                'best_val_recall': best_val_recall,\n",
        "                'best_val_precision': best_val_precision}\n",
        "\n",
        "    return model, model_stat\n",
        "\n",
        "\n",
        "def train_epoch(model, optimizer, criterion, train_loader, scheduler):\n",
        "    n_obs = len(train_loader.dataset)\n",
        "    train_loss = 0.0\n",
        "    train_correct = 0\n",
        "    train_recall_total = 0.0\n",
        "    train_precision_total = 0.0\n",
        "    train_f1_total = 0.0\n",
        "\n",
        "    preds_all = []\n",
        "    targets_all = []\n",
        "\n",
        "    for data, target in train_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item() * data.size(0)\n",
        "\n",
        "        output = F.softmax(output, dim=1)\n",
        "        _, preds = torch.max(output, 1)\n",
        "        target = torch.argmax(target, dim=1)\n",
        "\n",
        "        preds_all.append(preds)\n",
        "        targets_all.append(target)\n",
        "    \n",
        "    scheduler.step()\n",
        "\n",
        "    # Stack all into tensor\n",
        "    preds = torch.cat(preds_all, dim=0)\n",
        "    target = torch.cat(targets_all, dim=0)\n",
        "\n",
        "    train_loss /= n_obs\n",
        "    train_acc = torch.sum(preds == target.data).double() / n_obs\n",
        "\n",
        "    train_recall = recall_score(target.data.cpu().numpy(), preds.cpu().numpy(), average='weighted')\n",
        "    train_precision = precision_score(target.data.cpu().numpy(), preds.cpu().numpy(), average='weighted')\n",
        "    train_f1 = f1_score(target.data.cpu().numpy(), preds.cpu().numpy(), average='weighted')\n",
        "\n",
        "    return train_loss, train_acc, train_recall, train_precision, train_f1\n",
        "\n",
        "\n",
        "def eval_epoch(model, criterion, val_loader):\n",
        "    n_obs = len(val_loader.dataset)\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_recall_total = 0.0\n",
        "    val_precision_total = 0.0\n",
        "    val_f1_total = 0.0\n",
        "\n",
        "    preds_all = []\n",
        "    targets_all = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in val_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            val_loss += loss.item() * data.size(0)\n",
        "\n",
        "            output = F.softmax(output, dim=1)\n",
        "            target = torch.argmax(target, dim=1)\n",
        "            _, preds = torch.max(output, 1)\n",
        "\n",
        "            preds_all.append(preds)\n",
        "            targets_all.append(target)\n",
        "        \n",
        "        preds = torch.cat(preds_all, dim=0)\n",
        "        target = torch.cat(targets_all, dim=0)\n",
        "\n",
        "        val_loss /= n_obs\n",
        "        val_acc = torch.sum(preds == target.data).double() / n_obs\n",
        "\n",
        "        val_recall = recall_score(target.data.cpu().numpy(), preds.cpu().numpy(), average='weighted')\n",
        "        val_precision = precision_score(target.data.cpu().numpy(), preds.cpu().numpy(), average='weighted')\n",
        "        val_f1 = f1_score(target.data.cpu().numpy(), preds.cpu().numpy(), average='weighted')\n",
        "\n",
        "    return val_loss, val_acc, val_recall,val_precision,val_f1"
      ],
      "metadata": {
        "id": "d7VZDrXhkjU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we don't know what should be the num_epochs we trained for each of sequence model, so the experiment_0, will look at the benchmark, and will be set for the next experiment\n",
        "\n",
        "Note that CosineAnnealingLR is used as the default lr_scheduler which will set learning rate (\\eta) per epoch like the following equation\n",
        "\n",
        "$$\\eta_{t+1} = \\eta_{min} + \\frac{1}{2}(\\eta_{max} - \\eta_{min})(1 + \\cos(\\frac{T_{max}}{T_{cur}}\\pi)), \\ \\ T_{cur} \\neq (2k+1)T_{max};$$\n",
        "\n",
        "$$\\eta_{t+1} = \\eta_{t} + \\frac{1}{2}(\\eta_{max} - \\eta_{min})(1 - \\cos(\\frac{T_{max}}{1}\\pi)), \\ \\ T_{cur} = (2k+1)T_{max}.$$\n",
        "\n",
        "where\n",
        "\n",
        "$$\\eta_{t} = \\eta_{min} + \\frac{1}{2}(\\eta_{max} - \\eta_{min})(1 + \\cos(\\frac{T_{max}}{T_{cur}}\\pi))$$\n",
        "\n",
        "The idea behind using this learning rate scheduler, because we found that it is unnecessary to let the learning rate always shrinking\n",
        "\n",
        "Here's some visual guide:\n",
        "\n",
        "![](https://discuss.pytorch.org/uploads/default/original/3X/4/d/4de6d50a138c7a17184d147099687881d51eb9d1.png)\n",
        "\n",
        "the use of a cosine curve in the learning rate schedule ensures that the learning rate is decreased smoothly and gradually, avoiding abrupt changes that could lead to instability or poor convergence during training. Overall, the CosineAnnealingLR learning rate schedule has proven to be a effective method for training deep neural networks and is widely used in the deep learning community. You can use ither learning rate scheduler as well, but I (Run) decided not to use in the first 4 experiments"
      ],
      "metadata": {
        "id": "kGIord5T3SS8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us start the new experiment"
      ],
      "metadata": {
        "id": "Uc-5ue1HyzVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "# Define the hyperparameters to search over\n",
        "def experiment_0(benchmark):\n",
        "\n",
        "    \"\"\"\n",
        "    Test which epoch the sequence model gru,lstm is surpass the zero baseline\n",
        "    \"\"\"\n",
        "\n",
        "    name = ['gru']\n",
        "    weight_decay = [1e-2]\n",
        "    lr = [7e-4,5e-4,1e-4] # Initial guess lr\n",
        "    batch_size = [128]\n",
        "\n",
        "    # For lstm and gru only\n",
        "    hidden_sizes = [32]\n",
        "    num_layers_list = [1]\n",
        "\n",
        "    # Create a Cartesian product of all hyperparameter combinations\n",
        "    hyperparams = list(itertools.product(name, weight_decay, lr, batch_size, hidden_sizes, num_layers_list))\n",
        "    print(f'grid search : perform {len(hyperparams)} searchs')\n",
        "\n",
        "    # Loop over each combination of hyperparameters and train/evaluate the model\n",
        "    best_val_f1 = 0.0\n",
        "    num_epochs = 50\n",
        "    for i, (name, wd, lr, bs, hidden_size, num_layers) in enumerate(hyperparams):\n",
        "\n",
        "        print(f'\\n üîé search {i} : {name} --- hidden_size : {hidden_size}, num_layers : {num_layers}, lr : {lr}, weight_decay : {wd}, batch_size : {bs}')\n",
        "\n",
        "        # Setup Device\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        # Create the model, optimizer, and loss function\n",
        "        model = get_architecture(name = name, device = device, hidden_size=hidden_size, num_layers=num_layers)\n",
        "        class_weights_normalized = get_weighted_for_ce(y_train)\n",
        "        criterion = nn.CrossEntropyLoss(weight=class_weights_normalized.to(device))\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), weight_decay=wd)\n",
        "\n",
        "        # Create the data loaders\n",
        "        train_loader, val_loader, test_loader = get_loader(train_set, val_set, test_set, train_batch_size=bs)\n",
        "\n",
        "        # Train and evaluate the model\n",
        "        scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=0)\n",
        "        model, model_stat = train(model, optimizer, scheduler, criterion, train_loader, val_loader, num_epochs)\n",
        "\n",
        "        \n",
        "        # save the best model configuration based on validation F1 score\n",
        "        if model_stat['best_val_f1'] > best_val_f1:\n",
        "            best_val_f1 = model_stat['best_val_f1']\n",
        "            best_model = deepcopy(model.state_dict())\n",
        "        \n",
        "        row = {'model_name' : name,\n",
        "            'hyperparameter' : {'weight_decay' : wd, 'learning_rate' : lr,\n",
        "                                'batch_size' : bs, 'hidden_size' : hidden_size,\n",
        "                                'num_layers' : num_layers},\n",
        "            'best_epoch' : model_stat['best_epoch'],\n",
        "            'best_train_cost' : model_stat['best_train_cost'],\n",
        "            'best_val_cost' : model_stat['best_val_cost'],\n",
        "            'best_train_recall' : model_stat['best_train_recall'],\n",
        "            'best_train_precision' : model_stat['best_train_precision'],\n",
        "            'best_train_f1' : model_stat['best_train_f1'],\n",
        "            'best_val_recall' : model_stat['best_val_recall'],\n",
        "            'best_val_precision' : model_stat['best_val_precision'],\n",
        "            'best_val_f1' : model_stat['best_val_f1'],\n",
        "            'best_test_recall' : None,\n",
        "            'best_test_precision' : None,\n",
        "            'best_test_f1' : None,\n",
        "            }\n",
        "\n",
        "        benchmark =benchmark.append(row, ignore_index=True)\n",
        "\n",
        "    return benchmark, best_model"
      ],
      "metadata": {
        "id": "q69tlDwo2xrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## For new user, you can uncomment to append the result of the experiment_0 to your benchmark\n",
        "\n",
        "#benchmark, best_model = experiment_0(benchmark)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0dbQbFW3MF7",
        "outputId": "83866d0e-aff3-4f70-92aa-e0277626f740"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grid search : perform 3 searchs\n",
            "\n",
            " üîé search 0 : gru --- hidden_size : 32, num_layers : 1, lr : 0.0007, weight_decay : 0.01, batch_size : 128\n",
            "Epoch: 1/50, Train Loss: 8.0449, Train Acc: 0.0942, Train F1: 0.0579, Val Loss: 8.0292, Val Acc: 0.0774, Val F1: 0.0166\n",
            "Epoch: 2/50, Train Loss: 8.0079, Train Acc: 0.2367, Train F1: 0.2059, Val Loss: 7.8882, Val Acc: 0.0901, Val F1: 0.0361\n",
            "Epoch: 3/50, Train Loss: 7.8080, Train Acc: 0.0704, Train F1: 0.0774, Val Loss: 7.9232, Val Acc: 0.0271, Val F1: 0.0321\n",
            "Epoch: 4/50, Train Loss: 7.5714, Train Acc: 0.2347, Train F1: 0.2474, Val Loss: 7.0832, Val Acc: 0.1208, Val F1: 0.1149\n",
            "Epoch: 5/50, Train Loss: 6.9415, Train Acc: 0.1681, Train F1: 0.1878, Val Loss: 6.8809, Val Acc: 0.1719, Val F1: 0.2056\n",
            "Epoch: 6/50, Train Loss: 6.7422, Train Acc: 0.2046, Train F1: 0.2386, Val Loss: 6.6469, Val Acc: 0.2475, Val F1: 0.2952\n",
            "Epoch: 7/50, Train Loss: 6.6669, Train Acc: 0.2367, Train F1: 0.2846, Val Loss: 6.5378, Val Acc: 0.2776, Val F1: 0.3343\n",
            "Epoch: 8/50, Train Loss: 6.5574, Train Acc: 0.2608, Train F1: 0.3169, Val Loss: 6.3582, Val Acc: 0.2628, Val F1: 0.3148\n",
            "Epoch: 9/50, Train Loss: 6.4183, Train Acc: 0.2819, Train F1: 0.3446, Val Loss: 6.3294, Val Acc: 0.2598, Val F1: 0.3195\n",
            "Epoch: 10/50, Train Loss: 6.3181, Train Acc: 0.3020, Train F1: 0.3690, Val Loss: 6.1338, Val Acc: 0.3112, Val F1: 0.3794\n",
            "Epoch: 11/50, Train Loss: 6.2628, Train Acc: 0.3142, Train F1: 0.3838, Val Loss: 6.4416, Val Acc: 0.2761, Val F1: 0.3472\n",
            "Epoch: 12/50, Train Loss: 6.5052, Train Acc: 0.2891, Train F1: 0.3563, Val Loss: 6.2087, Val Acc: 0.3004, Val F1: 0.3711\n",
            "Epoch: 13/50, Train Loss: 6.2038, Train Acc: 0.3190, Train F1: 0.3894, Val Loss: 6.1480, Val Acc: 0.3139, Val F1: 0.3871\n",
            "Epoch: 14/50, Train Loss: 6.1742, Train Acc: 0.3170, Train F1: 0.3862, Val Loss: 9.8478, Val Acc: 0.0705, Val F1: 0.0504\n",
            "Epoch: 15/50, Train Loss: 8.4234, Train Acc: 0.0650, Train F1: 0.0311, Val Loss: 8.0012, Val Acc: 0.0651, Val F1: 0.0119\n",
            "Epoch: 16/50, Train Loss: 8.0003, Train Acc: 0.0827, Train F1: 0.0514, Val Loss: 7.9791, Val Acc: 0.0832, Val F1: 0.0234\n",
            "Epoch: 17/50, Train Loss: 7.9144, Train Acc: 0.0979, Train F1: 0.0729, Val Loss: 7.5907, Val Acc: 0.0975, Val F1: 0.0487\n",
            "Epoch: 18/50, Train Loss: 7.1662, Train Acc: 0.1591, Train F1: 0.1594, Val Loss: 6.5674, Val Acc: 0.1600, Val F1: 0.1652\n",
            "Epoch: 19/50, Train Loss: 6.4345, Train Acc: 0.2070, Train F1: 0.2419, Val Loss: 6.2616, Val Acc: 0.2292, Val F1: 0.2739\n",
            "Epoch: 20/50, Train Loss: 6.2824, Train Acc: 0.2379, Train F1: 0.2835, Val Loss: 6.2718, Val Acc: 0.2559, Val F1: 0.3146\n",
            "Epoch: 21/50, Train Loss: 6.2107, Train Acc: 0.2564, Train F1: 0.3081, Val Loss: 6.0922, Val Acc: 0.2325, Val F1: 0.2730\n",
            "Epoch: 22/50, Train Loss: 6.1050, Train Acc: 0.2420, Train F1: 0.2860, Val Loss: 5.9204, Val Acc: 0.2398, Val F1: 0.2806\n",
            "Epoch: 23/50, Train Loss: 6.0617, Train Acc: 0.2385, Train F1: 0.2811, Val Loss: 6.1670, Val Acc: 0.2013, Val F1: 0.2367\n",
            "Epoch: 24/50, Train Loss: 6.0187, Train Acc: 0.2460, Train F1: 0.2925, Val Loss: 5.8399, Val Acc: 0.2757, Val F1: 0.3344\n",
            "Epoch: 25/50, Train Loss: 5.9240, Train Acc: 0.2826, Train F1: 0.3432, Val Loss: 6.0248, Val Acc: 0.2340, Val F1: 0.2826\n",
            "Epoch: 26/50, Train Loss: 5.9001, Train Acc: 0.2635, Train F1: 0.3163, Val Loss: 5.7428, Val Acc: 0.2341, Val F1: 0.2686\n",
            "Epoch: 27/50, Train Loss: 5.8283, Train Acc: 0.3079, Train F1: 0.3774, Val Loss: 5.6294, Val Acc: 0.3039, Val F1: 0.3688\n",
            "Epoch: 28/50, Train Loss: 5.7397, Train Acc: 0.3202, Train F1: 0.3929, Val Loss: 5.7482, Val Acc: 0.2812, Val F1: 0.3468\n",
            "Epoch: 29/50, Train Loss: 5.7425, Train Acc: 0.2907, Train F1: 0.3523, Val Loss: 6.1907, Val Acc: 0.3444, Val F1: 0.4238\n",
            "Epoch: 30/50, Train Loss: 6.1574, Train Acc: 0.2403, Train F1: 0.2746, Val Loss: 5.6990, Val Acc: 0.2220, Val F1: 0.2508\n",
            "Epoch: 31/50, Train Loss: 5.7371, Train Acc: 0.2408, Train F1: 0.2795, Val Loss: 5.7824, Val Acc: 0.2476, Val F1: 0.2971\n",
            "Epoch: 32/50, Train Loss: 5.6921, Train Acc: 0.2556, Train F1: 0.3014, Val Loss: 5.6064, Val Acc: 0.2536, Val F1: 0.2954\n",
            "Epoch: 33/50, Train Loss: 5.6772, Train Acc: 0.2767, Train F1: 0.3295, Val Loss: 5.5580, Val Acc: 0.3141, Val F1: 0.3773\n",
            "Epoch: 34/50, Train Loss: 5.6754, Train Acc: 0.3130, Train F1: 0.3770, Val Loss: 5.5390, Val Acc: 0.3551, Val F1: 0.4271\n",
            "Epoch: 35/50, Train Loss: 5.6021, Train Acc: 0.3376, Train F1: 0.4094, Val Loss: 5.4852, Val Acc: 0.3383, Val F1: 0.4095\n",
            "Epoch: 36/50, Train Loss: 5.5716, Train Acc: 0.3469, Train F1: 0.4226, Val Loss: 5.5408, Val Acc: 0.3510, Val F1: 0.4226\n",
            "Epoch: 37/50, Train Loss: 5.5651, Train Acc: 0.3359, Train F1: 0.4077, Val Loss: 5.5162, Val Acc: 0.3257, Val F1: 0.3921\n",
            "Epoch: 38/50, Train Loss: 5.5773, Train Acc: 0.3386, Train F1: 0.4116, Val Loss: 5.4861, Val Acc: 0.3639, Val F1: 0.4415\n",
            "Epoch: 39/50, Train Loss: 5.5371, Train Acc: 0.3460, Train F1: 0.4210, Val Loss: 5.4635, Val Acc: 0.3518, Val F1: 0.4284\n",
            "Epoch: 40/50, Train Loss: 5.5161, Train Acc: 0.3513, Train F1: 0.4272, Val Loss: 5.4852, Val Acc: 0.3594, Val F1: 0.4340\n",
            "Epoch: 41/50, Train Loss: 5.5076, Train Acc: 0.3568, Train F1: 0.4338, Val Loss: 5.5095, Val Acc: 0.3730, Val F1: 0.4512\n",
            "Epoch: 42/50, Train Loss: 5.5183, Train Acc: 0.3514, Train F1: 0.4273, Val Loss: 5.4256, Val Acc: 0.3614, Val F1: 0.4386\n",
            "Epoch: 43/50, Train Loss: 5.4922, Train Acc: 0.3585, Train F1: 0.4359, Val Loss: 5.4227, Val Acc: 0.3491, Val F1: 0.4215\n",
            "Epoch: 44/50, Train Loss: 5.4927, Train Acc: 0.3576, Train F1: 0.4349, Val Loss: 5.4253, Val Acc: 0.3557, Val F1: 0.4313\n",
            "Epoch: 45/50, Train Loss: 5.4845, Train Acc: 0.3652, Train F1: 0.4444, Val Loss: 5.4168, Val Acc: 0.3656, Val F1: 0.4432\n",
            "Epoch: 46/50, Train Loss: 5.4792, Train Acc: 0.3654, Train F1: 0.4442, Val Loss: 5.4120, Val Acc: 0.3585, Val F1: 0.4337\n",
            "Epoch: 47/50, Train Loss: 5.4760, Train Acc: 0.3617, Train F1: 0.4395, Val Loss: 5.4140, Val Acc: 0.3610, Val F1: 0.4372\n",
            "Epoch: 48/50, Train Loss: 5.4743, Train Acc: 0.3638, Train F1: 0.4425, Val Loss: 5.4116, Val Acc: 0.3636, Val F1: 0.4394\n",
            "Epoch: 49/50, Train Loss: 5.4737, Train Acc: 0.3615, Train F1: 0.4389, Val Loss: 5.4127, Val Acc: 0.3619, Val F1: 0.4383\n",
            "Epoch: 50/50, Train Loss: 5.4708, Train Acc: 0.3625, Train F1: 0.4407, Val Loss: 5.4112, Val Acc: 0.3619, Val F1: 0.4381\n",
            "\n",
            " üîé search 1 : gru --- hidden_size : 32, num_layers : 1, lr : 0.0005, weight_decay : 0.01, batch_size : 128\n",
            "Epoch: 1/50, Train Loss: 8.0484, Train Acc: 0.4662, Train F1: 0.4123, Val Loss: 8.0320, Val Acc: 0.0103, Val F1: 0.0046\n",
            "Epoch: 2/50, Train Loss: 7.9585, Train Acc: 0.1255, Train F1: 0.0939, Val Loss: 7.7695, Val Acc: 0.0212, Val F1: 0.0092\n",
            "Epoch: 3/50, Train Loss: 7.6836, Train Acc: 0.0865, Train F1: 0.0994, Val Loss: 7.1616, Val Acc: 0.0850, Val F1: 0.0641\n",
            "Epoch: 4/50, Train Loss: 7.1001, Train Acc: 0.1410, Train F1: 0.1498, Val Loss: 6.9671, Val Acc: 0.1614, Val F1: 0.1806\n",
            "Epoch: 5/50, Train Loss: 6.9525, Train Acc: 0.1962, Train F1: 0.2334, Val Loss: 6.7473, Val Acc: 0.2122, Val F1: 0.2521\n",
            "Epoch: 6/50, Train Loss: 6.8919, Train Acc: 0.1963, Train F1: 0.2347, Val Loss: 6.7096, Val Acc: 0.2349, Val F1: 0.2819\n",
            "Epoch: 7/50, Train Loss: 6.7721, Train Acc: 0.2365, Train F1: 0.2891, Val Loss: 6.6730, Val Acc: 0.2414, Val F1: 0.2977\n",
            "Epoch: 8/50, Train Loss: 6.7261, Train Acc: 0.2435, Train F1: 0.2987, Val Loss: 6.7076, Val Acc: 0.2249, Val F1: 0.2803\n",
            "Epoch: 9/50, Train Loss: 6.6309, Train Acc: 0.2631, Train F1: 0.3230, Val Loss: 6.5349, Val Acc: 0.2559, Val F1: 0.3148\n",
            "Epoch: 10/50, Train Loss: 6.5558, Train Acc: 0.2835, Train F1: 0.3486, Val Loss: 6.3703, Val Acc: 0.2930, Val F1: 0.3567\n",
            "Epoch: 11/50, Train Loss: 6.4376, Train Acc: 0.3062, Train F1: 0.3771, Val Loss: 6.6565, Val Acc: 0.2052, Val F1: 0.2562\n",
            "Epoch: 12/50, Train Loss: 8.3372, Train Acc: 0.0376, Train F1: 0.0535, Val Loss: 7.8584, Val Acc: 0.0845, Val F1: 0.1371\n",
            "Epoch: 13/50, Train Loss: 7.8358, Train Acc: 0.1422, Train F1: 0.1845, Val Loss: 7.7824, Val Acc: 0.0814, Val F1: 0.1281\n",
            "Epoch: 14/50, Train Loss: 7.7373, Train Acc: 0.1145, Train F1: 0.1506, Val Loss: 7.6777, Val Acc: 0.0783, Val F1: 0.1010\n",
            "Epoch: 15/50, Train Loss: 6.9583, Train Acc: 0.1708, Train F1: 0.2010, Val Loss: 6.4353, Val Acc: 0.2303, Val F1: 0.2785\n",
            "Epoch: 16/50, Train Loss: 6.3986, Train Acc: 0.2416, Train F1: 0.2875, Val Loss: 6.3068, Val Acc: 0.2802, Val F1: 0.3345\n",
            "Epoch: 17/50, Train Loss: 6.2991, Train Acc: 0.3017, Train F1: 0.3688, Val Loss: 6.1446, Val Acc: 0.3415, Val F1: 0.4187\n",
            "Epoch: 18/50, Train Loss: 6.2271, Train Acc: 0.3344, Train F1: 0.4084, Val Loss: 6.0643, Val Acc: 0.3342, Val F1: 0.4052\n",
            "Epoch: 19/50, Train Loss: 6.2036, Train Acc: 0.3447, Train F1: 0.4201, Val Loss: 6.0219, Val Acc: 0.3659, Val F1: 0.4448\n",
            "Epoch: 20/50, Train Loss: 6.1822, Train Acc: 0.3498, Train F1: 0.4261, Val Loss: 6.0413, Val Acc: 0.3873, Val F1: 0.4665\n",
            "Epoch: 21/50, Train Loss: 6.1697, Train Acc: 0.3574, Train F1: 0.4341, Val Loss: 6.0052, Val Acc: 0.3307, Val F1: 0.4008\n",
            "Epoch: 22/50, Train Loss: 6.1522, Train Acc: 0.3497, Train F1: 0.4252, Val Loss: 5.9583, Val Acc: 0.3682, Val F1: 0.4439\n",
            "Epoch: 23/50, Train Loss: 6.1218, Train Acc: 0.3532, Train F1: 0.4297, Val Loss: 6.0038, Val Acc: 0.3294, Val F1: 0.4030\n",
            "Epoch: 24/50, Train Loss: 6.1065, Train Acc: 0.3617, Train F1: 0.4393, Val Loss: 5.9609, Val Acc: 0.4013, Val F1: 0.4861\n",
            "Epoch: 25/50, Train Loss: 6.0850, Train Acc: 0.3692, Train F1: 0.4486, Val Loss: 6.0014, Val Acc: 0.3620, Val F1: 0.4416\n",
            "Epoch: 26/50, Train Loss: 6.0538, Train Acc: 0.3842, Train F1: 0.4649, Val Loss: 5.8963, Val Acc: 0.3888, Val F1: 0.4702\n",
            "Epoch: 27/50, Train Loss: 6.0561, Train Acc: 0.3742, Train F1: 0.4538, Val Loss: 5.9829, Val Acc: 0.3813, Val F1: 0.4586\n",
            "Epoch: 28/50, Train Loss: 6.0345, Train Acc: 0.3776, Train F1: 0.4571, Val Loss: 5.8934, Val Acc: 0.3926, Val F1: 0.4730\n",
            "Epoch: 29/50, Train Loss: 6.0351, Train Acc: 0.3843, Train F1: 0.4659, Val Loss: 5.9424, Val Acc: 0.3948, Val F1: 0.4816\n",
            "Epoch: 30/50, Train Loss: 6.0085, Train Acc: 0.3720, Train F1: 0.4520, Val Loss: 5.8847, Val Acc: 0.4036, Val F1: 0.4850\n",
            "Epoch: 31/50, Train Loss: 5.9835, Train Acc: 0.3926, Train F1: 0.4746, Val Loss: 6.0932, Val Acc: 0.4509, Val F1: 0.5416\n",
            "Epoch: 32/50, Train Loss: 6.0052, Train Acc: 0.3978, Train F1: 0.4796, Val Loss: 6.0239, Val Acc: 0.3848, Val F1: 0.4699\n",
            "Epoch: 33/50, Train Loss: 5.9948, Train Acc: 0.3378, Train F1: 0.4119, Val Loss: 5.8337, Val Acc: 0.3541, Val F1: 0.4295\n",
            "Epoch: 34/50, Train Loss: 5.9712, Train Acc: 0.3624, Train F1: 0.4405, Val Loss: 5.8374, Val Acc: 0.3638, Val F1: 0.4412\n",
            "Epoch: 35/50, Train Loss: 5.9543, Train Acc: 0.3755, Train F1: 0.4560, Val Loss: 5.8470, Val Acc: 0.3882, Val F1: 0.4714\n",
            "Epoch: 36/50, Train Loss: 5.9433, Train Acc: 0.3902, Train F1: 0.4721, Val Loss: 5.8505, Val Acc: 0.3594, Val F1: 0.4328\n",
            "Epoch: 37/50, Train Loss: 5.9366, Train Acc: 0.3898, Train F1: 0.4719, Val Loss: 5.8119, Val Acc: 0.3778, Val F1: 0.4557\n",
            "Epoch: 38/50, Train Loss: 5.9343, Train Acc: 0.3936, Train F1: 0.4757, Val Loss: 5.8698, Val Acc: 0.3668, Val F1: 0.4465\n",
            "Epoch: 39/50, Train Loss: 5.9251, Train Acc: 0.3911, Train F1: 0.4733, Val Loss: 5.7967, Val Acc: 0.4003, Val F1: 0.4830\n",
            "Epoch: 40/50, Train Loss: 5.9178, Train Acc: 0.3909, Train F1: 0.4732, Val Loss: 5.7986, Val Acc: 0.3986, Val F1: 0.4814\n",
            "Epoch: 41/50, Train Loss: 5.9126, Train Acc: 0.3937, Train F1: 0.4757, Val Loss: 5.7945, Val Acc: 0.3933, Val F1: 0.4754\n",
            "Epoch: 42/50, Train Loss: 5.9061, Train Acc: 0.3926, Train F1: 0.4752, Val Loss: 5.7919, Val Acc: 0.3864, Val F1: 0.4665\n",
            "Epoch: 43/50, Train Loss: 5.9028, Train Acc: 0.3958, Train F1: 0.4787, Val Loss: 5.7861, Val Acc: 0.3936, Val F1: 0.4752\n",
            "Epoch: 44/50, Train Loss: 5.8995, Train Acc: 0.3948, Train F1: 0.4777, Val Loss: 5.7935, Val Acc: 0.3968, Val F1: 0.4789\n",
            "Epoch: 45/50, Train Loss: 5.8969, Train Acc: 0.3937, Train F1: 0.4759, Val Loss: 5.7862, Val Acc: 0.3877, Val F1: 0.4679\n",
            "Epoch: 46/50, Train Loss: 5.8926, Train Acc: 0.3972, Train F1: 0.4804, Val Loss: 5.7893, Val Acc: 0.3817, Val F1: 0.4608\n",
            "Epoch: 47/50, Train Loss: 5.8896, Train Acc: 0.3934, Train F1: 0.4757, Val Loss: 5.7807, Val Acc: 0.3880, Val F1: 0.4682\n",
            "Epoch: 48/50, Train Loss: 5.8922, Train Acc: 0.3910, Train F1: 0.4728, Val Loss: 5.7798, Val Acc: 0.3920, Val F1: 0.4732\n",
            "Epoch: 49/50, Train Loss: 5.8871, Train Acc: 0.3952, Train F1: 0.4780, Val Loss: 5.7801, Val Acc: 0.3922, Val F1: 0.4736\n",
            "Epoch: 50/50, Train Loss: 5.8864, Train Acc: 0.3952, Train F1: 0.4782, Val Loss: 5.7802, Val Acc: 0.3921, Val F1: 0.4735\n",
            "\n",
            " üîé search 2 : gru --- hidden_size : 32, num_layers : 1, lr : 0.0001, weight_decay : 0.01, batch_size : 128\n",
            "Epoch: 1/50, Train Loss: 8.0567, Train Acc: 0.0083, Train F1: 0.0015, Val Loss: 8.0462, Val Acc: 0.0090, Val F1: 0.0029\n",
            "Epoch: 2/50, Train Loss: 8.0458, Train Acc: 0.0102, Train F1: 0.0040, Val Loss: 8.0403, Val Acc: 0.0101, Val F1: 0.0042\n",
            "Epoch: 3/50, Train Loss: 8.0413, Train Acc: 0.0153, Train F1: 0.0041, Val Loss: 8.0369, Val Acc: 0.0102, Val F1: 0.0043\n",
            "Epoch: 4/50, Train Loss: 8.0376, Train Acc: 0.0161, Train F1: 0.0046, Val Loss: 8.0332, Val Acc: 0.0104, Val F1: 0.0044\n",
            "Epoch: 5/50, Train Loss: 8.0335, Train Acc: 0.0120, Train F1: 0.0045, Val Loss: 8.0287, Val Acc: 0.0105, Val F1: 0.0044\n",
            "Epoch: 6/50, Train Loss: 8.0277, Train Acc: 0.2339, Train F1: 0.2052, Val Loss: 8.0224, Val Acc: 0.0106, Val F1: 0.0042\n",
            "Epoch: 7/50, Train Loss: 8.0199, Train Acc: 0.0501, Train F1: 0.0098, Val Loss: 8.0121, Val Acc: 0.0111, Val F1: 0.0056\n",
            "Epoch: 8/50, Train Loss: 8.0030, Train Acc: 0.0284, Train F1: 0.0119, Val Loss: 7.9848, Val Acc: 0.0773, Val F1: 0.0153\n",
            "Epoch: 9/50, Train Loss: 7.9275, Train Acc: 0.0432, Train F1: 0.0119, Val Loss: 7.8396, Val Acc: 0.0789, Val F1: 0.0175\n",
            "Epoch: 10/50, Train Loss: 7.8193, Train Acc: 0.0572, Train F1: 0.0177, Val Loss: 7.7653, Val Acc: 0.0301, Val F1: 0.0246\n",
            "Epoch: 11/50, Train Loss: 7.7501, Train Acc: 0.0583, Train F1: 0.0548, Val Loss: 7.6450, Val Acc: 0.0736, Val F1: 0.0709\n",
            "Epoch: 12/50, Train Loss: 7.5063, Train Acc: 0.0726, Train F1: 0.0543, Val Loss: 7.3892, Val Acc: 0.0741, Val F1: 0.0598\n",
            "Epoch: 13/50, Train Loss: 7.1786, Train Acc: 0.0933, Train F1: 0.0713, Val Loss: 7.0320, Val Acc: 0.1339, Val F1: 0.1173\n",
            "Epoch: 14/50, Train Loss: 7.0546, Train Acc: 0.1306, Train F1: 0.1165, Val Loss: 6.9328, Val Acc: 0.1372, Val F1: 0.1262\n",
            "Epoch: 15/50, Train Loss: 6.9993, Train Acc: 0.1430, Train F1: 0.1388, Val Loss: 6.9006, Val Acc: 0.1467, Val F1: 0.1408\n",
            "Epoch: 16/50, Train Loss: 6.9722, Train Acc: 0.1605, Train F1: 0.1676, Val Loss: 6.8739, Val Acc: 0.1748, Val F1: 0.1897\n",
            "Epoch: 17/50, Train Loss: 6.9313, Train Acc: 0.1728, Train F1: 0.1871, Val Loss: 6.8854, Val Acc: 0.1889, Val F1: 0.2132\n",
            "Epoch: 18/50, Train Loss: 6.9081, Train Acc: 0.1826, Train F1: 0.2023, Val Loss: 6.8357, Val Acc: 0.1805, Val F1: 0.1967\n",
            "Epoch: 19/50, Train Loss: 6.8931, Train Acc: 0.1928, Train F1: 0.2184, Val Loss: 6.8488, Val Acc: 0.1795, Val F1: 0.1942\n",
            "Epoch: 20/50, Train Loss: 6.8701, Train Acc: 0.2003, Train F1: 0.2296, Val Loss: 6.8046, Val Acc: 0.2065, Val F1: 0.2379\n",
            "Epoch: 21/50, Train Loss: 6.8745, Train Acc: 0.1977, Train F1: 0.2254, Val Loss: 6.8133, Val Acc: 0.1917, Val F1: 0.2134\n",
            "Epoch: 22/50, Train Loss: 6.8528, Train Acc: 0.2024, Train F1: 0.2323, Val Loss: 6.8309, Val Acc: 0.1897, Val F1: 0.2096\n",
            "Epoch: 23/50, Train Loss: 6.8546, Train Acc: 0.2079, Train F1: 0.2410, Val Loss: 6.7775, Val Acc: 0.2020, Val F1: 0.2296\n",
            "Epoch: 24/50, Train Loss: 6.8313, Train Acc: 0.2083, Train F1: 0.2411, Val Loss: 6.7802, Val Acc: 0.1991, Val F1: 0.2248\n",
            "Epoch: 25/50, Train Loss: 6.8348, Train Acc: 0.2093, Train F1: 0.2430, Val Loss: 6.8504, Val Acc: 0.2084, Val F1: 0.2447\n",
            "Epoch: 26/50, Train Loss: 6.8391, Train Acc: 0.2082, Train F1: 0.2416, Val Loss: 6.8568, Val Acc: 0.2025, Val F1: 0.2366\n",
            "Epoch: 27/50, Train Loss: 6.8274, Train Acc: 0.2076, Train F1: 0.2406, Val Loss: 6.7471, Val Acc: 0.2149, Val F1: 0.2500\n",
            "Epoch: 28/50, Train Loss: 6.7996, Train Acc: 0.2143, Train F1: 0.2508, Val Loss: 6.7484, Val Acc: 0.2212, Val F1: 0.2606\n",
            "Epoch: 29/50, Train Loss: 6.8011, Train Acc: 0.2138, Train F1: 0.2498, Val Loss: 6.7545, Val Acc: 0.2215, Val F1: 0.2617\n",
            "Epoch: 30/50, Train Loss: 6.7972, Train Acc: 0.2128, Train F1: 0.2488, Val Loss: 6.8333, Val Acc: 0.1978, Val F1: 0.2222\n",
            "Epoch: 31/50, Train Loss: 6.7893, Train Acc: 0.2164, Train F1: 0.2532, Val Loss: 6.7687, Val Acc: 0.2236, Val F1: 0.2662\n",
            "Epoch: 32/50, Train Loss: 6.7787, Train Acc: 0.2199, Train F1: 0.2590, Val Loss: 6.7238, Val Acc: 0.2175, Val F1: 0.2545\n",
            "Epoch: 33/50, Train Loss: 6.7730, Train Acc: 0.2171, Train F1: 0.2543, Val Loss: 6.7364, Val Acc: 0.2250, Val F1: 0.2667\n",
            "Epoch: 34/50, Train Loss: 6.7705, Train Acc: 0.2201, Train F1: 0.2587, Val Loss: 6.7215, Val Acc: 0.2250, Val F1: 0.2660\n",
            "Epoch: 35/50, Train Loss: 6.7660, Train Acc: 0.2208, Train F1: 0.2598, Val Loss: 6.7209, Val Acc: 0.2097, Val F1: 0.2420\n",
            "Epoch: 36/50, Train Loss: 6.7644, Train Acc: 0.2187, Train F1: 0.2566, Val Loss: 6.7165, Val Acc: 0.2247, Val F1: 0.2655\n",
            "Epoch: 37/50, Train Loss: 6.7550, Train Acc: 0.2186, Train F1: 0.2563, Val Loss: 6.7108, Val Acc: 0.2139, Val F1: 0.2484\n",
            "Epoch: 38/50, Train Loss: 6.7599, Train Acc: 0.2200, Train F1: 0.2588, Val Loss: 6.7075, Val Acc: 0.2223, Val F1: 0.2616\n",
            "Epoch: 39/50, Train Loss: 6.7520, Train Acc: 0.2204, Train F1: 0.2588, Val Loss: 6.7058, Val Acc: 0.2229, Val F1: 0.2624\n",
            "Epoch: 40/50, Train Loss: 6.7488, Train Acc: 0.2208, Train F1: 0.2591, Val Loss: 6.7150, Val Acc: 0.2257, Val F1: 0.2673\n",
            "Epoch: 41/50, Train Loss: 6.7454, Train Acc: 0.2207, Train F1: 0.2595, Val Loss: 6.7027, Val Acc: 0.2162, Val F1: 0.2520\n",
            "Epoch: 42/50, Train Loss: 6.7466, Train Acc: 0.2212, Train F1: 0.2598, Val Loss: 6.7107, Val Acc: 0.2257, Val F1: 0.2672\n",
            "Epoch: 43/50, Train Loss: 6.7450, Train Acc: 0.2212, Train F1: 0.2602, Val Loss: 6.7046, Val Acc: 0.2259, Val F1: 0.2670\n",
            "Epoch: 44/50, Train Loss: 6.7392, Train Acc: 0.2218, Train F1: 0.2611, Val Loss: 6.7006, Val Acc: 0.2160, Val F1: 0.2517\n",
            "Epoch: 45/50, Train Loss: 6.7417, Train Acc: 0.2215, Train F1: 0.2603, Val Loss: 6.7040, Val Acc: 0.2261, Val F1: 0.2675\n",
            "Epoch: 46/50, Train Loss: 6.7409, Train Acc: 0.2233, Train F1: 0.2635, Val Loss: 6.6993, Val Acc: 0.2229, Val F1: 0.2624\n",
            "Epoch: 47/50, Train Loss: 6.7395, Train Acc: 0.2219, Train F1: 0.2613, Val Loss: 6.6998, Val Acc: 0.2241, Val F1: 0.2642\n",
            "Epoch: 48/50, Train Loss: 6.7393, Train Acc: 0.2225, Train F1: 0.2624, Val Loss: 6.6986, Val Acc: 0.2219, Val F1: 0.2609\n",
            "Epoch: 49/50, Train Loss: 6.7387, Train Acc: 0.2216, Train F1: 0.2606, Val Loss: 6.6988, Val Acc: 0.2228, Val F1: 0.2622\n",
            "Epoch: 50/50, Train Loss: 6.7383, Train Acc: 0.2224, Train F1: 0.2619, Val Loss: 6.6988, Val Acc: 0.2230, Val F1: 0.2625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#benchmark\n",
        "\n",
        "# It seems to be enough to limit the num_epoch not far from epoch 45"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "i9tog6-o3KA0",
        "outputId": "70f7fd52-05a8-4bce-b85a-047d61eaedef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      model_name                                     hyperparameter  \\\n",
              "0  zero_baseline                                            seed=42   \n",
              "1            gru  {'weight_decay': 0.01, 'learning_rate': 0.0007...   \n",
              "2            gru  {'weight_decay': 0.01, 'learning_rate': 0.0005...   \n",
              "3            gru  {'weight_decay': 0.01, 'learning_rate': 0.0001...   \n",
              "\n",
              "   best_epoch best_train_cost best_val_cost  best_train_recall  \\\n",
              "0           1            None          None           0.827732   \n",
              "1          41        5.507615      5.509489           0.356842   \n",
              "2          31        5.983451      6.093212           0.392644   \n",
              "3          45        6.741659      6.704005           0.221518   \n",
              "\n",
              "   best_train_precision  best_train_f1  best_val_recall  best_val_precision  \\\n",
              "0              0.685140       0.749716         0.827722            0.685123   \n",
              "1              0.825692       0.433814         0.373018            0.824422   \n",
              "2              0.804989       0.474624         0.450866            0.816760   \n",
              "3              0.812764       0.260281         0.226141            0.816713   \n",
              "\n",
              "   best_val_f1 best_test_recall best_test_precision best_test_f1  \n",
              "0     0.749702         0.827608            0.684935     0.749543  \n",
              "1     0.451205             None                None         None  \n",
              "2     0.541596             None                None         None  \n",
              "3     0.267453             None                None         None  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-30c061b7-1be7-453c-9d44-ca97b88885bf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>hyperparameter</th>\n",
              "      <th>best_epoch</th>\n",
              "      <th>best_train_cost</th>\n",
              "      <th>best_val_cost</th>\n",
              "      <th>best_train_recall</th>\n",
              "      <th>best_train_precision</th>\n",
              "      <th>best_train_f1</th>\n",
              "      <th>best_val_recall</th>\n",
              "      <th>best_val_precision</th>\n",
              "      <th>best_val_f1</th>\n",
              "      <th>best_test_recall</th>\n",
              "      <th>best_test_precision</th>\n",
              "      <th>best_test_f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>zero_baseline</td>\n",
              "      <td>seed=42</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>0.827732</td>\n",
              "      <td>0.685140</td>\n",
              "      <td>0.749716</td>\n",
              "      <td>0.827722</td>\n",
              "      <td>0.685123</td>\n",
              "      <td>0.749702</td>\n",
              "      <td>0.827608</td>\n",
              "      <td>0.684935</td>\n",
              "      <td>0.749543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gru</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.0007...</td>\n",
              "      <td>41</td>\n",
              "      <td>5.507615</td>\n",
              "      <td>5.509489</td>\n",
              "      <td>0.356842</td>\n",
              "      <td>0.825692</td>\n",
              "      <td>0.433814</td>\n",
              "      <td>0.373018</td>\n",
              "      <td>0.824422</td>\n",
              "      <td>0.451205</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gru</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.0005...</td>\n",
              "      <td>31</td>\n",
              "      <td>5.983451</td>\n",
              "      <td>6.093212</td>\n",
              "      <td>0.392644</td>\n",
              "      <td>0.804989</td>\n",
              "      <td>0.474624</td>\n",
              "      <td>0.450866</td>\n",
              "      <td>0.816760</td>\n",
              "      <td>0.541596</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gru</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.0001...</td>\n",
              "      <td>45</td>\n",
              "      <td>6.741659</td>\n",
              "      <td>6.704005</td>\n",
              "      <td>0.221518</td>\n",
              "      <td>0.812764</td>\n",
              "      <td>0.260281</td>\n",
              "      <td>0.226141</td>\n",
              "      <td>0.816713</td>\n",
              "      <td>0.267453</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30c061b7-1be7-453c-9d44-ca97b88885bf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-30c061b7-1be7-453c-9d44-ca97b88885bf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-30c061b7-1be7-453c-9d44-ca97b88885bf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/99dac6621f6ae8c4/data_table.js\";\n\n      window.createDataTable({\n        data: [[{\n            'v': 0,\n            'f': \"0\",\n        },\n\"zero_baseline\",\n\"seed=42\",\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': 0.8277316683164547,\n            'f': \"0.8277316683164547\",\n        },\n{\n            'v': 0.6851397147339414,\n            'f': \"0.6851397147339414\",\n        },\n{\n            'v': 0.7497158654202581,\n            'f': \"0.7497158654202581\",\n        },\n{\n            'v': 0.8277216866919457,\n            'f': \"0.8277216866919457\",\n        },\n{\n            'v': 0.6851231906201596,\n            'f': \"0.6851231906201596\",\n        },\n{\n            'v': 0.7497018781455581,\n            'f': \"0.7497018781455581\",\n        },\n{\n            'v': 0.8276082587246483,\n            'f': \"0.8276082587246483\",\n        },\n{\n            'v': 0.6849354299092444,\n            'f': \"0.6849354299092444\",\n        },\n{\n            'v': 0.7495429358446977,\n            'f': \"0.7495429358446977\",\n        }],\n [{\n            'v': 1,\n            'f': \"1\",\n        },\n\"gru\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.0007, 'batch_size': 128, 'hidden_size': 32, 'num_layers': 1}\",\n{\n            'v': 41,\n            'f': \"41\",\n        },\n{\n            'v': 5.507614932274097,\n            'f': \"5.507614932274097\",\n        },\n{\n            'v': 5.509488628009624,\n            'f': \"5.509488628009624\",\n        },\n{\n            'v': 0.3568415442016295,\n            'f': \"0.3568415442016295\",\n        },\n{\n            'v': 0.8256916678170723,\n            'f': \"0.8256916678170723\",\n        },\n{\n            'v': 0.43381446358436343,\n            'f': \"0.43381446358436343\",\n        },\n{\n            'v': 0.3730184110740555,\n            'f': \"0.3730184110740555\",\n        },\n{\n            'v': 0.8244220540949647,\n            'f': \"0.8244220540949647\",\n        },\n{\n            'v': 0.4512051344351721,\n            'f': \"0.4512051344351721\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 2,\n            'f': \"2\",\n        },\n\"gru\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.0005, 'batch_size': 128, 'hidden_size': 32, 'num_layers': 1}\",\n{\n            'v': 31,\n            'f': \"31\",\n        },\n{\n            'v': 5.983451240717898,\n            'f': \"5.983451240717898\",\n        },\n{\n            'v': 6.0932123053803116,\n            'f': \"6.0932123053803116\",\n        },\n{\n            'v': 0.3926444833625219,\n            'f': \"0.3926444833625219\",\n        },\n{\n            'v': 0.804988595547416,\n            'f': \"0.804988595547416\",\n        },\n{\n            'v': 0.474623652496336,\n            'f': \"0.474623652496336\",\n        },\n{\n            'v': 0.4508657316460323,\n            'f': \"0.4508657316460323\",\n        },\n{\n            'v': 0.8167604275762758,\n            'f': \"0.8167604275762758\",\n        },\n{\n            'v': 0.5415964601265059,\n            'f': \"0.5415964601265059\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 3,\n            'f': \"3\",\n        },\n\"gru\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.0001, 'batch_size': 128, 'hidden_size': 32, 'num_layers': 1}\",\n{\n            'v': 45,\n            'f': \"45\",\n        },\n{\n            'v': 6.741658943035103,\n            'f': \"6.741658943035103\",\n        },\n{\n            'v': 6.704004760396078,\n            'f': \"6.704004760396078\",\n        },\n{\n            'v': 0.22151831264752914,\n            'f': \"0.22151831264752914\",\n        },\n{\n            'v': 0.8127644637416019,\n            'f': \"0.8127644637416019\",\n        },\n{\n            'v': 0.2602808084672521,\n            'f': \"0.2602808084672521\",\n        },\n{\n            'v': 0.2261409840559185,\n            'f': \"0.2261409840559185\",\n        },\n{\n            'v': 0.8167132825529796,\n            'f': \"0.8167132825529796\",\n        },\n{\n            'v': 0.26745297834508336,\n            'f': \"0.26745297834508336\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }]],\n        columns: [[\"number\", \"index\"], [\"string\", \"model_name\"], [\"string\", \"hyperparameter\"], [\"number\", \"best_epoch\"], [\"number\", \"best_train_cost\"], [\"number\", \"best_val_cost\"], [\"number\", \"best_train_recall\"], [\"number\", \"best_train_precision\"], [\"number\", \"best_train_f1\"], [\"number\", \"best_val_recall\"], [\"number\", \"best_val_precision\"], [\"number\", \"best_val_f1\"], [\"number\", \"best_test_recall\"], [\"number\", \"best_test_precision\"], [\"number\", \"best_test_f1\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: \"0\",\n      });\n    "
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "# Define the hyperparameters to search over\n",
        "def experiment_1(benchmark):\n",
        "\n",
        "    \"\"\"\n",
        "    Grid search on the sequence model namely GRU and LSTM only\n",
        "    (45 epochs)\n",
        "    \"\"\"\n",
        "\n",
        "    name = ['gru', 'lstm']\n",
        "    weight_decay = [1e-2]\n",
        "    lr = [1e-3,7e-4]\n",
        "    batch_size = [128]\n",
        "\n",
        "    # For lstm and gru only\n",
        "    hidden_sizes = [32, 64]\n",
        "    num_layers_list = [1, 2]\n",
        "\n",
        "    # Create a Cartesian product of all hyperparameter combinations\n",
        "    hyperparams = list(itertools.product(name, weight_decay, lr, batch_size, hidden_sizes, num_layers_list))\n",
        "    print(f'grid search : perform {len(hyperparams)} searchs')\n",
        "\n",
        "    # Loop over each combination of hyperparameters and train/evaluate the model\n",
        "    best_val_f1 = 0.0\n",
        "    num_epochs = 45\n",
        "    for i, (name, wd, lr, bs, hidden_size, num_layers) in enumerate(hyperparams):\n",
        "\n",
        "        print(f'\\n üîé search {i} : {name} --- hidden_size : {hidden_size}, num_layers : {num_layers}, lr : {lr}, weight_decay : {wd}, batch_size : {bs}')\n",
        "\n",
        "        # Setup Device\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        # Create the model, optimizer, and loss function\n",
        "        model = get_architecture(name = name, device = device, hidden_size=hidden_size, num_layers=num_layers)\n",
        "        class_weights_normalized = get_weighted_for_ce(y_train)\n",
        "        criterion = nn.CrossEntropyLoss(weight=class_weights_normalized.to(device))\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), weight_decay=wd)\n",
        "\n",
        "        # Create the data loaders\n",
        "        train_loader, val_loader, test_loader = get_loader(train_set, val_set, test_set, train_batch_size=bs)\n",
        "\n",
        "        # Train and evaluate the model\n",
        "        scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=0)\n",
        "        model, model_stat = train(model, optimizer, scheduler, criterion, train_loader, val_loader, num_epochs)\n",
        "\n",
        "        \n",
        "        # save the best model configuration based on validation F1 score\n",
        "        if model_stat['best_val_f1'] > best_val_f1:\n",
        "            best_val_f1 = model_stat['best_val_f1']\n",
        "            best_model = deepcopy(model.state_dict())\n",
        "        \n",
        "        row = {'model_name' : name,\n",
        "            'hyperparameter' : {'weight_decay' : wd, 'learning_rate' : lr,\n",
        "                                'batch_size' : bs, 'hidden_size' : hidden_size,\n",
        "                                'num_layers' : num_layers},\n",
        "            'best_epoch' : model_stat['best_epoch'],\n",
        "            'best_train_cost' : model_stat['best_train_cost'],\n",
        "            'best_val_cost' : model_stat['best_val_cost'],\n",
        "            'best_train_recall' : model_stat['best_train_recall'],\n",
        "            'best_train_precision' : model_stat['best_train_precision'],\n",
        "            'best_train_f1' : model_stat['best_train_f1'],\n",
        "            'best_val_recall' : model_stat['best_val_recall'],\n",
        "            'best_val_precision' : model_stat['best_val_precision'],\n",
        "            'best_val_f1' : model_stat['best_val_f1'],\n",
        "            'best_test_recall' : None,\n",
        "            'best_test_precision' : None,\n",
        "            'best_test_f1' : None,\n",
        "            }\n",
        "\n",
        "        benchmark =benchmark.append(row, ignore_index=True)\n",
        "\n",
        "    return benchmark, best_model"
      ],
      "metadata": {
        "id": "jWphXtHfz_HU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#benchmark, best_model = experiment_1(benchmark)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qb9FMRPlPs94",
        "outputId": "7052ca83-61e7-4ffd-b860-b325895bde0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grid search : perform 16 searchs\n",
            "\n",
            " üîé search 0 : gru --- hidden_size : 32, num_layers : 1, lr : 0.001, weight_decay : 0.01, batch_size : 128\n",
            "Epoch: 1/45, Train Loss: 8.0400, Train Acc: 0.1654, Train F1: 0.1177, Val Loss: 7.9947, Val Acc: 0.0107, Val F1: 0.0042\n",
            "Epoch: 2/45, Train Loss: 7.8827, Train Acc: 0.1749, Train F1: 0.1689, Val Loss: 7.9295, Val Acc: 0.0143, Val F1: 0.0105\n",
            "Epoch: 3/45, Train Loss: 7.8758, Train Acc: 0.0931, Train F1: 0.0729, Val Loss: 7.8600, Val Acc: 0.1538, Val F1: 0.1536\n",
            "Epoch: 4/45, Train Loss: 7.8104, Train Acc: 0.1245, Train F1: 0.1285, Val Loss: 7.8833, Val Acc: 0.5738, Val F1: 0.6321\n",
            "Epoch: 5/45, Train Loss: 7.4782, Train Acc: 0.1802, Train F1: 0.2013, Val Loss: 6.7801, Val Acc: 0.1977, Val F1: 0.2193\n",
            "Epoch: 6/45, Train Loss: 6.9242, Train Acc: 0.2061, Train F1: 0.2474, Val Loss: 6.6686, Val Acc: 0.2417, Val F1: 0.3020\n",
            "Epoch: 7/45, Train Loss: 6.7291, Train Acc: 0.2448, Train F1: 0.3019, Val Loss: 6.4691, Val Acc: 0.2973, Val F1: 0.3690\n",
            "Epoch: 8/45, Train Loss: 6.4857, Train Acc: 0.3013, Train F1: 0.3740, Val Loss: 6.3220, Val Acc: 0.3240, Val F1: 0.4021\n",
            "Epoch: 9/45, Train Loss: 6.3447, Train Acc: 0.3165, Train F1: 0.3872, Val Loss: 6.1892, Val Acc: 0.2993, Val F1: 0.3575\n",
            "Epoch: 10/45, Train Loss: 6.2872, Train Acc: 0.3048, Train F1: 0.3723, Val Loss: 6.1409, Val Acc: 0.2648, Val F1: 0.3235\n",
            "Epoch: 11/45, Train Loss: 6.1440, Train Acc: 0.2607, Train F1: 0.3109, Val Loss: 5.9174, Val Acc: 0.2687, Val F1: 0.3206\n",
            "Epoch: 12/45, Train Loss: 6.0411, Train Acc: 0.2769, Train F1: 0.3340, Val Loss: 5.6651, Val Acc: 0.3467, Val F1: 0.4208\n",
            "Epoch: 13/45, Train Loss: 5.8608, Train Acc: 0.3473, Train F1: 0.4228, Val Loss: 5.6270, Val Acc: 0.3945, Val F1: 0.4719\n",
            "Epoch: 14/45, Train Loss: 5.7854, Train Acc: 0.3540, Train F1: 0.4301, Val Loss: 6.8650, Val Acc: 0.2925, Val F1: 0.3851\n",
            "Epoch: 15/45, Train Loss: 5.6788, Train Acc: 0.3749, Train F1: 0.4536, Val Loss: 5.7364, Val Acc: 0.3631, Val F1: 0.4459\n",
            "Epoch: 16/45, Train Loss: 6.2450, Train Acc: 0.3454, Train F1: 0.4117, Val Loss: 5.6874, Val Acc: 0.3003, Val F1: 0.3562\n",
            "Epoch: 17/45, Train Loss: 5.5878, Train Acc: 0.3335, Train F1: 0.4022, Val Loss: 5.3891, Val Acc: 0.4151, Val F1: 0.4951\n",
            "Epoch: 18/45, Train Loss: 5.4562, Train Acc: 0.4257, Train F1: 0.5088, Val Loss: 5.3180, Val Acc: 0.4692, Val F1: 0.5494\n",
            "Epoch: 19/45, Train Loss: 5.4169, Train Acc: 0.4595, Train F1: 0.5435, Val Loss: 5.2296, Val Acc: 0.4763, Val F1: 0.5606\n",
            "Epoch: 20/45, Train Loss: 5.3622, Train Acc: 0.4821, Train F1: 0.5650, Val Loss: 5.2311, Val Acc: 0.4523, Val F1: 0.5367\n",
            "Epoch: 21/45, Train Loss: 5.3501, Train Acc: 0.4864, Train F1: 0.5695, Val Loss: 5.1077, Val Acc: 0.4914, Val F1: 0.5726\n",
            "Epoch: 22/45, Train Loss: 5.2859, Train Acc: 0.4845, Train F1: 0.5669, Val Loss: 5.2685, Val Acc: 0.4881, Val F1: 0.5707\n",
            "Epoch: 23/45, Train Loss: 5.2558, Train Acc: 0.4961, Train F1: 0.5780, Val Loss: 5.0625, Val Acc: 0.4944, Val F1: 0.5735\n",
            "Epoch: 24/45, Train Loss: 5.2749, Train Acc: 0.5020, Train F1: 0.5833, Val Loss: 5.4352, Val Acc: 0.5200, Val F1: 0.5977\n",
            "Epoch: 25/45, Train Loss: 5.1703, Train Acc: 0.5025, Train F1: 0.5832, Val Loss: 5.0154, Val Acc: 0.5315, Val F1: 0.6081\n",
            "Epoch: 26/45, Train Loss: 5.1882, Train Acc: 0.5135, Train F1: 0.5935, Val Loss: 5.4854, Val Acc: 0.4898, Val F1: 0.5679\n",
            "Epoch: 27/45, Train Loss: 5.1509, Train Acc: 0.5150, Train F1: 0.5948, Val Loss: 5.1016, Val Acc: 0.4949, Val F1: 0.5705\n",
            "Epoch: 28/45, Train Loss: 5.1133, Train Acc: 0.5151, Train F1: 0.5946, Val Loss: 4.9818, Val Acc: 0.5528, Val F1: 0.6282\n",
            "Epoch: 29/45, Train Loss: 5.0821, Train Acc: 0.5195, Train F1: 0.5990, Val Loss: 5.0366, Val Acc: 0.5277, Val F1: 0.6031\n",
            "Epoch: 30/45, Train Loss: 5.0624, Train Acc: 0.5118, Train F1: 0.5913, Val Loss: 5.0046, Val Acc: 0.5289, Val F1: 0.6029\n",
            "Epoch: 31/45, Train Loss: 5.0531, Train Acc: 0.5234, Train F1: 0.6021, Val Loss: 4.8728, Val Acc: 0.5196, Val F1: 0.5967\n",
            "Epoch: 32/45, Train Loss: 5.0357, Train Acc: 0.5227, Train F1: 0.6016, Val Loss: 4.8733, Val Acc: 0.5140, Val F1: 0.5898\n",
            "Epoch: 33/45, Train Loss: 5.0194, Train Acc: 0.5033, Train F1: 0.5830, Val Loss: 4.9429, Val Acc: 0.5572, Val F1: 0.6308\n",
            "Epoch: 34/45, Train Loss: 5.0098, Train Acc: 0.5050, Train F1: 0.5847, Val Loss: 4.8563, Val Acc: 0.4946, Val F1: 0.5727\n",
            "Epoch: 35/45, Train Loss: 4.9924, Train Acc: 0.5074, Train F1: 0.5870, Val Loss: 4.9080, Val Acc: 0.4947, Val F1: 0.5740\n",
            "Epoch: 36/45, Train Loss: 4.9797, Train Acc: 0.4901, Train F1: 0.5705, Val Loss: 4.8608, Val Acc: 0.5066, Val F1: 0.5834\n",
            "Epoch: 37/45, Train Loss: 4.9625, Train Acc: 0.4960, Train F1: 0.5763, Val Loss: 4.8775, Val Acc: 0.4611, Val F1: 0.5386\n",
            "Epoch: 38/45, Train Loss: 4.9613, Train Acc: 0.4982, Train F1: 0.5782, Val Loss: 4.8335, Val Acc: 0.4669, Val F1: 0.5443\n",
            "Epoch: 39/45, Train Loss: 4.9600, Train Acc: 0.4788, Train F1: 0.5596, Val Loss: 4.8334, Val Acc: 0.4771, Val F1: 0.5549\n",
            "Epoch: 40/45, Train Loss: 4.9471, Train Acc: 0.4884, Train F1: 0.5693, Val Loss: 4.8289, Val Acc: 0.5039, Val F1: 0.5810\n",
            "Epoch: 41/45, Train Loss: 4.9456, Train Acc: 0.4910, Train F1: 0.5714, Val Loss: 4.8205, Val Acc: 0.4999, Val F1: 0.5774\n",
            "Epoch: 42/45, Train Loss: 4.9376, Train Acc: 0.4932, Train F1: 0.5734, Val Loss: 4.8173, Val Acc: 0.4952, Val F1: 0.5728\n",
            "Epoch: 43/45, Train Loss: 4.9370, Train Acc: 0.4939, Train F1: 0.5742, Val Loss: 4.8160, Val Acc: 0.4906, Val F1: 0.5683\n",
            "Epoch: 44/45, Train Loss: 4.9319, Train Acc: 0.4952, Train F1: 0.5751, Val Loss: 4.8186, Val Acc: 0.4838, Val F1: 0.5617\n",
            "Epoch: 45/45, Train Loss: 4.9309, Train Acc: 0.4900, Train F1: 0.5701, Val Loss: 4.8180, Val Acc: 0.4846, Val F1: 0.5625\n",
            "\n",
            " üîé search 1 : gru --- hidden_size : 32, num_layers : 2, lr : 0.001, weight_decay : 0.01, batch_size : 128\n",
            "Epoch: 1/45, Train Loss: 8.0314, Train Acc: 0.1405, Train F1: 0.1144, Val Loss: 7.9652, Val Acc: 0.8212, Val F1: 0.7549\n",
            "Epoch: 2/45, Train Loss: 7.9008, Train Acc: 0.2236, Train F1: 0.1916, Val Loss: 7.8296, Val Acc: 0.0948, Val F1: 0.0460\n",
            "Epoch: 3/45, Train Loss: 7.8545, Train Acc: 0.2235, Train F1: 0.2156, Val Loss: 7.8764, Val Acc: 0.0155, Val F1: 0.0115\n",
            "Epoch: 4/45, Train Loss: 7.9971, Train Acc: 0.0973, Train F1: 0.0750, Val Loss: 8.0582, Val Acc: 0.0661, Val F1: 0.0083\n",
            "Epoch: 5/45, Train Loss: 8.0366, Train Acc: 0.0683, Train F1: 0.0365, Val Loss: 8.0355, Val Acc: 0.0098, Val F1: 0.0039\n",
            "Epoch: 6/45, Train Loss: 7.9875, Train Acc: 0.1272, Train F1: 0.1015, Val Loss: 7.8964, Val Acc: 0.0177, Val F1: 0.0162\n",
            "Epoch: 7/45, Train Loss: 7.1861, Train Acc: 0.0889, Train F1: 0.0613, Val Loss: 6.6784, Val Acc: 0.1169, Val F1: 0.0913\n",
            "Epoch: 8/45, Train Loss: 6.4317, Train Acc: 0.2078, Train F1: 0.2319, Val Loss: 6.1356, Val Acc: 0.2652, Val F1: 0.3142\n",
            "Epoch: 9/45, Train Loss: 6.2284, Train Acc: 0.2402, Train F1: 0.2827, Val Loss: 6.1225, Val Acc: 0.2816, Val F1: 0.3433\n",
            "Epoch: 10/45, Train Loss: 6.0940, Train Acc: 0.2793, Train F1: 0.3372, Val Loss: 6.0161, Val Acc: 0.3094, Val F1: 0.3767\n",
            "Epoch: 11/45, Train Loss: 6.0367, Train Acc: 0.2953, Train F1: 0.3591, Val Loss: 6.0977, Val Acc: 0.3841, Val F1: 0.4625\n",
            "Epoch: 12/45, Train Loss: 5.9721, Train Acc: 0.3187, Train F1: 0.3884, Val Loss: 5.7397, Val Acc: 0.3535, Val F1: 0.4343\n",
            "Epoch: 13/45, Train Loss: 5.8577, Train Acc: 0.3218, Train F1: 0.3929, Val Loss: 5.6153, Val Acc: 0.3347, Val F1: 0.4047\n",
            "Epoch: 14/45, Train Loss: 5.7611, Train Acc: 0.3250, Train F1: 0.3942, Val Loss: 5.5081, Val Acc: 0.3512, Val F1: 0.4248\n",
            "Epoch: 15/45, Train Loss: 5.7242, Train Acc: 0.3191, Train F1: 0.3872, Val Loss: 6.1273, Val Acc: 0.3661, Val F1: 0.4429\n",
            "Epoch: 16/45, Train Loss: 5.6763, Train Acc: 0.3387, Train F1: 0.4117, Val Loss: 5.6426, Val Acc: 0.3218, Val F1: 0.3979\n",
            "Epoch: 17/45, Train Loss: 5.6469, Train Acc: 0.3331, Train F1: 0.4045, Val Loss: 5.5379, Val Acc: 0.3530, Val F1: 0.4305\n",
            "Epoch: 18/45, Train Loss: 5.6443, Train Acc: 0.3396, Train F1: 0.4130, Val Loss: 5.4757, Val Acc: 0.3456, Val F1: 0.4190\n",
            "Epoch: 19/45, Train Loss: 5.6216, Train Acc: 0.3507, Train F1: 0.4263, Val Loss: 5.4139, Val Acc: 0.3432, Val F1: 0.4149\n",
            "Epoch: 20/45, Train Loss: 5.6031, Train Acc: 0.3465, Train F1: 0.4211, Val Loss: 5.4693, Val Acc: 0.3385, Val F1: 0.4099\n",
            "Epoch: 21/45, Train Loss: 5.6139, Train Acc: 0.3414, Train F1: 0.4152, Val Loss: 5.6291, Val Acc: 0.3452, Val F1: 0.4244\n",
            "Epoch: 22/45, Train Loss: 5.6900, Train Acc: 0.3463, Train F1: 0.4203, Val Loss: 5.4252, Val Acc: 0.3246, Val F1: 0.3921\n",
            "Epoch: 23/45, Train Loss: 5.5696, Train Acc: 0.3568, Train F1: 0.4328, Val Loss: 5.5702, Val Acc: 0.3619, Val F1: 0.4404\n",
            "Epoch: 24/45, Train Loss: 5.5708, Train Acc: 0.3631, Train F1: 0.4404, Val Loss: 5.4657, Val Acc: 0.3977, Val F1: 0.4769\n",
            "Epoch: 25/45, Train Loss: 5.5805, Train Acc: 0.3647, Train F1: 0.4417, Val Loss: 5.4313, Val Acc: 0.3597, Val F1: 0.4362\n",
            "Epoch: 26/45, Train Loss: 5.5577, Train Acc: 0.3641, Train F1: 0.4414, Val Loss: 5.4678, Val Acc: 0.3665, Val F1: 0.4436\n",
            "Epoch: 27/45, Train Loss: 5.5683, Train Acc: 0.3679, Train F1: 0.4459, Val Loss: 5.5525, Val Acc: 0.3359, Val F1: 0.4090\n",
            "Epoch: 28/45, Train Loss: 5.5510, Train Acc: 0.3538, Train F1: 0.4283, Val Loss: 5.4126, Val Acc: 0.3817, Val F1: 0.4612\n",
            "Epoch: 29/45, Train Loss: 5.5310, Train Acc: 0.3690, Train F1: 0.4468, Val Loss: 5.4253, Val Acc: 0.3784, Val F1: 0.4579\n",
            "Epoch: 30/45, Train Loss: 5.5447, Train Acc: 0.3703, Train F1: 0.4490, Val Loss: 5.4468, Val Acc: 0.3661, Val F1: 0.4436\n",
            "Epoch: 31/45, Train Loss: 5.5301, Train Acc: 0.3656, Train F1: 0.4423, Val Loss: 5.3729, Val Acc: 0.3759, Val F1: 0.4522\n",
            "Epoch: 32/45, Train Loss: 5.5128, Train Acc: 0.3663, Train F1: 0.4431, Val Loss: 5.5823, Val Acc: 0.3875, Val F1: 0.4648\n",
            "Epoch: 33/45, Train Loss: 5.5065, Train Acc: 0.3708, Train F1: 0.4484, Val Loss: 5.4016, Val Acc: 0.3781, Val F1: 0.4569\n",
            "Epoch: 34/45, Train Loss: 5.5010, Train Acc: 0.3767, Train F1: 0.4555, Val Loss: 5.4023, Val Acc: 0.3804, Val F1: 0.4556\n",
            "Epoch: 35/45, Train Loss: 5.5035, Train Acc: 0.3740, Train F1: 0.4518, Val Loss: 5.4060, Val Acc: 0.3680, Val F1: 0.4452\n",
            "Epoch: 36/45, Train Loss: 5.4896, Train Acc: 0.3757, Train F1: 0.4539, Val Loss: 5.3864, Val Acc: 0.3799, Val F1: 0.4565\n",
            "Epoch: 37/45, Train Loss: 5.4799, Train Acc: 0.3755, Train F1: 0.4532, Val Loss: 5.4284, Val Acc: 0.3785, Val F1: 0.4582\n",
            "Epoch: 38/45, Train Loss: 5.4740, Train Acc: 0.3763, Train F1: 0.4547, Val Loss: 5.3964, Val Acc: 0.3781, Val F1: 0.4565\n",
            "Epoch: 39/45, Train Loss: 5.4759, Train Acc: 0.3794, Train F1: 0.4579, Val Loss: 5.3771, Val Acc: 0.3801, Val F1: 0.4580\n",
            "Epoch: 40/45, Train Loss: 5.4727, Train Acc: 0.3790, Train F1: 0.4573, Val Loss: 5.4211, Val Acc: 0.3772, Val F1: 0.4562\n",
            "Epoch: 41/45, Train Loss: 5.4731, Train Acc: 0.3785, Train F1: 0.4568, Val Loss: 5.3737, Val Acc: 0.3846, Val F1: 0.4620\n",
            "Epoch: 42/45, Train Loss: 5.4688, Train Acc: 0.3771, Train F1: 0.4555, Val Loss: 5.3692, Val Acc: 0.3824, Val F1: 0.4602\n",
            "Epoch: 43/45, Train Loss: 5.4644, Train Acc: 0.3785, Train F1: 0.4568, Val Loss: 5.3708, Val Acc: 0.3812, Val F1: 0.4588\n",
            "Epoch: 44/45, Train Loss: 5.4636, Train Acc: 0.3783, Train F1: 0.4567, Val Loss: 5.3664, Val Acc: 0.3822, Val F1: 0.4596\n",
            "Epoch: 45/45, Train Loss: 5.4624, Train Acc: 0.3788, Train F1: 0.4569, Val Loss: 5.3666, Val Acc: 0.3822, Val F1: 0.4598\n",
            "\n",
            " üîé search 2 : gru --- hidden_size : 64, num_layers : 1, lr : 0.001, weight_decay : 0.01, batch_size : 128\n",
            "Epoch: 1/45, Train Loss: 8.0169, Train Acc: 0.1252, Train F1: 0.0829, Val Loss: 7.9377, Val Acc: 0.0770, Val F1: 0.0151\n",
            "Epoch: 2/45, Train Loss: 7.8729, Train Acc: 0.0669, Train F1: 0.0440, Val Loss: 7.9110, Val Acc: 0.0123, Val F1: 0.0060\n",
            "Epoch: 3/45, Train Loss: 7.8865, Train Acc: 0.1132, Train F1: 0.1033, Val Loss: 7.9057, Val Acc: 0.0280, Val F1: 0.0348\n",
            "Epoch: 4/45, Train Loss: 7.8798, Train Acc: 0.0524, Train F1: 0.0382, Val Loss: 7.7693, Val Acc: 0.0545, Val F1: 0.0555\n",
            "Epoch: 5/45, Train Loss: 7.9060, Train Acc: 0.1133, Train F1: 0.1018, Val Loss: 7.8769, Val Acc: 0.0890, Val F1: 0.0368\n",
            "Epoch: 6/45, Train Loss: 7.8530, Train Acc: 0.1333, Train F1: 0.0976, Val Loss: 7.8450, Val Acc: 0.0195, Val F1: 0.0192\n",
            "Epoch: 7/45, Train Loss: 7.8049, Train Acc: 0.1845, Train F1: 0.1874, Val Loss: 7.9337, Val Acc: 0.0216, Val F1: 0.0238\n",
            "Epoch: 8/45, Train Loss: 7.8511, Train Acc: 0.3805, Train F1: 0.3743, Val Loss: 7.8232, Val Acc: 0.0204, Val F1: 0.0144\n",
            "Epoch: 9/45, Train Loss: 7.3633, Train Acc: 0.1032, Train F1: 0.0993, Val Loss: 6.7891, Val Acc: 0.1444, Val F1: 0.1551\n",
            "Epoch: 10/45, Train Loss: 6.7367, Train Acc: 0.2131, Train F1: 0.2581, Val Loss: 6.6888, Val Acc: 0.2011, Val F1: 0.2281\n",
            "Epoch: 11/45, Train Loss: 6.8037, Train Acc: 0.2160, Train F1: 0.2569, Val Loss: 6.5301, Val Acc: 0.1753, Val F1: 0.2172\n",
            "Epoch: 12/45, Train Loss: 6.4740, Train Acc: 0.2640, Train F1: 0.3219, Val Loss: 6.5494, Val Acc: 0.1968, Val F1: 0.2340\n",
            "Epoch: 13/45, Train Loss: 6.5313, Train Acc: 0.2195, Train F1: 0.2575, Val Loss: 6.6694, Val Acc: 0.1646, Val F1: 0.2204\n",
            "Epoch: 14/45, Train Loss: 6.3136, Train Acc: 0.2270, Train F1: 0.2656, Val Loss: 6.0268, Val Acc: 0.2102, Val F1: 0.2341\n",
            "Epoch: 15/45, Train Loss: 6.1158, Train Acc: 0.1761, Train F1: 0.1845, Val Loss: 5.6543, Val Acc: 0.1454, Val F1: 0.1225\n",
            "Epoch: 16/45, Train Loss: 5.9982, Train Acc: 0.1404, Train F1: 0.1218, Val Loss: 5.7781, Val Acc: 0.1578, Val F1: 0.1405\n",
            "Epoch: 17/45, Train Loss: 5.7200, Train Acc: 0.1697, Train F1: 0.1720, Val Loss: 5.3526, Val Acc: 0.1980, Val F1: 0.2166\n",
            "Epoch: 18/45, Train Loss: 5.4891, Train Acc: 0.2411, Train F1: 0.2859, Val Loss: 6.1260, Val Acc: 0.2395, Val F1: 0.3073\n",
            "Epoch: 19/45, Train Loss: 5.5201, Train Acc: 0.2695, Train F1: 0.3235, Val Loss: 5.4846, Val Acc: 0.2382, Val F1: 0.2951\n",
            "Epoch: 20/45, Train Loss: 5.3454, Train Acc: 0.2547, Train F1: 0.3033, Val Loss: 5.0470, Val Acc: 0.3108, Val F1: 0.3841\n",
            "Epoch: 21/45, Train Loss: 5.1618, Train Acc: 0.2640, Train F1: 0.3150, Val Loss: 5.1957, Val Acc: 0.2924, Val F1: 0.3475\n",
            "Epoch: 22/45, Train Loss: 5.0784, Train Acc: 0.3040, Train F1: 0.3687, Val Loss: 4.7748, Val Acc: 0.2696, Val F1: 0.3228\n",
            "Epoch: 23/45, Train Loss: 5.0362, Train Acc: 0.2763, Train F1: 0.3294, Val Loss: 4.7548, Val Acc: 0.3314, Val F1: 0.3935\n",
            "Epoch: 24/45, Train Loss: 4.8318, Train Acc: 0.2983, Train F1: 0.3571, Val Loss: 4.9858, Val Acc: 0.4157, Val F1: 0.5000\n",
            "Epoch: 25/45, Train Loss: 4.6125, Train Acc: 0.3300, Train F1: 0.3959, Val Loss: 5.5836, Val Acc: 0.3319, Val F1: 0.4165\n",
            "Epoch: 26/45, Train Loss: 4.5602, Train Acc: 0.3331, Train F1: 0.4005, Val Loss: 4.3058, Val Acc: 0.3067, Val F1: 0.3590\n",
            "Epoch: 27/45, Train Loss: 4.5123, Train Acc: 0.3472, Train F1: 0.4173, Val Loss: 4.3085, Val Acc: 0.3490, Val F1: 0.4184\n",
            "Epoch: 28/45, Train Loss: 4.3918, Train Acc: 0.3576, Train F1: 0.4287, Val Loss: 4.3258, Val Acc: 0.3270, Val F1: 0.3912\n",
            "Epoch: 29/45, Train Loss: 4.3171, Train Acc: 0.3762, Train F1: 0.4497, Val Loss: 4.3328, Val Acc: 0.3650, Val F1: 0.4433\n",
            "Epoch: 30/45, Train Loss: 4.2802, Train Acc: 0.3839, Train F1: 0.4600, Val Loss: 4.2105, Val Acc: 0.3965, Val F1: 0.4767\n",
            "Epoch: 31/45, Train Loss: 4.2885, Train Acc: 0.3934, Train F1: 0.4712, Val Loss: 4.1409, Val Acc: 0.4139, Val F1: 0.4938\n",
            "Epoch: 32/45, Train Loss: 4.1895, Train Acc: 0.4030, Train F1: 0.4802, Val Loss: 4.1457, Val Acc: 0.4630, Val F1: 0.5421\n",
            "Epoch: 33/45, Train Loss: 4.1365, Train Acc: 0.4067, Train F1: 0.4854, Val Loss: 4.1176, Val Acc: 0.4412, Val F1: 0.5182\n",
            "Epoch: 34/45, Train Loss: 4.1229, Train Acc: 0.4162, Train F1: 0.4949, Val Loss: 4.0950, Val Acc: 0.3861, Val F1: 0.4671\n",
            "Epoch: 35/45, Train Loss: 4.1038, Train Acc: 0.4201, Train F1: 0.4991, Val Loss: 4.0910, Val Acc: 0.4543, Val F1: 0.5345\n",
            "Epoch: 36/45, Train Loss: 4.0576, Train Acc: 0.4268, Train F1: 0.5066, Val Loss: 4.0602, Val Acc: 0.4165, Val F1: 0.4913\n",
            "Epoch: 37/45, Train Loss: 4.0384, Train Acc: 0.4308, Train F1: 0.5103, Val Loss: 4.0279, Val Acc: 0.4463, Val F1: 0.5273\n",
            "Epoch: 38/45, Train Loss: 4.0138, Train Acc: 0.4261, Train F1: 0.5058, Val Loss: 4.0359, Val Acc: 0.3710, Val F1: 0.4489\n",
            "Epoch: 39/45, Train Loss: 4.0089, Train Acc: 0.4257, Train F1: 0.5060, Val Loss: 4.0093, Val Acc: 0.3946, Val F1: 0.4729\n",
            "Epoch: 40/45, Train Loss: 3.9967, Train Acc: 0.4453, Train F1: 0.5270, Val Loss: 4.0386, Val Acc: 0.4647, Val F1: 0.5462\n",
            "Epoch: 41/45, Train Loss: 3.9811, Train Acc: 0.4294, Train F1: 0.5100, Val Loss: 3.9703, Val Acc: 0.4273, Val F1: 0.5069\n",
            "Epoch: 42/45, Train Loss: 3.9697, Train Acc: 0.4336, Train F1: 0.5148, Val Loss: 3.9689, Val Acc: 0.4383, Val F1: 0.5175\n",
            "Epoch: 43/45, Train Loss: 3.9602, Train Acc: 0.4464, Train F1: 0.5273, Val Loss: 3.9673, Val Acc: 0.4353, Val F1: 0.5149\n",
            "Epoch: 44/45, Train Loss: 3.9522, Train Acc: 0.4285, Train F1: 0.5095, Val Loss: 3.9637, Val Acc: 0.4320, Val F1: 0.5115\n",
            "Epoch: 45/45, Train Loss: 3.9519, Train Acc: 0.4279, Train F1: 0.5086, Val Loss: 3.9638, Val Acc: 0.4341, Val F1: 0.5138\n",
            "\n",
            " üîé search 3 : gru --- hidden_size : 64, num_layers : 2, lr : 0.001, weight_decay : 0.01, batch_size : 128\n",
            "Epoch: 1/45, Train Loss: 8.0144, Train Acc: 0.2041, Train F1: 0.1672, Val Loss: 7.8665, Val Acc: 0.0124, Val F1: 0.0045\n",
            "Epoch: 2/45, Train Loss: 7.9245, Train Acc: 0.2171, Train F1: 0.1890, Val Loss: 7.8421, Val Acc: 0.1141, Val F1: 0.0842\n",
            "Epoch: 3/45, Train Loss: 7.8201, Train Acc: 0.2733, Train F1: 0.2662, Val Loss: 7.7061, Val Acc: 0.1407, Val F1: 0.1257\n",
            "Epoch: 4/45, Train Loss: 7.9399, Train Acc: 0.1061, Train F1: 0.0943, Val Loss: 7.9040, Val Acc: 0.0187, Val F1: 0.0169\n",
            "Epoch: 5/45, Train Loss: 7.8268, Train Acc: 0.1091, Train F1: 0.0924, Val Loss: 7.3667, Val Acc: 0.0473, Val F1: 0.0244\n",
            "Epoch: 6/45, Train Loss: 6.8480, Train Acc: 0.1251, Train F1: 0.1053, Val Loss: 6.2898, Val Acc: 0.2847, Val F1: 0.3357\n",
            "Epoch: 7/45, Train Loss: 6.2988, Train Acc: 0.2882, Train F1: 0.3469, Val Loss: 6.0403, Val Acc: 0.3469, Val F1: 0.4248\n",
            "Epoch: 8/45, Train Loss: 6.1807, Train Acc: 0.3169, Train F1: 0.3841, Val Loss: 5.9700, Val Acc: 0.2962, Val F1: 0.3619\n",
            "Epoch: 9/45, Train Loss: 6.1086, Train Acc: 0.3232, Train F1: 0.3947, Val Loss: 5.9480, Val Acc: 0.2934, Val F1: 0.3597\n",
            "Epoch: 10/45, Train Loss: 6.0047, Train Acc: 0.3408, Train F1: 0.4164, Val Loss: 5.8936, Val Acc: 0.3759, Val F1: 0.4519\n",
            "Epoch: 11/45, Train Loss: 5.9085, Train Acc: 0.3355, Train F1: 0.4084, Val Loss: 5.6590, Val Acc: 0.3626, Val F1: 0.4371\n",
            "Epoch: 12/45, Train Loss: 5.7853, Train Acc: 0.3369, Train F1: 0.4096, Val Loss: 5.8847, Val Acc: 0.3841, Val F1: 0.4730\n",
            "Epoch: 13/45, Train Loss: 5.7248, Train Acc: 0.3518, Train F1: 0.4265, Val Loss: 5.5284, Val Acc: 0.4138, Val F1: 0.4965\n",
            "Epoch: 14/45, Train Loss: 5.7014, Train Acc: 0.3557, Train F1: 0.4307, Val Loss: 5.6785, Val Acc: 0.3734, Val F1: 0.4506\n",
            "Epoch: 15/45, Train Loss: 5.6733, Train Acc: 0.3695, Train F1: 0.4471, Val Loss: 5.6196, Val Acc: 0.3351, Val F1: 0.4111\n",
            "Epoch: 16/45, Train Loss: 5.6275, Train Acc: 0.3694, Train F1: 0.4471, Val Loss: 5.6593, Val Acc: 0.4132, Val F1: 0.4909\n",
            "Epoch: 17/45, Train Loss: 5.6207, Train Acc: 0.3788, Train F1: 0.4569, Val Loss: 5.8285, Val Acc: 0.3322, Val F1: 0.4050\n",
            "Epoch: 18/45, Train Loss: 5.5883, Train Acc: 0.3812, Train F1: 0.4607, Val Loss: 5.5427, Val Acc: 0.3771, Val F1: 0.4505\n",
            "Epoch: 19/45, Train Loss: 5.5021, Train Acc: 0.4272, Train F1: 0.5118, Val Loss: 5.1964, Val Acc: 0.4888, Val F1: 0.5722\n",
            "Epoch: 20/45, Train Loss: 5.3993, Train Acc: 0.4752, Train F1: 0.5603, Val Loss: 5.4188, Val Acc: 0.5061, Val F1: 0.5939\n",
            "Epoch: 21/45, Train Loss: 5.4040, Train Acc: 0.4962, Train F1: 0.5792, Val Loss: 5.2640, Val Acc: 0.3880, Val F1: 0.4727\n",
            "Epoch: 22/45, Train Loss: 5.2724, Train Acc: 0.4995, Train F1: 0.5830, Val Loss: 4.7609, Val Acc: 0.5558, Val F1: 0.6345\n",
            "Epoch: 23/45, Train Loss: 6.9820, Train Acc: 0.3432, Train F1: 0.4261, Val Loss: 6.4058, Val Acc: 0.3053, Val F1: 0.3847\n",
            "Epoch: 24/45, Train Loss: 6.2263, Train Acc: 0.3244, Train F1: 0.4013, Val Loss: 7.4978, Val Acc: 0.2914, Val F1: 0.3615\n",
            "Epoch: 25/45, Train Loss: 5.9464, Train Acc: 0.3012, Train F1: 0.3681, Val Loss: 5.6948, Val Acc: 0.3185, Val F1: 0.3836\n",
            "Epoch: 26/45, Train Loss: 5.7660, Train Acc: 0.3161, Train F1: 0.3866, Val Loss: 5.4884, Val Acc: 0.3392, Val F1: 0.4119\n",
            "Epoch: 27/45, Train Loss: 5.6169, Train Acc: 0.3199, Train F1: 0.3890, Val Loss: 5.4021, Val Acc: 0.2986, Val F1: 0.3552\n",
            "Epoch: 28/45, Train Loss: 5.5637, Train Acc: 0.3221, Train F1: 0.3904, Val Loss: 5.7153, Val Acc: 0.3051, Val F1: 0.3747\n",
            "Epoch: 29/45, Train Loss: 5.6754, Train Acc: 0.3353, Train F1: 0.4085, Val Loss: 6.6639, Val Acc: 0.2967, Val F1: 0.3812\n",
            "Epoch: 30/45, Train Loss: 6.0163, Train Acc: 0.3073, Train F1: 0.3769, Val Loss: 5.5741, Val Acc: 0.3470, Val F1: 0.4185\n",
            "Epoch: 31/45, Train Loss: 5.6309, Train Acc: 0.3384, Train F1: 0.4110, Val Loss: 5.6366, Val Acc: 0.3623, Val F1: 0.4413\n",
            "Epoch: 32/45, Train Loss: 5.6194, Train Acc: 0.3522, Train F1: 0.4270, Val Loss: 5.5082, Val Acc: 0.3457, Val F1: 0.4165\n",
            "Epoch: 33/45, Train Loss: 5.5272, Train Acc: 0.3454, Train F1: 0.4180, Val Loss: 5.4244, Val Acc: 0.3425, Val F1: 0.4145\n",
            "Epoch: 34/45, Train Loss: 5.4933, Train Acc: 0.3431, Train F1: 0.4145, Val Loss: 5.4044, Val Acc: 0.3414, Val F1: 0.4117\n",
            "Epoch: 35/45, Train Loss: 5.4480, Train Acc: 0.3421, Train F1: 0.4125, Val Loss: 5.4008, Val Acc: 0.3288, Val F1: 0.3960\n",
            "Epoch: 36/45, Train Loss: 5.5803, Train Acc: 0.3274, Train F1: 0.3946, Val Loss: 5.8324, Val Acc: 0.2776, Val F1: 0.3303\n",
            "Epoch: 37/45, Train Loss: 5.6943, Train Acc: 0.3219, Train F1: 0.3863, Val Loss: 5.5535, Val Acc: 0.3626, Val F1: 0.4346\n",
            "Epoch: 38/45, Train Loss: 5.6061, Train Acc: 0.3762, Train F1: 0.4518, Val Loss: 5.5372, Val Acc: 0.3840, Val F1: 0.4598\n",
            "Epoch: 39/45, Train Loss: 5.5912, Train Acc: 0.3890, Train F1: 0.4663, Val Loss: 5.5344, Val Acc: 0.3915, Val F1: 0.4683\n",
            "Epoch: 40/45, Train Loss: 5.5834, Train Acc: 0.3958, Train F1: 0.4739, Val Loss: 5.5295, Val Acc: 0.3938, Val F1: 0.4707\n",
            "Epoch: 41/45, Train Loss: 5.5809, Train Acc: 0.3902, Train F1: 0.4679, Val Loss: 5.5289, Val Acc: 0.3907, Val F1: 0.4674\n",
            "Epoch: 42/45, Train Loss: 5.5757, Train Acc: 0.3951, Train F1: 0.4734, Val Loss: 5.5278, Val Acc: 0.3924, Val F1: 0.4696\n",
            "Epoch: 43/45, Train Loss: 5.5729, Train Acc: 0.3945, Train F1: 0.4727, Val Loss: 5.5252, Val Acc: 0.3954, Val F1: 0.4726\n",
            "Epoch: 44/45, Train Loss: 5.5711, Train Acc: 0.3961, Train F1: 0.4743, Val Loss: 5.5247, Val Acc: 0.3948, Val F1: 0.4722\n",
            "Epoch: 45/45, Train Loss: 5.5700, Train Acc: 0.3961, Train F1: 0.4747, Val Loss: 5.5244, Val Acc: 0.3951, Val F1: 0.4724\n",
            "\n",
            " üîé search 4 : gru --- hidden_size : 32, num_layers : 1, lr : 0.0007, weight_decay : 0.01, batch_size : 128\n",
            "Epoch: 1/45, Train Loss: 8.0274, Train Acc: 0.2102, Train F1: 0.1821, Val Loss: 7.8804, Val Acc: 0.7512, Val F1: 0.7188\n",
            "Epoch: 2/45, Train Loss: 7.8156, Train Acc: 0.1943, Train F1: 0.1842, Val Loss: 7.5398, Val Acc: 0.1253, Val F1: 0.1660\n",
            "Epoch: 3/45, Train Loss: 7.1586, Train Acc: 0.1485, Train F1: 0.1697, Val Loss: 6.7433, Val Acc: 0.2133, Val F1: 0.2504\n",
            "Epoch: 4/45, Train Loss: 6.8424, Train Acc: 0.2137, Train F1: 0.2585, Val Loss: 6.6255, Val Acc: 0.2502, Val F1: 0.2996\n",
            "Epoch: 5/45, Train Loss: 6.7377, Train Acc: 0.2374, Train F1: 0.2898, Val Loss: 6.5814, Val Acc: 0.2398, Val F1: 0.2926\n",
            "Epoch: 6/45, Train Loss: 6.5560, Train Acc: 0.2782, Train F1: 0.3406, Val Loss: 6.5136, Val Acc: 0.2731, Val F1: 0.3447\n",
            "Epoch: 7/45, Train Loss: 6.4075, Train Acc: 0.3140, Train F1: 0.3854, Val Loss: 8.1716, Val Acc: 0.1768, Val F1: 0.2237\n",
            "Epoch: 8/45, Train Loss: 6.6151, Train Acc: 0.2532, Train F1: 0.3132, Val Loss: 6.2497, Val Acc: 0.3240, Val F1: 0.3985\n",
            "Epoch: 9/45, Train Loss: 6.2563, Train Acc: 0.3293, Train F1: 0.4020, Val Loss: 6.0782, Val Acc: 0.4190, Val F1: 0.4989\n",
            "Epoch: 10/45, Train Loss: 6.2837, Train Acc: 0.3268, Train F1: 0.3979, Val Loss: 6.5049, Val Acc: 0.3408, Val F1: 0.4058\n",
            "Epoch: 11/45, Train Loss: 6.2747, Train Acc: 0.3110, Train F1: 0.3778, Val Loss: 6.4180, Val Acc: 0.2501, Val F1: 0.3112\n",
            "Epoch: 12/45, Train Loss: 6.2123, Train Acc: 0.2866, Train F1: 0.3463, Val Loss: 6.0320, Val Acc: 0.2980, Val F1: 0.3550\n",
            "Epoch: 13/45, Train Loss: 6.1519, Train Acc: 0.2874, Train F1: 0.3455, Val Loss: 5.9838, Val Acc: 0.3276, Val F1: 0.3940\n",
            "Epoch: 14/45, Train Loss: 6.2748, Train Acc: 0.2608, Train F1: 0.3130, Val Loss: 5.9894, Val Acc: 0.2785, Val F1: 0.3329\n",
            "Epoch: 15/45, Train Loss: 6.1593, Train Acc: 0.2622, Train F1: 0.3130, Val Loss: 5.9282, Val Acc: 0.3055, Val F1: 0.3665\n",
            "Epoch: 16/45, Train Loss: 6.0836, Train Acc: 0.2765, Train F1: 0.3316, Val Loss: 6.4897, Val Acc: 0.2628, Val F1: 0.3149\n",
            "Epoch: 17/45, Train Loss: 6.1538, Train Acc: 0.2821, Train F1: 0.3364, Val Loss: 6.1100, Val Acc: 0.2654, Val F1: 0.3177\n",
            "Epoch: 18/45, Train Loss: 6.0559, Train Acc: 0.2957, Train F1: 0.3561, Val Loss: 6.2796, Val Acc: 0.2823, Val F1: 0.3437\n",
            "Epoch: 19/45, Train Loss: 6.0748, Train Acc: 0.3045, Train F1: 0.3696, Val Loss: 5.8379, Val Acc: 0.3401, Val F1: 0.4102\n",
            "Epoch: 20/45, Train Loss: 5.9599, Train Acc: 0.3123, Train F1: 0.3774, Val Loss: 6.0811, Val Acc: 0.3029, Val F1: 0.3764\n",
            "Epoch: 21/45, Train Loss: 5.9425, Train Acc: 0.3139, Train F1: 0.3800, Val Loss: 5.8973, Val Acc: 0.3028, Val F1: 0.3690\n",
            "Epoch: 22/45, Train Loss: 5.9631, Train Acc: 0.3180, Train F1: 0.3849, Val Loss: 6.2368, Val Acc: 0.3254, Val F1: 0.3945\n",
            "Epoch: 23/45, Train Loss: 5.9605, Train Acc: 0.3002, Train F1: 0.3615, Val Loss: 5.7448, Val Acc: 0.3391, Val F1: 0.4076\n",
            "Epoch: 24/45, Train Loss: 5.9168, Train Acc: 0.3214, Train F1: 0.3891, Val Loss: 5.8446, Val Acc: 0.3348, Val F1: 0.4040\n",
            "Epoch: 25/45, Train Loss: 5.8991, Train Acc: 0.3231, Train F1: 0.3908, Val Loss: 5.7373, Val Acc: 0.3670, Val F1: 0.4430\n",
            "Epoch: 26/45, Train Loss: 5.8869, Train Acc: 0.3281, Train F1: 0.3974, Val Loss: 5.6981, Val Acc: 0.3711, Val F1: 0.4474\n",
            "Epoch: 27/45, Train Loss: 5.8425, Train Acc: 0.3400, Train F1: 0.4125, Val Loss: 5.6863, Val Acc: 0.3335, Val F1: 0.4022\n",
            "Epoch: 28/45, Train Loss: 5.7797, Train Acc: 0.3375, Train F1: 0.4090, Val Loss: 5.9435, Val Acc: 0.3210, Val F1: 0.3984\n",
            "Epoch: 29/45, Train Loss: 5.8315, Train Acc: 0.3332, Train F1: 0.4043, Val Loss: 6.0318, Val Acc: 0.3193, Val F1: 0.3968\n",
            "Epoch: 30/45, Train Loss: 5.9113, Train Acc: 0.3411, Train F1: 0.4149, Val Loss: 5.6452, Val Acc: 0.3166, Val F1: 0.3833\n",
            "Epoch: 31/45, Train Loss: 5.7123, Train Acc: 0.3392, Train F1: 0.4109, Val Loss: 5.6024, Val Acc: 0.3437, Val F1: 0.4174\n",
            "Epoch: 32/45, Train Loss: 5.6620, Train Acc: 0.3382, Train F1: 0.4095, Val Loss: 5.5223, Val Acc: 0.3334, Val F1: 0.4020\n",
            "Epoch: 33/45, Train Loss: 5.6318, Train Acc: 0.3313, Train F1: 0.4010, Val Loss: 5.5115, Val Acc: 0.3273, Val F1: 0.3926\n",
            "Epoch: 34/45, Train Loss: 5.6297, Train Acc: 0.3382, Train F1: 0.4081, Val Loss: 5.4863, Val Acc: 0.3349, Val F1: 0.4008\n",
            "Epoch: 35/45, Train Loss: 5.5965, Train Acc: 0.3367, Train F1: 0.4054, Val Loss: 5.5393, Val Acc: 0.3390, Val F1: 0.4095\n",
            "Epoch: 36/45, Train Loss: 5.5778, Train Acc: 0.3338, Train F1: 0.4012, Val Loss: 5.4521, Val Acc: 0.3330, Val F1: 0.3985\n",
            "Epoch: 37/45, Train Loss: 5.5771, Train Acc: 0.3285, Train F1: 0.3949, Val Loss: 5.5677, Val Acc: 0.3248, Val F1: 0.3883\n",
            "Epoch: 38/45, Train Loss: 5.5718, Train Acc: 0.3371, Train F1: 0.4049, Val Loss: 5.4458, Val Acc: 0.3429, Val F1: 0.4097\n",
            "Epoch: 39/45, Train Loss: 5.5459, Train Acc: 0.3347, Train F1: 0.4021, Val Loss: 5.4353, Val Acc: 0.3335, Val F1: 0.3984\n",
            "Epoch: 40/45, Train Loss: 5.5458, Train Acc: 0.3392, Train F1: 0.4076, Val Loss: 5.4212, Val Acc: 0.3420, Val F1: 0.4096\n",
            "Epoch: 41/45, Train Loss: 5.5370, Train Acc: 0.3390, Train F1: 0.4074, Val Loss: 5.4195, Val Acc: 0.3352, Val F1: 0.4007\n",
            "Epoch: 42/45, Train Loss: 5.5355, Train Acc: 0.3366, Train F1: 0.4045, Val Loss: 5.4170, Val Acc: 0.3369, Val F1: 0.4033\n",
            "Epoch: 43/45, Train Loss: 5.5307, Train Acc: 0.3365, Train F1: 0.4047, Val Loss: 5.4161, Val Acc: 0.3363, Val F1: 0.4025\n",
            "Epoch: 44/45, Train Loss: 5.5316, Train Acc: 0.3345, Train F1: 0.4016, Val Loss: 5.4158, Val Acc: 0.3353, Val F1: 0.4013\n",
            "Epoch: 45/45, Train Loss: 5.5288, Train Acc: 0.3358, Train F1: 0.4032, Val Loss: 5.4158, Val Acc: 0.3360, Val F1: 0.4022\n",
            "\n",
            " üîé search 5 : gru --- hidden_size : 32, num_layers : 2, lr : 0.0007, weight_decay : 0.01, batch_size : 128\n",
            "Epoch: 1/45, Train Loss: 8.0515, Train Acc: 0.1535, Train F1: 0.1186, Val Loss: 8.0375, Val Acc: 0.0766, Val F1: 0.0157\n",
            "Epoch: 2/45, Train Loss: 7.9798, Train Acc: 0.0978, Train F1: 0.0592, Val Loss: 7.8476, Val Acc: 0.7075, Val F1: 0.6976\n",
            "Epoch: 3/45, Train Loss: 7.8247, Train Acc: 0.2789, Train F1: 0.2635, Val Loss: 7.7774, Val Acc: 0.0676, Val F1: 0.0959\n",
            "Epoch: 4/45, Train Loss: 7.8339, Train Acc: 0.0667, Train F1: 0.0329, Val Loss: 6.6723, Val Acc: 0.0922, Val F1: 0.0293\n",
            "Epoch: 5/45, Train Loss: 6.6712, Train Acc: 0.1360, Train F1: 0.1132, Val Loss: 6.3833, Val Acc: 0.1907, Val F1: 0.2090\n",
            "Epoch: 6/45, Train Loss: 6.3127, Train Acc: 0.2598, Train F1: 0.3083, Val Loss: 6.0356, Val Acc: 0.3392, Val F1: 0.4125\n",
            "Epoch: 7/45, Train Loss: 6.1805, Train Acc: 0.2907, Train F1: 0.3541, Val Loss: 6.1443, Val Acc: 0.2447, Val F1: 0.3016\n",
            "Epoch: 8/45, Train Loss: 6.0777, Train Acc: 0.2769, Train F1: 0.3363, Val Loss: 6.2530, Val Acc: 0.2572, Val F1: 0.3253\n",
            "Epoch: 9/45, Train Loss: 6.1248, Train Acc: 0.2728, Train F1: 0.3306, Val Loss: 5.8061, Val Acc: 0.3133, Val F1: 0.3786\n",
            "Epoch: 10/45, Train Loss: 5.9338, Train Acc: 0.2978, Train F1: 0.3624, Val Loss: 5.7659, Val Acc: 0.3089, Val F1: 0.3748\n",
            "Epoch: 11/45, Train Loss: 5.9046, Train Acc: 0.2997, Train F1: 0.3641, Val Loss: 5.9633, Val Acc: 0.2951, Val F1: 0.3680\n",
            "Epoch: 12/45, Train Loss: 5.8758, Train Acc: 0.3052, Train F1: 0.3712, Val Loss: 6.1052, Val Acc: 0.2617, Val F1: 0.3132\n",
            "Epoch: 13/45, Train Loss: 5.8137, Train Acc: 0.3055, Train F1: 0.3707, Val Loss: 5.6587, Val Acc: 0.3134, Val F1: 0.3781\n",
            "Epoch: 14/45, Train Loss: 5.7882, Train Acc: 0.3033, Train F1: 0.3691, Val Loss: 5.5735, Val Acc: 0.3189, Val F1: 0.3860\n",
            "Epoch: 15/45, Train Loss: 5.7367, Train Acc: 0.2995, Train F1: 0.3645, Val Loss: 5.6068, Val Acc: 0.2904, Val F1: 0.3502\n",
            "Epoch: 16/45, Train Loss: 5.6779, Train Acc: 0.3189, Train F1: 0.3871, Val Loss: 5.5951, Val Acc: 0.2963, Val F1: 0.3535\n",
            "Epoch: 17/45, Train Loss: 5.7374, Train Acc: 0.3111, Train F1: 0.3766, Val Loss: 5.4977, Val Acc: 0.3342, Val F1: 0.4071\n",
            "Epoch: 18/45, Train Loss: 5.6049, Train Acc: 0.3245, Train F1: 0.3936, Val Loss: 5.5686, Val Acc: 0.3072, Val F1: 0.3732\n",
            "Epoch: 19/45, Train Loss: 5.5993, Train Acc: 0.3364, Train F1: 0.4088, Val Loss: 5.5402, Val Acc: 0.3481, Val F1: 0.4203\n",
            "Epoch: 20/45, Train Loss: 5.5792, Train Acc: 0.3377, Train F1: 0.4097, Val Loss: 5.4538, Val Acc: 0.3633, Val F1: 0.4412\n",
            "Epoch: 21/45, Train Loss: 5.5582, Train Acc: 0.3485, Train F1: 0.4232, Val Loss: 5.4195, Val Acc: 0.3568, Val F1: 0.4311\n",
            "Epoch: 22/45, Train Loss: 5.5743, Train Acc: 0.3545, Train F1: 0.4308, Val Loss: 5.4711, Val Acc: 0.3444, Val F1: 0.4174\n",
            "Epoch: 23/45, Train Loss: 5.5502, Train Acc: 0.3517, Train F1: 0.4268, Val Loss: 5.6236, Val Acc: 0.3677, Val F1: 0.4436\n",
            "Epoch: 24/45, Train Loss: 5.5585, Train Acc: 0.3602, Train F1: 0.4373, Val Loss: 5.5443, Val Acc: 0.3562, Val F1: 0.4342\n",
            "Epoch: 25/45, Train Loss: 5.5418, Train Acc: 0.3600, Train F1: 0.4369, Val Loss: 5.4663, Val Acc: 0.3595, Val F1: 0.4363\n",
            "Epoch: 26/45, Train Loss: 5.5344, Train Acc: 0.3589, Train F1: 0.4355, Val Loss: 5.4224, Val Acc: 0.3516, Val F1: 0.4237\n",
            "Epoch: 27/45, Train Loss: 5.5242, Train Acc: 0.3633, Train F1: 0.4399, Val Loss: 5.4076, Val Acc: 0.3650, Val F1: 0.4424\n",
            "Epoch: 28/45, Train Loss: 5.5276, Train Acc: 0.3608, Train F1: 0.4379, Val Loss: 5.3811, Val Acc: 0.3797, Val F1: 0.4575\n",
            "Epoch: 29/45, Train Loss: 5.5181, Train Acc: 0.3666, Train F1: 0.4444, Val Loss: 5.4921, Val Acc: 0.3634, Val F1: 0.4423\n",
            "Epoch: 30/45, Train Loss: 5.5000, Train Acc: 0.3664, Train F1: 0.4436, Val Loss: 5.4476, Val Acc: 0.3754, Val F1: 0.4523\n",
            "Epoch: 31/45, Train Loss: 5.5073, Train Acc: 0.3663, Train F1: 0.4440, Val Loss: 5.6278, Val Acc: 0.3520, Val F1: 0.4324\n",
            "Epoch: 32/45, Train Loss: 5.4922, Train Acc: 0.3704, Train F1: 0.4484, Val Loss: 5.5434, Val Acc: 0.3708, Val F1: 0.4498\n",
            "Epoch: 33/45, Train Loss: 5.4937, Train Acc: 0.3659, Train F1: 0.4434, Val Loss: 5.3856, Val Acc: 0.3717, Val F1: 0.4478\n",
            "Epoch: 34/45, Train Loss: 5.4748, Train Acc: 0.3734, Train F1: 0.4524, Val Loss: 5.3621, Val Acc: 0.3703, Val F1: 0.4468\n",
            "Epoch: 35/45, Train Loss: 5.4676, Train Acc: 0.3771, Train F1: 0.4569, Val Loss: 5.4699, Val Acc: 0.3662, Val F1: 0.4480\n",
            "Epoch: 36/45, Train Loss: 5.4416, Train Acc: 0.3782, Train F1: 0.4588, Val Loss: 5.3177, Val Acc: 0.3777, Val F1: 0.4556\n",
            "Epoch: 37/45, Train Loss: 5.4159, Train Acc: 0.3761, Train F1: 0.4563, Val Loss: 5.3065, Val Acc: 0.3772, Val F1: 0.4560\n",
            "Epoch: 38/45, Train Loss: 5.3981, Train Acc: 0.3707, Train F1: 0.4504, Val Loss: 5.3018, Val Acc: 0.3716, Val F1: 0.4496\n",
            "Epoch: 39/45, Train Loss: 5.3897, Train Acc: 0.3696, Train F1: 0.4491, Val Loss: 5.2793, Val Acc: 0.3722, Val F1: 0.4494\n",
            "Epoch: 40/45, Train Loss: 5.3797, Train Acc: 0.3686, Train F1: 0.4479, Val Loss: 5.3110, Val Acc: 0.3674, Val F1: 0.4440\n",
            "Epoch: 41/45, Train Loss: 5.3740, Train Acc: 0.3679, Train F1: 0.4474, Val Loss: 5.2847, Val Acc: 0.3650, Val F1: 0.4408\n",
            "Epoch: 42/45, Train Loss: 5.3695, Train Acc: 0.3645, Train F1: 0.4428, Val Loss: 5.2778, Val Acc: 0.3630, Val F1: 0.4404\n",
            "Epoch: 43/45, Train Loss: 5.3640, Train Acc: 0.3639, Train F1: 0.4426, Val Loss: 5.2751, Val Acc: 0.3635, Val F1: 0.4399\n",
            "Epoch: 44/45, Train Loss: 5.3620, Train Acc: 0.3637, Train F1: 0.4417, Val Loss: 5.2747, Val Acc: 0.3632, Val F1: 0.4394\n",
            "Epoch: 45/45, Train Loss: 5.3611, Train Acc: 0.3630, Train F1: 0.4411, Val Loss: 5.2734, Val Acc: 0.3630, Val F1: 0.4397\n",
            "\n",
            " üîé search 6 : gru --- hidden_size : 64, num_layers : 1, lr : 0.0007, weight_decay : 0.01, batch_size : 128\n",
            "Epoch: 1/45, Train Loss: 8.0139, Train Acc: 0.0753, Train F1: 0.0450, Val Loss: 7.8170, Val Acc: 0.0966, Val F1: 0.0501\n",
            "Epoch: 2/45, Train Loss: 7.8149, Train Acc: 0.0880, Train F1: 0.0825, Val Loss: 7.8827, Val Acc: 0.0497, Val F1: 0.0701\n",
            "Epoch: 3/45, Train Loss: 7.4431, Train Acc: 0.1725, Train F1: 0.1909, Val Loss: 6.6795, Val Acc: 0.1551, Val F1: 0.1572\n",
            "Epoch: 4/45, Train Loss: 6.7592, Train Acc: 0.1938, Train F1: 0.2223, Val Loss: 6.7356, Val Acc: 0.2228, Val F1: 0.2560\n",
            "Epoch: 5/45, Train Loss: 6.6127, Train Acc: 0.2414, Train F1: 0.2906, Val Loss: 6.4819, Val Acc: 0.2949, Val F1: 0.3535\n",
            "Epoch: 6/45, Train Loss: 6.4776, Train Acc: 0.2676, Train F1: 0.3264, Val Loss: 6.2158, Val Acc: 0.2823, Val F1: 0.3449\n",
            "Epoch: 7/45, Train Loss: 6.3395, Train Acc: 0.2745, Train F1: 0.3322, Val Loss: 6.1490, Val Acc: 0.2465, Val F1: 0.2891\n",
            "Epoch: 8/45, Train Loss: 6.2618, Train Acc: 0.2377, Train F1: 0.2809, Val Loss: 6.1085, Val Acc: 0.2733, Val F1: 0.3248\n",
            "Epoch: 9/45, Train Loss: 6.1578, Train Acc: 0.2534, Train F1: 0.3021, Val Loss: 5.9332, Val Acc: 0.2164, Val F1: 0.2421\n",
            "Epoch: 10/45, Train Loss: 5.9983, Train Acc: 0.2695, Train F1: 0.3228, Val Loss: 6.3404, Val Acc: 0.2556, Val F1: 0.3197\n",
            "Epoch: 11/45, Train Loss: 5.9283, Train Acc: 0.2792, Train F1: 0.3348, Val Loss: 5.6221, Val Acc: 0.2672, Val F1: 0.3106\n",
            "Epoch: 12/45, Train Loss: 5.8825, Train Acc: 0.2850, Train F1: 0.3423, Val Loss: 7.7629, Val Acc: 0.2513, Val F1: 0.3079\n",
            "Epoch: 13/45, Train Loss: 8.2299, Train Acc: 0.1397, Train F1: 0.1355, Val Loss: 7.8383, Val Acc: 0.0918, Val F1: 0.0467\n",
            "Epoch: 14/45, Train Loss: 7.3869, Train Acc: 0.1521, Train F1: 0.1443, Val Loss: 6.9218, Val Acc: 0.2285, Val F1: 0.2775\n",
            "Epoch: 15/45, Train Loss: 6.6749, Train Acc: 0.2279, Train F1: 0.2696, Val Loss: 6.4751, Val Acc: 0.2626, Val F1: 0.3171\n",
            "Epoch: 16/45, Train Loss: 6.4906, Train Acc: 0.2837, Train F1: 0.3431, Val Loss: 6.3132, Val Acc: 0.2816, Val F1: 0.3426\n",
            "Epoch: 17/45, Train Loss: 6.2283, Train Acc: 0.3176, Train F1: 0.3852, Val Loss: 6.0720, Val Acc: 0.3738, Val F1: 0.4473\n",
            "Epoch: 18/45, Train Loss: 6.0930, Train Acc: 0.3746, Train F1: 0.4521, Val Loss: 5.9859, Val Acc: 0.3664, Val F1: 0.4437\n",
            "Epoch: 19/45, Train Loss: 5.9127, Train Acc: 0.3921, Train F1: 0.4705, Val Loss: 5.8282, Val Acc: 0.4586, Val F1: 0.5394\n",
            "Epoch: 20/45, Train Loss: 5.9059, Train Acc: 0.3703, Train F1: 0.4458, Val Loss: 5.6378, Val Acc: 0.3451, Val F1: 0.4148\n",
            "Epoch: 21/45, Train Loss: 5.7503, Train Acc: 0.3560, Train F1: 0.4285, Val Loss: 5.5750, Val Acc: 0.3261, Val F1: 0.3933\n",
            "Epoch: 22/45, Train Loss: 5.6812, Train Acc: 0.3351, Train F1: 0.4053, Val Loss: 5.7654, Val Acc: 0.2678, Val F1: 0.3227\n",
            "Epoch: 23/45, Train Loss: 5.6410, Train Acc: 0.3493, Train F1: 0.4231, Val Loss: 5.4449, Val Acc: 0.3712, Val F1: 0.4505\n",
            "Epoch: 24/45, Train Loss: 5.5094, Train Acc: 0.3714, Train F1: 0.4497, Val Loss: 5.3284, Val Acc: 0.3909, Val F1: 0.4711\n",
            "Epoch: 25/45, Train Loss: 5.4847, Train Acc: 0.3807, Train F1: 0.4606, Val Loss: 5.3027, Val Acc: 0.3942, Val F1: 0.4761\n",
            "Epoch: 26/45, Train Loss: 5.4493, Train Acc: 0.3899, Train F1: 0.4713, Val Loss: 5.7111, Val Acc: 0.4352, Val F1: 0.5193\n",
            "Epoch: 27/45, Train Loss: 5.3726, Train Acc: 0.4000, Train F1: 0.4828, Val Loss: 5.1778, Val Acc: 0.4425, Val F1: 0.5282\n",
            "Epoch: 28/45, Train Loss: 5.2662, Train Acc: 0.4301, Train F1: 0.5145, Val Loss: 5.1526, Val Acc: 0.3996, Val F1: 0.4798\n",
            "Epoch: 29/45, Train Loss: 5.2107, Train Acc: 0.4336, Train F1: 0.5170, Val Loss: 5.1813, Val Acc: 0.4337, Val F1: 0.5176\n",
            "Epoch: 30/45, Train Loss: 5.2226, Train Acc: 0.4426, Train F1: 0.5261, Val Loss: 5.0039, Val Acc: 0.4534, Val F1: 0.5359\n",
            "Epoch: 31/45, Train Loss: 5.1297, Train Acc: 0.4485, Train F1: 0.5317, Val Loss: 5.0989, Val Acc: 0.4617, Val F1: 0.5483\n",
            "Epoch: 32/45, Train Loss: 5.0711, Train Acc: 0.4564, Train F1: 0.5388, Val Loss: 4.9946, Val Acc: 0.4380, Val F1: 0.5163\n",
            "Epoch: 33/45, Train Loss: 5.0436, Train Acc: 0.4690, Train F1: 0.5512, Val Loss: 4.9187, Val Acc: 0.4568, Val F1: 0.5350\n",
            "Epoch: 34/45, Train Loss: 5.0159, Train Acc: 0.4655, Train F1: 0.5468, Val Loss: 4.8713, Val Acc: 0.4683, Val F1: 0.5479\n",
            "Epoch: 35/45, Train Loss: 4.9815, Train Acc: 0.4771, Train F1: 0.5586, Val Loss: 5.0356, Val Acc: 0.4425, Val F1: 0.5249\n",
            "Epoch: 36/45, Train Loss: 4.9838, Train Acc: 0.4719, Train F1: 0.5536, Val Loss: 4.9392, Val Acc: 0.4325, Val F1: 0.5103\n",
            "Epoch: 37/45, Train Loss: 4.9505, Train Acc: 0.4924, Train F1: 0.5732, Val Loss: 4.8376, Val Acc: 0.4964, Val F1: 0.5752\n",
            "Epoch: 38/45, Train Loss: 4.9363, Train Acc: 0.4855, Train F1: 0.5666, Val Loss: 4.8379, Val Acc: 0.4926, Val F1: 0.5726\n",
            "Epoch: 39/45, Train Loss: 4.9171, Train Acc: 0.4996, Train F1: 0.5810, Val Loss: 4.8440, Val Acc: 0.4735, Val F1: 0.5507\n",
            "Epoch: 40/45, Train Loss: 4.9062, Train Acc: 0.4962, Train F1: 0.5774, Val Loss: 4.8260, Val Acc: 0.5029, Val F1: 0.5816\n",
            "Epoch: 41/45, Train Loss: 4.9106, Train Acc: 0.4935, Train F1: 0.5744, Val Loss: 4.8064, Val Acc: 0.4962, Val F1: 0.5756\n",
            "Epoch: 42/45, Train Loss: 4.8858, Train Acc: 0.5027, Train F1: 0.5837, Val Loss: 4.8046, Val Acc: 0.4824, Val F1: 0.5610\n",
            "Epoch: 43/45, Train Loss: 4.8813, Train Acc: 0.5026, Train F1: 0.5833, Val Loss: 4.7963, Val Acc: 0.4977, Val F1: 0.5768\n",
            "Epoch: 44/45, Train Loss: 4.8750, Train Acc: 0.5040, Train F1: 0.5849, Val Loss: 4.7957, Val Acc: 0.4936, Val F1: 0.5725\n",
            "Epoch: 45/45, Train Loss: 4.8739, Train Acc: 0.5000, Train F1: 0.5806, Val Loss: 4.7948, Val Acc: 0.4980, Val F1: 0.5769\n",
            "\n",
            " üîé search 7 : gru --- hidden_size : 64, num_layers : 2, lr : 0.0007, weight_decay : 0.01, batch_size : 128\n",
            "Epoch: 1/45, Train Loss: 8.0261, Train Acc: 0.0936, Train F1: 0.0547, Val Loss: 7.9123, Val Acc: 0.0796, Val F1: 0.0184\n",
            "Epoch: 2/45, Train Loss: 7.8504, Train Acc: 0.1065, Train F1: 0.0814, Val Loss: 7.5303, Val Acc: 0.1191, Val F1: 0.1536\n",
            "Epoch: 3/45, Train Loss: 7.9452, Train Acc: 0.1948, Train F1: 0.1613, Val Loss: 7.7252, Val Acc: 0.0512, Val F1: 0.0501\n",
            "Epoch: 4/45, Train Loss: 7.8273, Train Acc: 0.1121, Train F1: 0.1004, Val Loss: 7.1257, Val Acc: 0.0491, Val F1: 0.0116\n",
            "Epoch: 5/45, Train Loss: 7.7574, Train Acc: 0.0959, Train F1: 0.0544, Val Loss: 7.8721, Val Acc: 0.0180, Val F1: 0.0125\n",
            "Epoch: 6/45, Train Loss: 6.8591, Train Acc: 0.1250, Train F1: 0.1060, Val Loss: 6.2144, Val Acc: 0.2670, Val F1: 0.3196\n",
            "Epoch: 7/45, Train Loss: 6.2187, Train Acc: 0.2484, Train F1: 0.2913, Val Loss: 5.9800, Val Acc: 0.3171, Val F1: 0.3836\n",
            "Epoch: 8/45, Train Loss: 6.1452, Train Acc: 0.2630, Train F1: 0.3154, Val Loss: 6.0283, Val Acc: 0.2887, Val F1: 0.3487\n",
            "Epoch: 9/45, Train Loss: 6.1505, Train Acc: 0.2755, Train F1: 0.3344, Val Loss: 5.8723, Val Acc: 0.2546, Val F1: 0.3046\n",
            "Epoch: 10/45, Train Loss: 5.9605, Train Acc: 0.3074, Train F1: 0.3739, Val Loss: 5.8678, Val Acc: 0.3077, Val F1: 0.3744\n",
            "Epoch: 11/45, Train Loss: 5.9228, Train Acc: 0.3221, Train F1: 0.3935, Val Loss: 5.7449, Val Acc: 0.3764, Val F1: 0.4541\n",
            "Epoch: 12/45, Train Loss: 5.8065, Train Acc: 0.3300, Train F1: 0.4028, Val Loss: 5.5334, Val Acc: 0.3327, Val F1: 0.4009\n",
            "Epoch: 13/45, Train Loss: 5.7405, Train Acc: 0.3433, Train F1: 0.4165, Val Loss: 5.5195, Val Acc: 0.3849, Val F1: 0.4602\n",
            "Epoch: 14/45, Train Loss: 5.6812, Train Acc: 0.3441, Train F1: 0.4167, Val Loss: 5.5488, Val Acc: 0.3919, Val F1: 0.4687\n",
            "Epoch: 15/45, Train Loss: 5.6986, Train Acc: 0.3383, Train F1: 0.4102, Val Loss: 6.7509, Val Acc: 0.2901, Val F1: 0.3519\n",
            "Epoch: 16/45, Train Loss: 5.6911, Train Acc: 0.3291, Train F1: 0.3994, Val Loss: 5.4897, Val Acc: 0.3569, Val F1: 0.4323\n",
            "Epoch: 17/45, Train Loss: 5.6526, Train Acc: 0.3352, Train F1: 0.4071, Val Loss: 5.8284, Val Acc: 0.3524, Val F1: 0.4378\n",
            "Epoch: 18/45, Train Loss: 5.6190, Train Acc: 0.3459, Train F1: 0.4202, Val Loss: 5.4619, Val Acc: 0.3456, Val F1: 0.4208\n",
            "Epoch: 19/45, Train Loss: 5.5925, Train Acc: 0.3467, Train F1: 0.4211, Val Loss: 5.7434, Val Acc: 0.3393, Val F1: 0.4116\n",
            "Epoch: 20/45, Train Loss: 5.6182, Train Acc: 0.3456, Train F1: 0.4196, Val Loss: 5.5403, Val Acc: 0.3304, Val F1: 0.4020\n",
            "Epoch: 21/45, Train Loss: 5.6217, Train Acc: 0.3473, Train F1: 0.4220, Val Loss: 7.8714, Val Acc: 0.2188, Val F1: 0.3015\n",
            "Epoch: 22/45, Train Loss: 8.0107, Train Acc: 0.1037, Train F1: 0.0888, Val Loss: 7.7712, Val Acc: 0.0462, Val F1: 0.0626\n",
            "Epoch: 23/45, Train Loss: 7.7623, Train Acc: 0.1561, Train F1: 0.1640, Val Loss: 7.6702, Val Acc: 0.0792, Val F1: 0.1195\n",
            "Epoch: 24/45, Train Loss: 7.6803, Train Acc: 0.1364, Train F1: 0.1701, Val Loss: 7.5918, Val Acc: 0.1087, Val F1: 0.1604\n",
            "Epoch: 25/45, Train Loss: 7.0525, Train Acc: 0.1490, Train F1: 0.1689, Val Loss: 5.8207, Val Acc: 0.2733, Val F1: 0.3296\n",
            "Epoch: 26/45, Train Loss: 5.8453, Train Acc: 0.3082, Train F1: 0.3761, Val Loss: 5.9615, Val Acc: 0.4142, Val F1: 0.4955\n",
            "Epoch: 27/45, Train Loss: 5.6616, Train Acc: 0.3449, Train F1: 0.4216, Val Loss: 5.5521, Val Acc: 0.3839, Val F1: 0.4665\n",
            "Epoch: 28/45, Train Loss: 5.6253, Train Acc: 0.3497, Train F1: 0.4248, Val Loss: 5.5617, Val Acc: 0.3684, Val F1: 0.4435\n",
            "Epoch: 29/45, Train Loss: 5.5608, Train Acc: 0.3437, Train F1: 0.4170, Val Loss: 5.4703, Val Acc: 0.3288, Val F1: 0.3952\n",
            "Epoch: 30/45, Train Loss: 5.5639, Train Acc: 0.3440, Train F1: 0.4178, Val Loss: 5.5536, Val Acc: 0.3453, Val F1: 0.4240\n",
            "Epoch: 31/45, Train Loss: 5.5530, Train Acc: 0.3458, Train F1: 0.4199, Val Loss: 5.4932, Val Acc: 0.3550, Val F1: 0.4270\n",
            "Epoch: 32/45, Train Loss: 5.5175, Train Acc: 0.3637, Train F1: 0.4406, Val Loss: 5.4845, Val Acc: 0.3311, Val F1: 0.4040\n",
            "Epoch: 33/45, Train Loss: 5.5015, Train Acc: 0.3492, Train F1: 0.4234, Val Loss: 5.4348, Val Acc: 0.3477, Val F1: 0.4220\n",
            "Epoch: 34/45, Train Loss: 5.5035, Train Acc: 0.3499, Train F1: 0.4242, Val Loss: 5.4270, Val Acc: 0.3403, Val F1: 0.4124\n",
            "Epoch: 35/45, Train Loss: 5.4968, Train Acc: 0.3519, Train F1: 0.4264, Val Loss: 5.3854, Val Acc: 0.3425, Val F1: 0.4120\n",
            "Epoch: 36/45, Train Loss: 5.4832, Train Acc: 0.3594, Train F1: 0.4350, Val Loss: 5.3761, Val Acc: 0.3449, Val F1: 0.4164\n",
            "Epoch: 37/45, Train Loss: 5.4737, Train Acc: 0.3555, Train F1: 0.4308, Val Loss: 5.3768, Val Acc: 0.3457, Val F1: 0.4172\n",
            "Epoch: 38/45, Train Loss: 5.4677, Train Acc: 0.3617, Train F1: 0.4376, Val Loss: 5.3851, Val Acc: 0.3688, Val F1: 0.4440\n",
            "Epoch: 39/45, Train Loss: 5.4673, Train Acc: 0.3600, Train F1: 0.4363, Val Loss: 5.3850, Val Acc: 0.3665, Val F1: 0.4430\n",
            "Epoch: 40/45, Train Loss: 5.4620, Train Acc: 0.3649, Train F1: 0.4413, Val Loss: 5.3816, Val Acc: 0.3567, Val F1: 0.4313\n",
            "Epoch: 41/45, Train Loss: 5.4526, Train Acc: 0.3623, Train F1: 0.4382, Val Loss: 5.3712, Val Acc: 0.3684, Val F1: 0.4440\n",
            "Epoch: 42/45, Train Loss: 5.4491, Train Acc: 0.3615, Train F1: 0.4372, Val Loss: 5.3714, Val Acc: 0.3631, Val F1: 0.4377\n",
            "Epoch: 43/45, Train Loss: 5.4465, Train Acc: 0.3640, Train F1: 0.4400, Val Loss: 5.3704, Val Acc: 0.3637, Val F1: 0.4386\n",
            "Epoch: 44/45, Train Loss: 5.4444, Train Acc: 0.3633, Train F1: 0.4394, Val Loss: 5.3669, Val Acc: 0.3673, Val F1: 0.4423\n",
            "Epoch: 45/45, Train Loss: 5.4429, Train Acc: 0.3637, Train F1: 0.4397, Val Loss: 5.3672, Val Acc: 0.3669, Val F1: 0.4420\n",
            "\n",
            " üîé search 8 : lstm --- hidden_size : 32, num_layers : 1, lr : 0.001, weight_decay : 0.01, batch_size : 128\n",
            "Epoch: 1/45, Train Loss: 8.0445, Train Acc: 0.0582, Train F1: 0.0179, Val Loss: 8.0331, Val Acc: 0.0254, Val F1: 0.0013\n",
            "Epoch: 2/45, Train Loss: 7.9357, Train Acc: 0.1916, Train F1: 0.1530, Val Loss: 7.9005, Val Acc: 0.0115, Val F1: 0.0044\n",
            "Epoch: 3/45, Train Loss: 7.8899, Train Acc: 0.0524, Train F1: 0.0154, Val Loss: 7.8275, Val Acc: 0.0213, Val F1: 0.0064\n",
            "Epoch: 4/45, Train Loss: 7.8328, Train Acc: 0.0658, Train F1: 0.0718, Val Loss: 7.8366, Val Acc: 0.1023, Val F1: 0.1624\n",
            "Epoch: 5/45, Train Loss: 7.7673, Train Acc: 0.1121, Train F1: 0.1325, Val Loss: 7.9521, Val Acc: 0.0278, Val F1: 0.0373\n",
            "Epoch: 6/45, Train Loss: 7.8525, Train Acc: 0.1636, Train F1: 0.1771, Val Loss: 7.8958, Val Acc: 0.0238, Val F1: 0.0271\n",
            "Epoch: 7/45, Train Loss: 7.7562, Train Acc: 0.0920, Train F1: 0.1058, Val Loss: 7.6745, Val Acc: 0.0918, Val F1: 0.0398\n",
            "Epoch: 8/45, Train Loss: 7.6836, Train Acc: 0.0462, Train F1: 0.0264, Val Loss: 7.9170, Val Acc: 0.0123, Val F1: 0.0081\n",
            "Epoch: 9/45, Train Loss: 7.7775, Train Acc: 0.0491, Train F1: 0.0180, Val Loss: 7.6495, Val Acc: 0.0450, Val F1: 0.0259\n",
            "Epoch: 10/45, Train Loss: 7.0940, Train Acc: 0.0941, Train F1: 0.0514, Val Loss: 6.5359, Val Acc: 0.1069, Val F1: 0.0560\n",
            "Epoch: 11/45, Train Loss: 6.6515, Train Acc: 0.1344, Train F1: 0.1114, Val Loss: 7.9423, Val Acc: 0.1096, Val F1: 0.1341\n",
            "Epoch: 12/45, Train Loss: 6.4697, Train Acc: 0.1894, Train F1: 0.2040, Val Loss: 6.2690, Val Acc: 0.2622, Val F1: 0.3117\n",
            "Epoch: 13/45, Train Loss: 6.3146, Train Acc: 0.2478, Train F1: 0.2921, Val Loss: 6.7895, Val Acc: 0.3648, Val F1: 0.4446\n",
            "Epoch: 14/45, Train Loss: 6.2748, Train Acc: 0.2364, Train F1: 0.2761, Val Loss: 6.0968, Val Acc: 0.2975, Val F1: 0.3585\n",
            "Epoch: 15/45, Train Loss: 6.2178, Train Acc: 0.3054, Train F1: 0.3709, Val Loss: 6.0717, Val Acc: 0.3471, Val F1: 0.4226\n",
            "Epoch: 16/45, Train Loss: 6.1411, Train Acc: 0.3468, Train F1: 0.4223, Val Loss: 6.0188, Val Acc: 0.2870, Val F1: 0.3476\n",
            "Epoch: 17/45, Train Loss: 6.0833, Train Acc: 0.3429, Train F1: 0.4171, Val Loss: 6.0692, Val Acc: 0.3444, Val F1: 0.4239\n",
            "Epoch: 18/45, Train Loss: 6.0860, Train Acc: 0.3517, Train F1: 0.4286, Val Loss: 5.9806, Val Acc: 0.3173, Val F1: 0.3868\n",
            "Epoch: 19/45, Train Loss: 6.1873, Train Acc: 0.3231, Train F1: 0.3926, Val Loss: 5.9538, Val Acc: 0.3721, Val F1: 0.4527\n",
            "Epoch: 20/45, Train Loss: 6.0241, Train Acc: 0.3811, Train F1: 0.4633, Val Loss: 5.9005, Val Acc: 0.3863, Val F1: 0.4681\n",
            "Epoch: 21/45, Train Loss: 5.9932, Train Acc: 0.3865, Train F1: 0.4692, Val Loss: 5.9048, Val Acc: 0.3900, Val F1: 0.4716\n",
            "Epoch: 22/45, Train Loss: 5.9681, Train Acc: 0.3972, Train F1: 0.4807, Val Loss: 5.9108, Val Acc: 0.3499, Val F1: 0.4292\n",
            "Epoch: 23/45, Train Loss: 5.9635, Train Acc: 0.3777, Train F1: 0.4590, Val Loss: 5.8102, Val Acc: 0.3741, Val F1: 0.4522\n",
            "Epoch: 24/45, Train Loss: 5.9169, Train Acc: 0.3957, Train F1: 0.4781, Val Loss: 5.7546, Val Acc: 0.3748, Val F1: 0.4509\n",
            "Epoch: 25/45, Train Loss: 5.9699, Train Acc: 0.3759, Train F1: 0.4567, Val Loss: 5.8108, Val Acc: 0.3517, Val F1: 0.4293\n",
            "Epoch: 26/45, Train Loss: 5.8640, Train Acc: 0.3540, Train F1: 0.4307, Val Loss: 5.7901, Val Acc: 0.4106, Val F1: 0.4917\n",
            "Epoch: 27/45, Train Loss: 6.0137, Train Acc: 0.3277, Train F1: 0.3994, Val Loss: 6.6003, Val Acc: 0.3063, Val F1: 0.3816\n",
            "Epoch: 28/45, Train Loss: 5.6993, Train Acc: 0.3209, Train F1: 0.3882, Val Loss: 5.6786, Val Acc: 0.3544, Val F1: 0.4266\n",
            "Epoch: 29/45, Train Loss: 5.6698, Train Acc: 0.3554, Train F1: 0.4288, Val Loss: 5.6320, Val Acc: 0.3058, Val F1: 0.3667\n",
            "Epoch: 30/45, Train Loss: 5.6237, Train Acc: 0.3287, Train F1: 0.3968, Val Loss: 5.4773, Val Acc: 0.3374, Val F1: 0.4056\n",
            "Epoch: 31/45, Train Loss: 5.6054, Train Acc: 0.3223, Train F1: 0.3893, Val Loss: 5.4431, Val Acc: 0.3241, Val F1: 0.3883\n",
            "Epoch: 32/45, Train Loss: 5.5768, Train Acc: 0.3439, Train F1: 0.4157, Val Loss: 5.5554, Val Acc: 0.3472, Val F1: 0.4185\n",
            "Epoch: 33/45, Train Loss: 5.6094, Train Acc: 0.3499, Train F1: 0.4241, Val Loss: 5.6578, Val Acc: 0.3730, Val F1: 0.4532\n",
            "Epoch: 34/45, Train Loss: 5.7143, Train Acc: 0.3408, Train F1: 0.4160, Val Loss: 5.4573, Val Acc: 0.3142, Val F1: 0.3770\n",
            "Epoch: 35/45, Train Loss: 5.6704, Train Acc: 0.3052, Train F1: 0.3676, Val Loss: 5.4607, Val Acc: 0.3110, Val F1: 0.3702\n",
            "Epoch: 36/45, Train Loss: 5.5403, Train Acc: 0.3401, Train F1: 0.4114, Val Loss: 5.4662, Val Acc: 0.3330, Val F1: 0.4026\n",
            "Epoch: 37/45, Train Loss: 5.5830, Train Acc: 0.3293, Train F1: 0.3996, Val Loss: 5.4197, Val Acc: 0.3275, Val F1: 0.3920\n",
            "Epoch: 38/45, Train Loss: 5.5526, Train Acc: 0.3348, Train F1: 0.4046, Val Loss: 5.5181, Val Acc: 0.3569, Val F1: 0.4337\n",
            "Epoch: 39/45, Train Loss: 5.5392, Train Acc: 0.3372, Train F1: 0.4071, Val Loss: 5.3878, Val Acc: 0.3370, Val F1: 0.4048\n",
            "Epoch: 40/45, Train Loss: 5.5025, Train Acc: 0.3481, Train F1: 0.4205, Val Loss: 5.3821, Val Acc: 0.3513, Val F1: 0.4224\n",
            "Epoch: 41/45, Train Loss: 5.4990, Train Acc: 0.3526, Train F1: 0.4263, Val Loss: 5.3796, Val Acc: 0.3499, Val F1: 0.4211\n",
            "Epoch: 42/45, Train Loss: 5.4993, Train Acc: 0.3515, Train F1: 0.4248, Val Loss: 5.3769, Val Acc: 0.3475, Val F1: 0.4177\n",
            "Epoch: 43/45, Train Loss: 5.4934, Train Acc: 0.3502, Train F1: 0.4230, Val Loss: 5.3759, Val Acc: 0.3438, Val F1: 0.4132\n",
            "Epoch: 44/45, Train Loss: 5.4862, Train Acc: 0.3477, Train F1: 0.4199, Val Loss: 5.3759, Val Acc: 0.3470, Val F1: 0.4173\n",
            "Epoch: 45/45, Train Loss: 5.4866, Train Acc: 0.3494, Train F1: 0.4224, Val Loss: 5.3763, Val Acc: 0.3460, Val F1: 0.4161\n",
            "\n",
            " üîé search 9 : lstm --- hidden_size : 32, num_layers : 2, lr : 0.001, weight_decay : 0.01, batch_size : 128\n",
            "Epoch: 1/45, Train Loss: 8.0534, Train Acc: 0.1374, Train F1: 0.0846, Val Loss: 8.0459, Val Acc: 0.0254, Val F1: 0.0013\n",
            "Epoch: 2/45, Train Loss: 8.0501, Train Acc: 0.2322, Train F1: 0.1875, Val Loss: 8.0451, Val Acc: 0.0661, Val F1: 0.0083\n",
            "Epoch: 3/45, Train Loss: 8.0486, Train Acc: 0.1100, Train F1: 0.0709, Val Loss: 8.0475, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 4/45, Train Loss: 8.0495, Train Acc: 0.1372, Train F1: 0.1023, Val Loss: 8.0452, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 5/45, Train Loss: 8.0493, Train Acc: 0.1040, Train F1: 0.0662, Val Loss: 8.0450, Val Acc: 0.0661, Val F1: 0.0083\n",
            "Epoch: 6/45, Train Loss: 8.0486, Train Acc: 0.0863, Train F1: 0.0416, Val Loss: 8.0451, Val Acc: 0.0661, Val F1: 0.0083\n",
            "Epoch: 7/45, Train Loss: 8.0486, Train Acc: 0.1103, Train F1: 0.0643, Val Loss: 8.0451, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 8/45, Train Loss: 8.0483, Train Acc: 0.0815, Train F1: 0.0307, Val Loss: 8.0451, Val Acc: 0.0661, Val F1: 0.0083\n",
            "Epoch: 9/45, Train Loss: 8.0492, Train Acc: 0.1325, Train F1: 0.0895, Val Loss: 8.0450, Val Acc: 0.0661, Val F1: 0.0083\n",
            "Epoch: 10/45, Train Loss: 8.0485, Train Acc: 0.0564, Train F1: 0.0112, Val Loss: 8.0450, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 11/45, Train Loss: 8.0482, Train Acc: 0.5362, Train F1: 0.4739, Val Loss: 8.0450, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 12/45, Train Loss: 8.0488, Train Acc: 0.0074, Train F1: 0.0002, Val Loss: 8.0457, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 13/45, Train Loss: 8.0480, Train Acc: 0.0073, Train F1: 0.0002, Val Loss: 8.0452, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 14/45, Train Loss: 8.0478, Train Acc: 0.0073, Train F1: 0.0002, Val Loss: 8.0451, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 15/45, Train Loss: 8.0478, Train Acc: 0.0372, Train F1: 0.0044, Val Loss: 8.0451, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 16/45, Train Loss: 8.0480, Train Acc: 0.1203, Train F1: 0.0954, Val Loss: 8.0450, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 17/45, Train Loss: 8.0478, Train Acc: 0.2062, Train F1: 0.1757, Val Loss: 8.0450, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 18/45, Train Loss: 8.0478, Train Acc: 0.0161, Train F1: 0.0017, Val Loss: 8.0450, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 19/45, Train Loss: 8.0479, Train Acc: 0.0395, Train F1: 0.0049, Val Loss: 8.0450, Val Acc: 0.0661, Val F1: 0.0083\n",
            "Epoch: 20/45, Train Loss: 8.0477, Train Acc: 0.0491, Train F1: 0.0065, Val Loss: 8.0449, Val Acc: 0.0661, Val F1: 0.0083\n",
            "Epoch: 21/45, Train Loss: 8.0477, Train Acc: 0.0958, Train F1: 0.0582, Val Loss: 8.0449, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 22/45, Train Loss: 8.0476, Train Acc: 0.2003, Train F1: 0.1767, Val Loss: 8.0449, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 23/45, Train Loss: 8.0478, Train Acc: 0.6736, Train F1: 0.6085, Val Loss: 8.0449, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 24/45, Train Loss: 8.0477, Train Acc: 0.1085, Train F1: 0.0514, Val Loss: 8.0449, Val Acc: 0.0254, Val F1: 0.0013\n",
            "Epoch: 25/45, Train Loss: 8.0476, Train Acc: 0.1845, Train F1: 0.1429, Val Loss: 8.0449, Val Acc: 0.0254, Val F1: 0.0013\n",
            "Epoch: 26/45, Train Loss: 8.0477, Train Acc: 0.0660, Train F1: 0.0090, Val Loss: 8.0449, Val Acc: 0.0661, Val F1: 0.0083\n",
            "Epoch: 27/45, Train Loss: 8.0476, Train Acc: 0.1011, Train F1: 0.0430, Val Loss: 8.0449, Val Acc: 0.0661, Val F1: 0.0083\n",
            "Epoch: 28/45, Train Loss: 8.0476, Train Acc: 0.0715, Train F1: 0.0105, Val Loss: 8.0449, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 29/45, Train Loss: 8.0476, Train Acc: 0.0888, Train F1: 0.0276, Val Loss: 8.0449, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 30/45, Train Loss: 8.0475, Train Acc: 0.0734, Train F1: 0.0108, Val Loss: 8.0449, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 31/45, Train Loss: 8.0475, Train Acc: 0.0553, Train F1: 0.0080, Val Loss: 8.0449, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 32/45, Train Loss: 8.0474, Train Acc: 0.0734, Train F1: 0.0109, Val Loss: 8.0449, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 33/45, Train Loss: 8.0474, Train Acc: 0.3463, Train F1: 0.2780, Val Loss: 8.0449, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 34/45, Train Loss: 8.0474, Train Acc: 0.1667, Train F1: 0.1021, Val Loss: 8.0449, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 35/45, Train Loss: 8.0473, Train Acc: 0.2473, Train F1: 0.1811, Val Loss: 8.0449, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 36/45, Train Loss: 8.0473, Train Acc: 0.0661, Train F1: 0.0090, Val Loss: 8.0449, Val Acc: 0.0661, Val F1: 0.0083\n",
            "Epoch: 37/45, Train Loss: 8.0473, Train Acc: 0.0661, Train F1: 0.0091, Val Loss: 8.0449, Val Acc: 0.0661, Val F1: 0.0083\n",
            "Epoch: 38/45, Train Loss: 8.0473, Train Acc: 0.0661, Train F1: 0.0090, Val Loss: 8.0449, Val Acc: 0.0661, Val F1: 0.0083\n",
            "Epoch: 39/45, Train Loss: 8.0473, Train Acc: 0.0661, Train F1: 0.0090, Val Loss: 8.0449, Val Acc: 0.0661, Val F1: 0.0083\n",
            "Epoch: 40/45, Train Loss: 8.0472, Train Acc: 0.0661, Train F1: 0.0091, Val Loss: 8.0449, Val Acc: 0.0661, Val F1: 0.0083\n",
            "Epoch: 41/45, Train Loss: 8.0472, Train Acc: 0.0661, Train F1: 0.0091, Val Loss: 8.0449, Val Acc: 0.0661, Val F1: 0.0083\n",
            "Epoch: 42/45, Train Loss: 8.0472, Train Acc: 0.0661, Train F1: 0.0090, Val Loss: 8.0449, Val Acc: 0.0661, Val F1: 0.0083\n",
            "Epoch: 43/45, Train Loss: 8.0472, Train Acc: 0.0661, Train F1: 0.0089, Val Loss: 8.0449, Val Acc: 0.0661, Val F1: 0.0083\n",
            "Epoch: 44/45, Train Loss: 8.0472, Train Acc: 0.0661, Train F1: 0.0090, Val Loss: 8.0449, Val Acc: 0.0661, Val F1: 0.0083\n",
            "Epoch: 45/45, Train Loss: 8.0472, Train Acc: 0.0661, Train F1: 0.0090, Val Loss: 8.0449, Val Acc: 0.0661, Val F1: 0.0083\n",
            "\n",
            " üîé search 10 : lstm --- hidden_size : 64, num_layers : 1, lr : 0.001, weight_decay : 0.01, batch_size : 128\n",
            "Epoch: 1/45, Train Loss: 8.0425, Train Acc: 0.2817, Train F1: 0.2364, Val Loss: 8.0204, Val Acc: 0.0103, Val F1: 0.0042\n",
            "Epoch: 2/45, Train Loss: 7.9536, Train Acc: 0.3500, Train F1: 0.3059, Val Loss: 7.8506, Val Acc: 0.0116, Val F1: 0.0026\n",
            "Epoch: 3/45, Train Loss: 7.8678, Train Acc: 0.1754, Train F1: 0.1489, Val Loss: 7.8142, Val Acc: 0.0844, Val F1: 0.0253\n",
            "Epoch: 4/45, Train Loss: 7.9052, Train Acc: 0.1797, Train F1: 0.1357, Val Loss: 7.8756, Val Acc: 0.0799, Val F1: 0.0192\n",
            "Epoch: 5/45, Train Loss: 7.8409, Train Acc: 0.1479, Train F1: 0.1258, Val Loss: 7.8662, Val Acc: 0.0157, Val F1: 0.0114\n",
            "Epoch: 6/45, Train Loss: 7.8299, Train Acc: 0.0634, Train F1: 0.0718, Val Loss: 7.9761, Val Acc: 0.0127, Val F1: 0.0092\n",
            "Epoch: 7/45, Train Loss: 7.8964, Train Acc: 0.2837, Train F1: 0.2587, Val Loss: 7.8116, Val Acc: 0.0169, Val F1: 0.0093\n",
            "Epoch: 8/45, Train Loss: 7.7898, Train Acc: 0.0671, Train F1: 0.0480, Val Loss: 7.8732, Val Acc: 0.0222, Val F1: 0.0225\n",
            "Epoch: 9/45, Train Loss: 7.8367, Train Acc: 0.1183, Train F1: 0.1258, Val Loss: 7.9079, Val Acc: 0.0219, Val F1: 0.0253\n",
            "Epoch: 10/45, Train Loss: 7.8594, Train Acc: 0.1178, Train F1: 0.1075, Val Loss: 7.7024, Val Acc: 0.0755, Val F1: 0.1000\n",
            "Epoch: 11/45, Train Loss: 7.8152, Train Acc: 0.1287, Train F1: 0.1373, Val Loss: 7.9228, Val Acc: 0.0237, Val F1: 0.0293\n",
            "Epoch: 12/45, Train Loss: 7.8072, Train Acc: 0.1340, Train F1: 0.1466, Val Loss: 7.6707, Val Acc: 0.1004, Val F1: 0.1225\n",
            "Epoch: 13/45, Train Loss: 7.8074, Train Acc: 0.2250, Train F1: 0.2389, Val Loss: 7.5116, Val Acc: 0.1398, Val F1: 0.1692\n",
            "Epoch: 14/45, Train Loss: 7.7458, Train Acc: 0.0512, Train F1: 0.0465, Val Loss: 7.4848, Val Acc: 0.1588, Val F1: 0.2089\n",
            "Epoch: 15/45, Train Loss: 7.5117, Train Acc: 0.0721, Train F1: 0.0615, Val Loss: 7.7719, Val Acc: 0.0787, Val F1: 0.0186\n",
            "Epoch: 16/45, Train Loss: 7.1283, Train Acc: 0.0968, Train F1: 0.0594, Val Loss: 7.1020, Val Acc: 0.0957, Val F1: 0.0814\n",
            "Epoch: 17/45, Train Loss: 6.5697, Train Acc: 0.1652, Train F1: 0.1645, Val Loss: 6.8789, Val Acc: 0.1344, Val F1: 0.1403\n",
            "Epoch: 18/45, Train Loss: 7.1129, Train Acc: 0.2351, Train F1: 0.2503, Val Loss: 8.0898, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 19/45, Train Loss: 8.0541, Train Acc: 0.1019, Train F1: 0.0688, Val Loss: 7.9783, Val Acc: 0.0774, Val F1: 0.0130\n",
            "Epoch: 20/45, Train Loss: 7.9357, Train Acc: 0.1482, Train F1: 0.1331, Val Loss: 7.9012, Val Acc: 0.2267, Val F1: 0.2699\n",
            "Epoch: 21/45, Train Loss: 7.8671, Train Acc: 0.1552, Train F1: 0.1766, Val Loss: 7.8976, Val Acc: 0.7862, Val F1: 0.7409\n",
            "Epoch: 22/45, Train Loss: 7.8192, Train Acc: 0.1762, Train F1: 0.1553, Val Loss: 7.7327, Val Acc: 0.0279, Val F1: 0.0197\n",
            "Epoch: 23/45, Train Loss: 7.6909, Train Acc: 0.1930, Train F1: 0.1863, Val Loss: 6.6161, Val Acc: 0.0954, Val F1: 0.0326\n",
            "Epoch: 24/45, Train Loss: 6.5431, Train Acc: 0.1800, Train F1: 0.1927, Val Loss: 6.3690, Val Acc: 0.2209, Val F1: 0.2439\n",
            "Epoch: 25/45, Train Loss: 6.3083, Train Acc: 0.2776, Train F1: 0.3338, Val Loss: 6.6326, Val Acc: 0.2518, Val F1: 0.3190\n",
            "Epoch: 26/45, Train Loss: 6.3854, Train Acc: 0.3251, Train F1: 0.3973, Val Loss: 6.8284, Val Acc: 0.2559, Val F1: 0.3265\n",
            "Epoch: 27/45, Train Loss: 6.0310, Train Acc: 0.3750, Train F1: 0.4550, Val Loss: 5.8698, Val Acc: 0.3666, Val F1: 0.4435\n",
            "Epoch: 28/45, Train Loss: 5.8968, Train Acc: 0.3867, Train F1: 0.4658, Val Loss: 5.8330, Val Acc: 0.4186, Val F1: 0.4963\n",
            "Epoch: 29/45, Train Loss: 5.9188, Train Acc: 0.3617, Train F1: 0.4374, Val Loss: 5.6827, Val Acc: 0.3541, Val F1: 0.4244\n",
            "Epoch: 30/45, Train Loss: 6.1747, Train Acc: 0.2768, Train F1: 0.3364, Val Loss: 5.8682, Val Acc: 0.2813, Val F1: 0.3350\n",
            "Epoch: 31/45, Train Loss: 5.9778, Train Acc: 0.2900, Train F1: 0.3487, Val Loss: 5.8835, Val Acc: 0.3120, Val F1: 0.3812\n",
            "Epoch: 32/45, Train Loss: 5.9277, Train Acc: 0.3036, Train F1: 0.3666, Val Loss: 5.8051, Val Acc: 0.3114, Val F1: 0.3755\n",
            "Epoch: 33/45, Train Loss: 5.7953, Train Acc: 0.3243, Train F1: 0.3926, Val Loss: 5.6477, Val Acc: 0.3139, Val F1: 0.3762\n",
            "Epoch: 34/45, Train Loss: 5.8323, Train Acc: 0.3549, Train F1: 0.4223, Val Loss: 5.7407, Val Acc: 0.4953, Val F1: 0.5757\n",
            "Epoch: 35/45, Train Loss: 5.7501, Train Acc: 0.4493, Train F1: 0.5297, Val Loss: 5.5891, Val Acc: 0.2839, Val F1: 0.3362\n",
            "Epoch: 36/45, Train Loss: 5.7607, Train Acc: 0.2951, Train F1: 0.3543, Val Loss: 5.5820, Val Acc: 0.3436, Val F1: 0.4119\n",
            "Epoch: 37/45, Train Loss: 5.7791, Train Acc: 0.3344, Train F1: 0.4043, Val Loss: 5.6122, Val Acc: 0.3499, Val F1: 0.4205\n",
            "Epoch: 38/45, Train Loss: 5.6747, Train Acc: 0.3504, Train F1: 0.4227, Val Loss: 5.5525, Val Acc: 0.3458, Val F1: 0.4153\n",
            "Epoch: 39/45, Train Loss: 5.6735, Train Acc: 0.3430, Train F1: 0.4150, Val Loss: 5.5472, Val Acc: 0.3314, Val F1: 0.3992\n",
            "Epoch: 40/45, Train Loss: 5.6445, Train Acc: 0.3283, Train F1: 0.3960, Val Loss: 5.5459, Val Acc: 0.3352, Val F1: 0.4016\n",
            "Epoch: 41/45, Train Loss: 5.6574, Train Acc: 0.3375, Train F1: 0.4078, Val Loss: 5.5452, Val Acc: 0.3400, Val F1: 0.4087\n",
            "Epoch: 42/45, Train Loss: 5.6341, Train Acc: 0.3378, Train F1: 0.4077, Val Loss: 5.5569, Val Acc: 0.3454, Val F1: 0.4151\n",
            "Epoch: 43/45, Train Loss: 5.6300, Train Acc: 0.3397, Train F1: 0.4102, Val Loss: 5.5333, Val Acc: 0.3413, Val F1: 0.4102\n",
            "Epoch: 44/45, Train Loss: 5.6269, Train Acc: 0.3389, Train F1: 0.4090, Val Loss: 5.5355, Val Acc: 0.3411, Val F1: 0.4100\n",
            "Epoch: 45/45, Train Loss: 5.6246, Train Acc: 0.3384, Train F1: 0.4080, Val Loss: 5.5398, Val Acc: 0.3399, Val F1: 0.4087\n",
            "\n",
            " üîé search 11 : lstm --- hidden_size : 64, num_layers : 2, lr : 0.001, weight_decay : 0.01, batch_size : 128\n",
            "Epoch: 1/45, Train Loss: 8.0522, Train Acc: 0.0973, Train F1: 0.0614, Val Loss: 8.0465, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 2/45, Train Loss: 8.0498, Train Acc: 0.1526, Train F1: 0.1252, Val Loss: 8.0458, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 3/45, Train Loss: 8.0496, Train Acc: 0.2139, Train F1: 0.1699, Val Loss: 8.0449, Val Acc: 0.0254, Val F1: 0.0013\n",
            "Epoch: 4/45, Train Loss: 8.0490, Train Acc: 0.0934, Train F1: 0.0772, Val Loss: 8.0451, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 5/45, Train Loss: 8.0490, Train Acc: 0.0692, Train F1: 0.0128, Val Loss: 8.0450, Val Acc: 0.0661, Val F1: 0.0083\n",
            "Epoch: 6/45, Train Loss: 8.0480, Train Acc: 0.0606, Train F1: 0.0082, Val Loss: 8.0450, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 7/45, Train Loss: 8.0485, Train Acc: 0.1413, Train F1: 0.1200, Val Loss: 8.0451, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 8/45, Train Loss: 8.0482, Train Acc: 0.0963, Train F1: 0.0387, Val Loss: 8.0451, Val Acc: 0.0661, Val F1: 0.0083\n",
            "Epoch: 9/45, Train Loss: 8.0482, Train Acc: 0.0488, Train F1: 0.0159, Val Loss: 8.0450, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 10/45, Train Loss: 8.0487, Train Acc: 0.0588, Train F1: 0.0080, Val Loss: 8.0450, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 11/45, Train Loss: 8.0483, Train Acc: 0.0877, Train F1: 0.0619, Val Loss: 8.0450, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 12/45, Train Loss: 8.0481, Train Acc: 0.1417, Train F1: 0.1122, Val Loss: 8.0450, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 13/45, Train Loss: 8.0487, Train Acc: 0.0952, Train F1: 0.0628, Val Loss: 8.0452, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 14/45, Train Loss: 8.0483, Train Acc: 0.1972, Train F1: 0.1603, Val Loss: 8.0451, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 15/45, Train Loss: 8.0480, Train Acc: 0.1877, Train F1: 0.1285, Val Loss: 8.0450, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 16/45, Train Loss: 8.0484, Train Acc: 0.6055, Train F1: 0.5429, Val Loss: 8.0450, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 17/45, Train Loss: 8.0481, Train Acc: 0.2181, Train F1: 0.1647, Val Loss: 8.0450, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 18/45, Train Loss: 8.0481, Train Acc: 0.0863, Train F1: 0.0715, Val Loss: 8.0449, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 19/45, Train Loss: 8.0483, Train Acc: 0.2838, Train F1: 0.2512, Val Loss: 8.0449, Val Acc: 0.0661, Val F1: 0.0083\n",
            "Epoch: 20/45, Train Loss: 8.0479, Train Acc: 0.3288, Train F1: 0.2801, Val Loss: 8.0449, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 21/45, Train Loss: 8.0477, Train Acc: 0.1774, Train F1: 0.1313, Val Loss: 8.0449, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 22/45, Train Loss: 8.0477, Train Acc: 0.0734, Train F1: 0.0108, Val Loss: 8.0450, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 23/45, Train Loss: 8.0478, Train Acc: 0.1305, Train F1: 0.0825, Val Loss: 8.0449, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 24/45, Train Loss: 8.0478, Train Acc: 0.4131, Train F1: 0.3451, Val Loss: 8.0449, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 25/45, Train Loss: 8.0479, Train Acc: 0.0278, Train F1: 0.0034, Val Loss: 8.0450, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 26/45, Train Loss: 8.0479, Train Acc: 0.3523, Train F1: 0.3061, Val Loss: 8.0450, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 27/45, Train Loss: 8.0478, Train Acc: 0.0734, Train F1: 0.0108, Val Loss: 8.0450, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 28/45, Train Loss: 8.0476, Train Acc: 0.0637, Train F1: 0.0094, Val Loss: 8.0449, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 29/45, Train Loss: 8.0475, Train Acc: 0.1127, Train F1: 0.0511, Val Loss: 8.0449, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 30/45, Train Loss: 8.0475, Train Acc: 0.0663, Train F1: 0.0090, Val Loss: 8.0449, Val Acc: 0.0661, Val F1: 0.0083\n",
            "Epoch: 31/45, Train Loss: 8.0476, Train Acc: 0.0546, Train F1: 0.0070, Val Loss: 8.0449, Val Acc: 0.0661, Val F1: 0.0083\n",
            "Epoch: 32/45, Train Loss: 8.0475, Train Acc: 0.1700, Train F1: 0.1098, Val Loss: 8.0449, Val Acc: 0.0661, Val F1: 0.0083\n",
            "Epoch: 33/45, Train Loss: 8.0475, Train Acc: 0.3063, Train F1: 0.2425, Val Loss: 8.0449, Val Acc: 0.0661, Val F1: 0.0083\n",
            "Epoch: 34/45, Train Loss: 8.0475, Train Acc: 0.3078, Train F1: 0.2438, Val Loss: 8.0449, Val Acc: 0.0661, Val F1: 0.0083\n",
            "Epoch: 35/45, Train Loss: 8.0473, Train Acc: 0.5536, Train F1: 0.4838, Val Loss: 8.0449, Val Acc: 0.0661, Val F1: 0.0083\n",
            "Epoch: 36/45, Train Loss: 8.0473, Train Acc: 0.6471, Train F1: 0.5743, Val Loss: 8.0449, Val Acc: 0.0661, Val F1: 0.0083\n",
            "Epoch: 37/45, Train Loss: 8.0473, Train Acc: 0.4545, Train F1: 0.3864, Val Loss: 8.0449, Val Acc: 0.0661, Val F1: 0.0083\n",
            "Epoch: 38/45, Train Loss: 8.0473, Train Acc: 0.7024, Train F1: 0.6286, Val Loss: 8.0449, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 39/45, Train Loss: 8.0473, Train Acc: 0.4426, Train F1: 0.3751, Val Loss: 8.0449, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 40/45, Train Loss: 8.0472, Train Acc: 0.6944, Train F1: 0.6206, Val Loss: 8.0449, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 41/45, Train Loss: 8.0472, Train Acc: 0.8277, Train F1: 0.7501, Val Loss: 8.0449, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 42/45, Train Loss: 8.0472, Train Acc: 0.8277, Train F1: 0.7501, Val Loss: 8.0449, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 43/45, Train Loss: 8.0472, Train Acc: 0.7466, Train F1: 0.6716, Val Loss: 8.0449, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 44/45, Train Loss: 8.0472, Train Acc: 0.8277, Train F1: 0.7501, Val Loss: 8.0449, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 45/45, Train Loss: 8.0472, Train Acc: 0.8277, Train F1: 0.7501, Val Loss: 8.0449, Val Acc: 0.8277, Val F1: 0.7497\n",
            "\n",
            " üîé search 12 : lstm --- hidden_size : 32, num_layers : 1, lr : 0.0007, weight_decay : 0.01, batch_size : 128\n",
            "Epoch: 1/45, Train Loss: 8.0489, Train Acc: 0.0258, Train F1: 0.0030, Val Loss: 8.0433, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 2/45, Train Loss: 8.0438, Train Acc: 0.1367, Train F1: 0.1110, Val Loss: 8.0323, Val Acc: 0.0766, Val F1: 0.0145\n",
            "Epoch: 3/45, Train Loss: 7.9168, Train Acc: 0.1137, Train F1: 0.0748, Val Loss: 7.8147, Val Acc: 0.0244, Val F1: 0.0156\n",
            "Epoch: 4/45, Train Loss: 7.8240, Train Acc: 0.0695, Train F1: 0.0404, Val Loss: 7.7467, Val Acc: 0.0441, Val F1: 0.0474\n",
            "Epoch: 5/45, Train Loss: 7.7753, Train Acc: 0.0695, Train F1: 0.0667, Val Loss: 7.7563, Val Acc: 0.0858, Val F1: 0.1030\n",
            "Epoch: 6/45, Train Loss: 7.7597, Train Acc: 0.0737, Train F1: 0.0841, Val Loss: 7.7286, Val Acc: 0.0810, Val F1: 0.0990\n",
            "Epoch: 7/45, Train Loss: 7.7521, Train Acc: 0.0807, Train F1: 0.0886, Val Loss: 7.6714, Val Acc: 0.0583, Val F1: 0.0715\n",
            "Epoch: 8/45, Train Loss: 7.7838, Train Acc: 0.1176, Train F1: 0.1295, Val Loss: 7.6676, Val Acc: 0.0599, Val F1: 0.0717\n",
            "Epoch: 9/45, Train Loss: 7.7756, Train Acc: 0.0721, Train F1: 0.0798, Val Loss: 7.7520, Val Acc: 0.0430, Val F1: 0.0511\n",
            "Epoch: 10/45, Train Loss: 7.8223, Train Acc: 0.0625, Train F1: 0.0530, Val Loss: 7.7490, Val Acc: 0.0866, Val F1: 0.0237\n",
            "Epoch: 11/45, Train Loss: 7.5900, Train Acc: 0.0585, Train F1: 0.0227, Val Loss: 7.3324, Val Acc: 0.0719, Val F1: 0.0350\n",
            "Epoch: 12/45, Train Loss: 7.1818, Train Acc: 0.0849, Train F1: 0.0304, Val Loss: 6.7765, Val Acc: 0.0908, Val F1: 0.0304\n",
            "Epoch: 13/45, Train Loss: 6.7593, Train Acc: 0.0981, Train F1: 0.0431, Val Loss: 6.7311, Val Acc: 0.1099, Val F1: 0.0762\n",
            "Epoch: 14/45, Train Loss: 6.6036, Train Acc: 0.1323, Train F1: 0.1044, Val Loss: 6.4560, Val Acc: 0.1460, Val F1: 0.1249\n",
            "Epoch: 15/45, Train Loss: 6.4597, Train Acc: 0.2175, Train F1: 0.2442, Val Loss: 6.2048, Val Acc: 0.2648, Val F1: 0.3115\n",
            "Epoch: 16/45, Train Loss: 6.2432, Train Acc: 0.3255, Train F1: 0.3937, Val Loss: 6.0539, Val Acc: 0.3573, Val F1: 0.4319\n",
            "Epoch: 17/45, Train Loss: 6.1914, Train Acc: 0.3571, Train F1: 0.4319, Val Loss: 6.0291, Val Acc: 0.4536, Val F1: 0.5319\n",
            "Epoch: 18/45, Train Loss: 6.0965, Train Acc: 0.3785, Train F1: 0.4567, Val Loss: 5.9220, Val Acc: 0.4068, Val F1: 0.4875\n",
            "Epoch: 19/45, Train Loss: 6.0388, Train Acc: 0.3507, Train F1: 0.4254, Val Loss: 5.8684, Val Acc: 0.3303, Val F1: 0.3978\n",
            "Epoch: 20/45, Train Loss: 6.0122, Train Acc: 0.3283, Train F1: 0.3990, Val Loss: 5.9515, Val Acc: 0.3646, Val F1: 0.4375\n",
            "Epoch: 21/45, Train Loss: 5.9391, Train Acc: 0.3251, Train F1: 0.3952, Val Loss: 5.8207, Val Acc: 0.3258, Val F1: 0.3923\n",
            "Epoch: 22/45, Train Loss: 7.2675, Train Acc: 0.1981, Train F1: 0.2264, Val Loss: 8.0743, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 23/45, Train Loss: 8.0517, Train Acc: 0.1847, Train F1: 0.1500, Val Loss: 8.0437, Val Acc: 0.8014, Val F1: 0.7425\n",
            "Epoch: 24/45, Train Loss: 8.0448, Train Acc: 0.1435, Train F1: 0.1061, Val Loss: 8.0359, Val Acc: 0.0247, Val F1: 0.0013\n",
            "Epoch: 25/45, Train Loss: 8.0475, Train Acc: 0.0971, Train F1: 0.0674, Val Loss: 8.0303, Val Acc: 0.8019, Val F1: 0.7429\n",
            "Epoch: 26/45, Train Loss: 8.0341, Train Acc: 0.2802, Train F1: 0.2425, Val Loss: 8.0327, Val Acc: 0.0101, Val F1: 0.0041\n",
            "Epoch: 27/45, Train Loss: 8.0344, Train Acc: 0.1215, Train F1: 0.1021, Val Loss: 8.0292, Val Acc: 0.0106, Val F1: 0.0044\n",
            "Epoch: 28/45, Train Loss: 8.0159, Train Acc: 0.1168, Train F1: 0.0953, Val Loss: 7.9791, Val Acc: 0.0143, Val F1: 0.0106\n",
            "Epoch: 29/45, Train Loss: 7.9633, Train Acc: 0.0290, Train F1: 0.0096, Val Loss: 7.9152, Val Acc: 0.0185, Val F1: 0.0091\n",
            "Epoch: 30/45, Train Loss: 7.9010, Train Acc: 0.0287, Train F1: 0.0195, Val Loss: 7.9116, Val Acc: 0.0158, Val F1: 0.0121\n",
            "Epoch: 31/45, Train Loss: 7.8562, Train Acc: 0.0280, Train F1: 0.0173, Val Loss: 7.7260, Val Acc: 0.0299, Val F1: 0.0118\n",
            "Epoch: 32/45, Train Loss: 7.7941, Train Acc: 0.0295, Train F1: 0.0140, Val Loss: 7.9092, Val Acc: 0.0216, Val F1: 0.0231\n",
            "Epoch: 33/45, Train Loss: 7.7942, Train Acc: 0.0313, Train F1: 0.0196, Val Loss: 7.7764, Val Acc: 0.0361, Val F1: 0.0239\n",
            "Epoch: 34/45, Train Loss: 7.5806, Train Acc: 0.0572, Train F1: 0.0233, Val Loss: 7.5750, Val Acc: 0.0653, Val F1: 0.0399\n",
            "Epoch: 35/45, Train Loss: 7.5398, Train Acc: 0.0554, Train F1: 0.0212, Val Loss: 7.3142, Val Acc: 0.0549, Val F1: 0.0218\n",
            "Epoch: 36/45, Train Loss: 7.2743, Train Acc: 0.0564, Train F1: 0.0212, Val Loss: 7.2821, Val Acc: 0.0648, Val F1: 0.0418\n",
            "Epoch: 37/45, Train Loss: 7.2223, Train Acc: 0.0575, Train F1: 0.0229, Val Loss: 7.2797, Val Acc: 0.0773, Val F1: 0.0483\n",
            "Epoch: 38/45, Train Loss: 7.1479, Train Acc: 0.0644, Train F1: 0.0374, Val Loss: 7.0473, Val Acc: 0.0643, Val F1: 0.0392\n",
            "Epoch: 39/45, Train Loss: 7.1171, Train Acc: 0.0739, Train F1: 0.0536, Val Loss: 7.0759, Val Acc: 0.0852, Val F1: 0.0721\n",
            "Epoch: 40/45, Train Loss: 7.0450, Train Acc: 0.0810, Train F1: 0.0696, Val Loss: 6.9947, Val Acc: 0.0739, Val F1: 0.0608\n",
            "Epoch: 41/45, Train Loss: 7.0175, Train Acc: 0.0876, Train F1: 0.0790, Val Loss: 7.0530, Val Acc: 0.1080, Val F1: 0.0966\n",
            "Epoch: 42/45, Train Loss: 6.9979, Train Acc: 0.0918, Train F1: 0.0851, Val Loss: 6.9938, Val Acc: 0.1040, Val F1: 0.0993\n",
            "Epoch: 43/45, Train Loss: 6.9916, Train Acc: 0.0977, Train F1: 0.0930, Val Loss: 6.9686, Val Acc: 0.0980, Val F1: 0.0916\n",
            "Epoch: 44/45, Train Loss: 6.9887, Train Acc: 0.0945, Train F1: 0.0879, Val Loss: 6.9605, Val Acc: 0.0943, Val F1: 0.0843\n",
            "Epoch: 45/45, Train Loss: 6.9769, Train Acc: 0.0983, Train F1: 0.0886, Val Loss: 6.9613, Val Acc: 0.0966, Val F1: 0.0873\n",
            "\n",
            " üîé search 13 : lstm --- hidden_size : 32, num_layers : 2, lr : 0.0007, weight_decay : 0.01, batch_size : 128\n",
            "Epoch: 1/45, Train Loss: 8.0500, Train Acc: 0.4223, Train F1: 0.3710, Val Loss: 8.0452, Val Acc: 0.0661, Val F1: 0.0083\n",
            "Epoch: 2/45, Train Loss: 8.0494, Train Acc: 0.1378, Train F1: 0.1038, Val Loss: 8.0450, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 3/45, Train Loss: 8.0486, Train Acc: 0.4944, Train F1: 0.4403, Val Loss: 8.0454, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 4/45, Train Loss: 8.0484, Train Acc: 0.1014, Train F1: 0.0755, Val Loss: 8.0450, Val Acc: 0.0661, Val F1: 0.0083\n",
            "Epoch: 5/45, Train Loss: 8.0486, Train Acc: 0.4060, Train F1: 0.3513, Val Loss: 8.0451, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 6/45, Train Loss: 8.0481, Train Acc: 0.0631, Train F1: 0.0409, Val Loss: 8.0450, Val Acc: 0.0254, Val F1: 0.0013\n",
            "Epoch: 7/45, Train Loss: 8.0482, Train Acc: 0.1021, Train F1: 0.0539, Val Loss: 8.0450, Val Acc: 0.0254, Val F1: 0.0013\n",
            "Epoch: 8/45, Train Loss: 8.0482, Train Acc: 0.1872, Train F1: 0.1566, Val Loss: 8.0450, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 9/45, Train Loss: 8.0482, Train Acc: 0.3494, Train F1: 0.2910, Val Loss: 8.0450, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 10/45, Train Loss: 8.0482, Train Acc: 0.1101, Train F1: 0.0936, Val Loss: 8.0449, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 11/45, Train Loss: 8.0479, Train Acc: 0.2062, Train F1: 0.1675, Val Loss: 8.0450, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 12/45, Train Loss: 8.0477, Train Acc: 0.1617, Train F1: 0.1077, Val Loss: 8.0450, Val Acc: 0.0661, Val F1: 0.0083\n",
            "Epoch: 13/45, Train Loss: 8.0479, Train Acc: 0.1401, Train F1: 0.1186, Val Loss: 8.0450, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 14/45, Train Loss: 8.0481, Train Acc: 0.1963, Train F1: 0.1553, Val Loss: 8.0450, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 15/45, Train Loss: 8.0478, Train Acc: 0.3080, Train F1: 0.2706, Val Loss: 8.0449, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 16/45, Train Loss: 8.0478, Train Acc: 0.0716, Train F1: 0.0465, Val Loss: 8.0449, Val Acc: 0.0661, Val F1: 0.0083\n",
            "Epoch: 17/45, Train Loss: 8.0477, Train Acc: 0.0480, Train F1: 0.0281, Val Loss: 8.0449, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 18/45, Train Loss: 8.0478, Train Acc: 0.2138, Train F1: 0.1728, Val Loss: 8.0449, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 19/45, Train Loss: 8.0477, Train Acc: 0.4838, Train F1: 0.4259, Val Loss: 8.0449, Val Acc: 0.0254, Val F1: 0.0013\n",
            "Epoch: 20/45, Train Loss: 8.0476, Train Acc: 0.1744, Train F1: 0.1377, Val Loss: 8.0449, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 21/45, Train Loss: 8.0476, Train Acc: 0.2518, Train F1: 0.2237, Val Loss: 8.0449, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 22/45, Train Loss: 8.0477, Train Acc: 0.2064, Train F1: 0.1761, Val Loss: 8.0449, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 23/45, Train Loss: 8.0476, Train Acc: 0.6637, Train F1: 0.5923, Val Loss: 8.0449, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 24/45, Train Loss: 8.0476, Train Acc: 0.0555, Train F1: 0.0092, Val Loss: 8.0449, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 25/45, Train Loss: 8.0475, Train Acc: 0.0585, Train F1: 0.0081, Val Loss: 8.0449, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 26/45, Train Loss: 8.0475, Train Acc: 0.1590, Train F1: 0.1039, Val Loss: 8.0449, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 27/45, Train Loss: 8.0474, Train Acc: 0.0260, Train F1: 0.0039, Val Loss: 8.0449, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 28/45, Train Loss: 8.0474, Train Acc: 0.3394, Train F1: 0.2720, Val Loss: 8.0449, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 29/45, Train Loss: 8.0474, Train Acc: 0.6940, Train F1: 0.6191, Val Loss: 8.0449, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 30/45, Train Loss: 8.0474, Train Acc: 0.5783, Train F1: 0.5066, Val Loss: 8.0449, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 31/45, Train Loss: 8.0474, Train Acc: 0.6965, Train F1: 0.6285, Val Loss: 8.0449, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 32/45, Train Loss: 8.0473, Train Acc: 0.0968, Train F1: 0.0821, Val Loss: 8.0449, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 33/45, Train Loss: 8.0473, Train Acc: 0.6543, Train F1: 0.5831, Val Loss: 8.0449, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 34/45, Train Loss: 8.0473, Train Acc: 0.3822, Train F1: 0.3300, Val Loss: 8.0449, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 35/45, Train Loss: 8.0473, Train Acc: 0.5146, Train F1: 0.4633, Val Loss: 8.0449, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 36/45, Train Loss: 8.0473, Train Acc: 0.5855, Train F1: 0.5268, Val Loss: 8.0449, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 37/45, Train Loss: 8.0473, Train Acc: 0.8277, Train F1: 0.7501, Val Loss: 8.0449, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 38/45, Train Loss: 8.0473, Train Acc: 0.8277, Train F1: 0.7501, Val Loss: 8.0449, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 39/45, Train Loss: 8.0472, Train Acc: 0.8277, Train F1: 0.7501, Val Loss: 8.0449, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 40/45, Train Loss: 8.0472, Train Acc: 0.8277, Train F1: 0.7501, Val Loss: 8.0449, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 41/45, Train Loss: 8.0472, Train Acc: 0.8277, Train F1: 0.7501, Val Loss: 8.0449, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 42/45, Train Loss: 8.0472, Train Acc: 0.8277, Train F1: 0.7501, Val Loss: 8.0449, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 43/45, Train Loss: 8.0472, Train Acc: 0.8277, Train F1: 0.7501, Val Loss: 8.0449, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 44/45, Train Loss: 8.0472, Train Acc: 0.8277, Train F1: 0.7501, Val Loss: 8.0449, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 45/45, Train Loss: 8.0472, Train Acc: 0.8277, Train F1: 0.7500, Val Loss: 8.0449, Val Acc: 0.8277, Val F1: 0.7497\n",
            "\n",
            " üîé search 14 : lstm --- hidden_size : 64, num_layers : 1, lr : 0.0007, weight_decay : 0.01, batch_size : 128\n",
            "Epoch: 1/45, Train Loss: 8.0458, Train Acc: 0.0645, Train F1: 0.0246, Val Loss: 8.0300, Val Acc: 0.0763, Val F1: 0.0143\n",
            "Epoch: 2/45, Train Loss: 7.9457, Train Acc: 0.0432, Train F1: 0.0103, Val Loss: 7.8871, Val Acc: 0.0773, Val F1: 0.0134\n",
            "Epoch: 3/45, Train Loss: 7.8885, Train Acc: 0.0316, Train F1: 0.0112, Val Loss: 7.9384, Val Acc: 0.0158, Val F1: 0.0137\n",
            "Epoch: 4/45, Train Loss: 7.8372, Train Acc: 0.0752, Train F1: 0.0811, Val Loss: 7.8404, Val Acc: 0.0661, Val F1: 0.0083\n",
            "Epoch: 5/45, Train Loss: 7.8608, Train Acc: 0.1624, Train F1: 0.1605, Val Loss: 7.8977, Val Acc: 0.0212, Val F1: 0.0221\n",
            "Epoch: 6/45, Train Loss: 7.8929, Train Acc: 0.1117, Train F1: 0.1017, Val Loss: 7.7761, Val Acc: 0.0213, Val F1: 0.0183\n",
            "Epoch: 7/45, Train Loss: 7.8343, Train Acc: 0.0754, Train F1: 0.0825, Val Loss: 7.8800, Val Acc: 0.0767, Val F1: 0.1205\n",
            "Epoch: 8/45, Train Loss: 7.8724, Train Acc: 0.0940, Train F1: 0.1142, Val Loss: 7.9357, Val Acc: 0.0149, Val F1: 0.0112\n",
            "Epoch: 9/45, Train Loss: 7.8763, Train Acc: 0.0380, Train F1: 0.0134, Val Loss: 7.8674, Val Acc: 0.0177, Val F1: 0.0127\n",
            "Epoch: 10/45, Train Loss: 7.7913, Train Acc: 0.0632, Train F1: 0.0638, Val Loss: 7.7743, Val Acc: 0.3489, Val F1: 0.4363\n",
            "Epoch: 11/45, Train Loss: 7.8784, Train Acc: 0.0877, Train F1: 0.0849, Val Loss: 7.6788, Val Acc: 0.0389, Val F1: 0.0122\n",
            "Epoch: 12/45, Train Loss: 7.7800, Train Acc: 0.0464, Train F1: 0.0375, Val Loss: 7.7828, Val Acc: 0.1862, Val F1: 0.2658\n",
            "Epoch: 13/45, Train Loss: 7.6520, Train Acc: 0.1274, Train F1: 0.1549, Val Loss: 7.4126, Val Acc: 0.1391, Val F1: 0.1629\n",
            "Epoch: 14/45, Train Loss: 7.2286, Train Acc: 0.1254, Train F1: 0.1279, Val Loss: 6.7839, Val Acc: 0.1392, Val F1: 0.1182\n",
            "Epoch: 15/45, Train Loss: 7.5656, Train Acc: 0.1035, Train F1: 0.0901, Val Loss: 6.9432, Val Acc: 0.1031, Val F1: 0.0696\n",
            "Epoch: 16/45, Train Loss: 6.7973, Train Acc: 0.1222, Train F1: 0.0979, Val Loss: 7.6547, Val Acc: 0.0704, Val F1: 0.0827\n",
            "Epoch: 17/45, Train Loss: 6.6469, Train Acc: 0.1457, Train F1: 0.1344, Val Loss: 6.6881, Val Acc: 0.1474, Val F1: 0.1524\n",
            "Epoch: 18/45, Train Loss: 6.5264, Train Acc: 0.1693, Train F1: 0.1734, Val Loss: 6.3676, Val Acc: 0.2015, Val F1: 0.2229\n",
            "Epoch: 19/45, Train Loss: 6.4858, Train Acc: 0.1959, Train F1: 0.2168, Val Loss: 6.3399, Val Acc: 0.2112, Val F1: 0.2402\n",
            "Epoch: 20/45, Train Loss: 6.4677, Train Acc: 0.2153, Train F1: 0.2477, Val Loss: 6.2790, Val Acc: 0.2363, Val F1: 0.2696\n",
            "Epoch: 21/45, Train Loss: 6.3499, Train Acc: 0.2434, Train F1: 0.2871, Val Loss: 6.5736, Val Acc: 0.2093, Val F1: 0.2577\n",
            "Epoch: 22/45, Train Loss: 6.2633, Train Acc: 0.2853, Train F1: 0.3449, Val Loss: 6.2244, Val Acc: 0.2718, Val F1: 0.3262\n",
            "Epoch: 23/45, Train Loss: 6.2681, Train Acc: 0.2901, Train F1: 0.3519, Val Loss: 6.0470, Val Acc: 0.3447, Val F1: 0.4175\n",
            "Epoch: 24/45, Train Loss: 6.6358, Train Acc: 0.3167, Train F1: 0.3719, Val Loss: 6.1253, Val Acc: 0.2720, Val F1: 0.3264\n",
            "Epoch: 25/45, Train Loss: 6.2058, Train Acc: 0.2855, Train F1: 0.3450, Val Loss: 6.3306, Val Acc: 0.2646, Val F1: 0.3273\n",
            "Epoch: 26/45, Train Loss: 6.1836, Train Acc: 0.3147, Train F1: 0.3834, Val Loss: 6.0253, Val Acc: 0.3159, Val F1: 0.3824\n",
            "Epoch: 27/45, Train Loss: 6.1611, Train Acc: 0.3314, Train F1: 0.4040, Val Loss: 5.9899, Val Acc: 0.3400, Val F1: 0.4117\n",
            "Epoch: 28/45, Train Loss: 6.1112, Train Acc: 0.3430, Train F1: 0.4178, Val Loss: 6.0251, Val Acc: 0.3248, Val F1: 0.3957\n",
            "Epoch: 29/45, Train Loss: 6.1080, Train Acc: 0.3416, Train F1: 0.4158, Val Loss: 6.0164, Val Acc: 0.3014, Val F1: 0.3649\n",
            "Epoch: 30/45, Train Loss: 6.1629, Train Acc: 0.3391, Train F1: 0.4139, Val Loss: 6.0190, Val Acc: 0.3382, Val F1: 0.4089\n",
            "Epoch: 31/45, Train Loss: 6.0881, Train Acc: 0.3346, Train F1: 0.4079, Val Loss: 5.9488, Val Acc: 0.3556, Val F1: 0.4317\n",
            "Epoch: 32/45, Train Loss: 6.0639, Train Acc: 0.3326, Train F1: 0.4054, Val Loss: 5.9956, Val Acc: 0.3067, Val F1: 0.3738\n",
            "Epoch: 33/45, Train Loss: 6.0431, Train Acc: 0.3235, Train F1: 0.3939, Val Loss: 5.9282, Val Acc: 0.3317, Val F1: 0.4041\n",
            "Epoch: 34/45, Train Loss: 6.0046, Train Acc: 0.3230, Train F1: 0.3927, Val Loss: 5.8833, Val Acc: 0.3250, Val F1: 0.3949\n",
            "Epoch: 35/45, Train Loss: 6.0042, Train Acc: 0.3182, Train F1: 0.3871, Val Loss: 5.9246, Val Acc: 0.3337, Val F1: 0.4021\n",
            "Epoch: 36/45, Train Loss: 6.0312, Train Acc: 0.3100, Train F1: 0.3760, Val Loss: 5.9297, Val Acc: 0.2733, Val F1: 0.3270\n",
            "Epoch: 37/45, Train Loss: 6.0788, Train Acc: 0.2942, Train F1: 0.3588, Val Loss: 5.9229, Val Acc: 0.3153, Val F1: 0.3818\n",
            "Epoch: 38/45, Train Loss: 5.9882, Train Acc: 0.3022, Train F1: 0.3668, Val Loss: 5.9200, Val Acc: 0.2918, Val F1: 0.3540\n",
            "Epoch: 39/45, Train Loss: 5.9767, Train Acc: 0.2990, Train F1: 0.3624, Val Loss: 5.9168, Val Acc: 0.2946, Val F1: 0.3583\n",
            "Epoch: 40/45, Train Loss: 5.9784, Train Acc: 0.2987, Train F1: 0.3629, Val Loss: 5.9084, Val Acc: 0.3012, Val F1: 0.3678\n",
            "Epoch: 41/45, Train Loss: 5.9475, Train Acc: 0.3039, Train F1: 0.3690, Val Loss: 5.8754, Val Acc: 0.3192, Val F1: 0.3861\n",
            "Epoch: 42/45, Train Loss: 5.9532, Train Acc: 0.3012, Train F1: 0.3651, Val Loss: 5.8576, Val Acc: 0.3139, Val F1: 0.3805\n",
            "Epoch: 43/45, Train Loss: 5.9429, Train Acc: 0.3082, Train F1: 0.3741, Val Loss: 5.8611, Val Acc: 0.3050, Val F1: 0.3693\n",
            "Epoch: 44/45, Train Loss: 5.9383, Train Acc: 0.3021, Train F1: 0.3668, Val Loss: 5.8545, Val Acc: 0.3099, Val F1: 0.3749\n",
            "Epoch: 45/45, Train Loss: 5.9352, Train Acc: 0.3073, Train F1: 0.3729, Val Loss: 5.8543, Val Acc: 0.3099, Val F1: 0.3749\n",
            "\n",
            " üîé search 15 : lstm --- hidden_size : 64, num_layers : 2, lr : 0.0007, weight_decay : 0.01, batch_size : 128\n",
            "Epoch: 1/45, Train Loss: 8.0503, Train Acc: 0.0801, Train F1: 0.0403, Val Loss: 8.0459, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 2/45, Train Loss: 8.0498, Train Acc: 0.0860, Train F1: 0.0426, Val Loss: 8.0454, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 3/45, Train Loss: 8.0498, Train Acc: 0.0220, Train F1: 0.0016, Val Loss: 8.0453, Val Acc: 0.0254, Val F1: 0.0013\n",
            "Epoch: 4/45, Train Loss: 8.0491, Train Acc: 0.0075, Train F1: 0.0002, Val Loss: 8.0453, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 5/45, Train Loss: 8.0483, Train Acc: 0.0123, Train F1: 0.0006, Val Loss: 8.0452, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 6/45, Train Loss: 8.0479, Train Acc: 0.0261, Train F1: 0.0032, Val Loss: 8.0450, Val Acc: 0.0661, Val F1: 0.0083\n",
            "Epoch: 7/45, Train Loss: 8.0482, Train Acc: 0.0764, Train F1: 0.0352, Val Loss: 8.0451, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 8/45, Train Loss: 8.0480, Train Acc: 0.3595, Train F1: 0.3171, Val Loss: 8.0451, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 9/45, Train Loss: 8.0482, Train Acc: 0.0213, Train F1: 0.0022, Val Loss: 8.0449, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 10/45, Train Loss: 8.0482, Train Acc: 0.0255, Train F1: 0.0017, Val Loss: 8.0451, Val Acc: 0.0254, Val F1: 0.0013\n",
            "Epoch: 11/45, Train Loss: 8.0479, Train Acc: 0.0176, Train F1: 0.0012, Val Loss: 8.0450, Val Acc: 0.0254, Val F1: 0.0013\n",
            "Epoch: 12/45, Train Loss: 8.0481, Train Acc: 0.0732, Train F1: 0.0109, Val Loss: 8.0450, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 13/45, Train Loss: 8.0480, Train Acc: 0.0660, Train F1: 0.0092, Val Loss: 8.0450, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 14/45, Train Loss: 8.0479, Train Acc: 0.0734, Train F1: 0.0109, Val Loss: 8.0450, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 15/45, Train Loss: 8.0480, Train Acc: 0.0414, Train F1: 0.0065, Val Loss: 8.0450, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 16/45, Train Loss: 8.0479, Train Acc: 0.0618, Train F1: 0.0090, Val Loss: 8.0450, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 17/45, Train Loss: 8.0478, Train Acc: 0.1611, Train F1: 0.1355, Val Loss: 8.0450, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 18/45, Train Loss: 8.0478, Train Acc: 0.0357, Train F1: 0.0072, Val Loss: 8.0449, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 19/45, Train Loss: 8.0478, Train Acc: 0.0472, Train F1: 0.0219, Val Loss: 8.0450, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 20/45, Train Loss: 8.0479, Train Acc: 0.2999, Train F1: 0.2454, Val Loss: 8.0449, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 21/45, Train Loss: 8.0477, Train Acc: 0.3248, Train F1: 0.2863, Val Loss: 8.0449, Val Acc: 0.0254, Val F1: 0.0013\n",
            "Epoch: 22/45, Train Loss: 8.0476, Train Acc: 0.0288, Train F1: 0.0050, Val Loss: 8.0449, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 23/45, Train Loss: 8.0476, Train Acc: 0.1080, Train F1: 0.0882, Val Loss: 8.0449, Val Acc: 0.8277, Val F1: 0.7497\n",
            "Epoch: 24/45, Train Loss: 8.0476, Train Acc: 0.2573, Train F1: 0.1937, Val Loss: 8.0449, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 25/45, Train Loss: 8.0475, Train Acc: 0.1655, Train F1: 0.1445, Val Loss: 8.0449, Val Acc: 0.0073, Val F1: 0.0001\n",
            "Epoch: 26/45, Train Loss: 8.0476, Train Acc: 0.0623, Train F1: 0.0084, Val Loss: 8.0449, Val Acc: 0.0661, Val F1: 0.0083\n",
            "Epoch: 27/45, Train Loss: 8.0475, Train Acc: 0.0734, Train F1: 0.0110, Val Loss: 8.0449, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 28/45, Train Loss: 8.0475, Train Acc: 0.0681, Train F1: 0.0134, Val Loss: 8.0449, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 29/45, Train Loss: 8.0475, Train Acc: 0.0734, Train F1: 0.0109, Val Loss: 8.0449, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 30/45, Train Loss: 8.0474, Train Acc: 0.0673, Train F1: 0.0093, Val Loss: 8.0449, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 31/45, Train Loss: 8.0474, Train Acc: 0.0691, Train F1: 0.0098, Val Loss: 8.0449, Val Acc: 0.0661, Val F1: 0.0083\n",
            "Epoch: 32/45, Train Loss: 8.0474, Train Acc: 0.0636, Train F1: 0.0089, Val Loss: 8.0449, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 33/45, Train Loss: 8.0473, Train Acc: 0.0594, Train F1: 0.0232, Val Loss: 8.0449, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 34/45, Train Loss: 8.0473, Train Acc: 0.0716, Train F1: 0.0104, Val Loss: 8.0449, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 35/45, Train Loss: 8.0473, Train Acc: 0.0709, Train F1: 0.0103, Val Loss: 8.0449, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 36/45, Train Loss: 8.0473, Train Acc: 0.0586, Train F1: 0.0082, Val Loss: 8.0449, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 37/45, Train Loss: 8.0472, Train Acc: 0.0734, Train F1: 0.0109, Val Loss: 8.0449, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 38/45, Train Loss: 8.0473, Train Acc: 0.0734, Train F1: 0.0109, Val Loss: 8.0449, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 39/45, Train Loss: 8.0472, Train Acc: 0.0734, Train F1: 0.0109, Val Loss: 8.0449, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 40/45, Train Loss: 8.0472, Train Acc: 0.0734, Train F1: 0.0109, Val Loss: 8.0449, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 41/45, Train Loss: 8.0472, Train Acc: 0.0734, Train F1: 0.0109, Val Loss: 8.0449, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 42/45, Train Loss: 8.0472, Train Acc: 0.0734, Train F1: 0.0109, Val Loss: 8.0449, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 43/45, Train Loss: 8.0472, Train Acc: 0.0734, Train F1: 0.0108, Val Loss: 8.0449, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 44/45, Train Loss: 8.0472, Train Acc: 0.0734, Train F1: 0.0110, Val Loss: 8.0449, Val Acc: 0.0735, Val F1: 0.0102\n",
            "Epoch: 45/45, Train Loss: 8.0472, Train Acc: 0.0734, Train F1: 0.0108, Val Loss: 8.0449, Val Acc: 0.0735, Val F1: 0.0102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark\n",
        "\n",
        "# Overall, sequence model like lstm and gru is hard to train due to long sequence.\n",
        "# Next experiment will move forward to the next architecture (CNN-based)\n",
        "# Which theorically, is easier to train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3051
        },
        "id": "ADNsAFpbqWqF",
        "outputId": "7e4d48b4-1661-4fae-fe9f-ed15f80332c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       model_name                                     hyperparameter  \\\n",
              "0   zero_baseline                                            seed=42   \n",
              "1             gru  {'weight_decay': 0.01, 'learning_rate': 0.0007...   \n",
              "2             gru  {'weight_decay': 0.01, 'learning_rate': 0.0005...   \n",
              "3             gru  {'weight_decay': 0.01, 'learning_rate': 0.0001...   \n",
              "4             gru  {'weight_decay': 0.01, 'learning_rate': 0.001,...   \n",
              "5             gru  {'weight_decay': 0.01, 'learning_rate': 0.001,...   \n",
              "6             gru  {'weight_decay': 0.01, 'learning_rate': 0.001,...   \n",
              "7             gru  {'weight_decay': 0.01, 'learning_rate': 0.001,...   \n",
              "8             gru  {'weight_decay': 0.01, 'learning_rate': 0.0007...   \n",
              "9             gru  {'weight_decay': 0.01, 'learning_rate': 0.0007...   \n",
              "10            gru  {'weight_decay': 0.01, 'learning_rate': 0.0007...   \n",
              "11            gru  {'weight_decay': 0.01, 'learning_rate': 0.0007...   \n",
              "12           lstm  {'weight_decay': 0.01, 'learning_rate': 0.001,...   \n",
              "13           lstm  {'weight_decay': 0.01, 'learning_rate': 0.001,...   \n",
              "14           lstm  {'weight_decay': 0.01, 'learning_rate': 0.001,...   \n",
              "15           lstm  {'weight_decay': 0.01, 'learning_rate': 0.001,...   \n",
              "16           lstm  {'weight_decay': 0.01, 'learning_rate': 0.0007...   \n",
              "17           lstm  {'weight_decay': 0.01, 'learning_rate': 0.0007...   \n",
              "18           lstm  {'weight_decay': 0.01, 'learning_rate': 0.0007...   \n",
              "19           lstm  {'weight_decay': 0.01, 'learning_rate': 0.0007...   \n",
              "\n",
              "    best_epoch best_train_cost best_val_cost  best_train_recall  \\\n",
              "0            1            None          None           0.827732   \n",
              "1           41        5.507615      5.509489           0.356842   \n",
              "2           31        5.983451      6.093212           0.392644   \n",
              "3           45        6.741659      6.704005           0.221518   \n",
              "4            4        7.810387      7.883294           0.124465   \n",
              "5            1        8.031378      7.965182           0.140471   \n",
              "6           40        3.996663      4.038586           0.445306   \n",
              "7           22         5.27236      4.760894           0.499505   \n",
              "8            1         8.02739      7.880352           0.210234   \n",
              "9            2        7.979831      7.847589           0.097754   \n",
              "10          40        4.906158      4.826031           0.496200   \n",
              "11          26        5.845338      5.961468           0.308216   \n",
              "12          26        5.864016      5.790077           0.354009   \n",
              "13          10        8.048463      8.044958           0.056423   \n",
              "14          21        7.867059      7.897568           0.155243   \n",
              "15           2        8.049805      8.045814           0.152623   \n",
              "16          25        8.047501      8.030314           0.097114   \n",
              "17           2        8.049438      8.044966           0.137806   \n",
              "18          10         7.79125      7.774259           0.063154   \n",
              "19          19         8.04777      8.045049           0.047209   \n",
              "\n",
              "    best_train_precision  best_train_f1  best_val_recall  best_val_precision  \\\n",
              "0               0.685140       0.749716         0.827722            0.685123   \n",
              "1               0.825692       0.433814         0.373018            0.824422   \n",
              "2               0.804989       0.474624         0.450866            0.816760   \n",
              "3               0.812764       0.260281         0.226141            0.816713   \n",
              "4               0.576825       0.128467         0.573804            0.742679   \n",
              "5               0.109344       0.114392         0.821234            0.711592   \n",
              "6               0.849698       0.526997         0.464663            0.849047   \n",
              "7               0.827367       0.582974         0.555850            0.834463   \n",
              "8               0.169824       0.182143         0.751199            0.694037   \n",
              "9               0.082395       0.059245         0.707479            0.689311   \n",
              "10              0.835485       0.577439         0.502947            0.832597   \n",
              "11              0.807866       0.376088         0.414181            0.804355   \n",
              "12              0.805761       0.430653         0.410572            0.802027   \n",
              "13              0.007673       0.011213         0.827722            0.685268   \n",
              "14              0.715464       0.176584         0.786240            0.702104   \n",
              "15              0.114048       0.125235         0.827722            0.685268   \n",
              "16              0.065587       0.067391         0.801864            0.692356   \n",
              "17              0.093675       0.103754         0.827722            0.685268   \n",
              "18              0.439376       0.063762         0.348942            0.632488   \n",
              "19              0.018925       0.021912         0.827722            0.685268   \n",
              "\n",
              "    best_val_f1 best_test_recall best_test_precision best_test_f1  \n",
              "0      0.749702         0.827608            0.684935     0.749543  \n",
              "1      0.451205             None                None         None  \n",
              "2      0.541596             None                None         None  \n",
              "3      0.267453             None                None         None  \n",
              "4      0.632116             None                None         None  \n",
              "5      0.754855             None                None         None  \n",
              "6      0.546155             None                None         None  \n",
              "7      0.634460             None                None         None  \n",
              "8      0.718792             None                None         None  \n",
              "9      0.697626             None                None         None  \n",
              "10     0.581607             None                None         None  \n",
              "11     0.495542             None                None         None  \n",
              "12     0.491736             None                None         None  \n",
              "13     0.749750             None                None         None  \n",
              "14     0.740868             None                None         None  \n",
              "15     0.749750             None                None         None  \n",
              "16     0.742942             None                None         None  \n",
              "17     0.749750             None                None         None  \n",
              "18     0.436329             None                None         None  \n",
              "19     0.749750             None                None         None  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f5ded5e3-5f79-47e3-bb4f-18e185966c9a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>hyperparameter</th>\n",
              "      <th>best_epoch</th>\n",
              "      <th>best_train_cost</th>\n",
              "      <th>best_val_cost</th>\n",
              "      <th>best_train_recall</th>\n",
              "      <th>best_train_precision</th>\n",
              "      <th>best_train_f1</th>\n",
              "      <th>best_val_recall</th>\n",
              "      <th>best_val_precision</th>\n",
              "      <th>best_val_f1</th>\n",
              "      <th>best_test_recall</th>\n",
              "      <th>best_test_precision</th>\n",
              "      <th>best_test_f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>zero_baseline</td>\n",
              "      <td>seed=42</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>0.827732</td>\n",
              "      <td>0.685140</td>\n",
              "      <td>0.749716</td>\n",
              "      <td>0.827722</td>\n",
              "      <td>0.685123</td>\n",
              "      <td>0.749702</td>\n",
              "      <td>0.827608</td>\n",
              "      <td>0.684935</td>\n",
              "      <td>0.749543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gru</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.0007...</td>\n",
              "      <td>41</td>\n",
              "      <td>5.507615</td>\n",
              "      <td>5.509489</td>\n",
              "      <td>0.356842</td>\n",
              "      <td>0.825692</td>\n",
              "      <td>0.433814</td>\n",
              "      <td>0.373018</td>\n",
              "      <td>0.824422</td>\n",
              "      <td>0.451205</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gru</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.0005...</td>\n",
              "      <td>31</td>\n",
              "      <td>5.983451</td>\n",
              "      <td>6.093212</td>\n",
              "      <td>0.392644</td>\n",
              "      <td>0.804989</td>\n",
              "      <td>0.474624</td>\n",
              "      <td>0.450866</td>\n",
              "      <td>0.816760</td>\n",
              "      <td>0.541596</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gru</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.0001...</td>\n",
              "      <td>45</td>\n",
              "      <td>6.741659</td>\n",
              "      <td>6.704005</td>\n",
              "      <td>0.221518</td>\n",
              "      <td>0.812764</td>\n",
              "      <td>0.260281</td>\n",
              "      <td>0.226141</td>\n",
              "      <td>0.816713</td>\n",
              "      <td>0.267453</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gru</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.001,...</td>\n",
              "      <td>4</td>\n",
              "      <td>7.810387</td>\n",
              "      <td>7.883294</td>\n",
              "      <td>0.124465</td>\n",
              "      <td>0.576825</td>\n",
              "      <td>0.128467</td>\n",
              "      <td>0.573804</td>\n",
              "      <td>0.742679</td>\n",
              "      <td>0.632116</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>gru</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.001,...</td>\n",
              "      <td>1</td>\n",
              "      <td>8.031378</td>\n",
              "      <td>7.965182</td>\n",
              "      <td>0.140471</td>\n",
              "      <td>0.109344</td>\n",
              "      <td>0.114392</td>\n",
              "      <td>0.821234</td>\n",
              "      <td>0.711592</td>\n",
              "      <td>0.754855</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>gru</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.001,...</td>\n",
              "      <td>40</td>\n",
              "      <td>3.996663</td>\n",
              "      <td>4.038586</td>\n",
              "      <td>0.445306</td>\n",
              "      <td>0.849698</td>\n",
              "      <td>0.526997</td>\n",
              "      <td>0.464663</td>\n",
              "      <td>0.849047</td>\n",
              "      <td>0.546155</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>gru</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.001,...</td>\n",
              "      <td>22</td>\n",
              "      <td>5.27236</td>\n",
              "      <td>4.760894</td>\n",
              "      <td>0.499505</td>\n",
              "      <td>0.827367</td>\n",
              "      <td>0.582974</td>\n",
              "      <td>0.555850</td>\n",
              "      <td>0.834463</td>\n",
              "      <td>0.634460</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>gru</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.0007...</td>\n",
              "      <td>1</td>\n",
              "      <td>8.02739</td>\n",
              "      <td>7.880352</td>\n",
              "      <td>0.210234</td>\n",
              "      <td>0.169824</td>\n",
              "      <td>0.182143</td>\n",
              "      <td>0.751199</td>\n",
              "      <td>0.694037</td>\n",
              "      <td>0.718792</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>gru</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.0007...</td>\n",
              "      <td>2</td>\n",
              "      <td>7.979831</td>\n",
              "      <td>7.847589</td>\n",
              "      <td>0.097754</td>\n",
              "      <td>0.082395</td>\n",
              "      <td>0.059245</td>\n",
              "      <td>0.707479</td>\n",
              "      <td>0.689311</td>\n",
              "      <td>0.697626</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>gru</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.0007...</td>\n",
              "      <td>40</td>\n",
              "      <td>4.906158</td>\n",
              "      <td>4.826031</td>\n",
              "      <td>0.496200</td>\n",
              "      <td>0.835485</td>\n",
              "      <td>0.577439</td>\n",
              "      <td>0.502947</td>\n",
              "      <td>0.832597</td>\n",
              "      <td>0.581607</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>gru</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.0007...</td>\n",
              "      <td>26</td>\n",
              "      <td>5.845338</td>\n",
              "      <td>5.961468</td>\n",
              "      <td>0.308216</td>\n",
              "      <td>0.807866</td>\n",
              "      <td>0.376088</td>\n",
              "      <td>0.414181</td>\n",
              "      <td>0.804355</td>\n",
              "      <td>0.495542</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>lstm</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.001,...</td>\n",
              "      <td>26</td>\n",
              "      <td>5.864016</td>\n",
              "      <td>5.790077</td>\n",
              "      <td>0.354009</td>\n",
              "      <td>0.805761</td>\n",
              "      <td>0.430653</td>\n",
              "      <td>0.410572</td>\n",
              "      <td>0.802027</td>\n",
              "      <td>0.491736</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>lstm</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.001,...</td>\n",
              "      <td>10</td>\n",
              "      <td>8.048463</td>\n",
              "      <td>8.044958</td>\n",
              "      <td>0.056423</td>\n",
              "      <td>0.007673</td>\n",
              "      <td>0.011213</td>\n",
              "      <td>0.827722</td>\n",
              "      <td>0.685268</td>\n",
              "      <td>0.749750</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>lstm</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.001,...</td>\n",
              "      <td>21</td>\n",
              "      <td>7.867059</td>\n",
              "      <td>7.897568</td>\n",
              "      <td>0.155243</td>\n",
              "      <td>0.715464</td>\n",
              "      <td>0.176584</td>\n",
              "      <td>0.786240</td>\n",
              "      <td>0.702104</td>\n",
              "      <td>0.740868</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>lstm</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.001,...</td>\n",
              "      <td>2</td>\n",
              "      <td>8.049805</td>\n",
              "      <td>8.045814</td>\n",
              "      <td>0.152623</td>\n",
              "      <td>0.114048</td>\n",
              "      <td>0.125235</td>\n",
              "      <td>0.827722</td>\n",
              "      <td>0.685268</td>\n",
              "      <td>0.749750</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>lstm</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.0007...</td>\n",
              "      <td>25</td>\n",
              "      <td>8.047501</td>\n",
              "      <td>8.030314</td>\n",
              "      <td>0.097114</td>\n",
              "      <td>0.065587</td>\n",
              "      <td>0.067391</td>\n",
              "      <td>0.801864</td>\n",
              "      <td>0.692356</td>\n",
              "      <td>0.742942</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>lstm</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.0007...</td>\n",
              "      <td>2</td>\n",
              "      <td>8.049438</td>\n",
              "      <td>8.044966</td>\n",
              "      <td>0.137806</td>\n",
              "      <td>0.093675</td>\n",
              "      <td>0.103754</td>\n",
              "      <td>0.827722</td>\n",
              "      <td>0.685268</td>\n",
              "      <td>0.749750</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>lstm</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.0007...</td>\n",
              "      <td>10</td>\n",
              "      <td>7.79125</td>\n",
              "      <td>7.774259</td>\n",
              "      <td>0.063154</td>\n",
              "      <td>0.439376</td>\n",
              "      <td>0.063762</td>\n",
              "      <td>0.348942</td>\n",
              "      <td>0.632488</td>\n",
              "      <td>0.436329</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>lstm</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.0007...</td>\n",
              "      <td>19</td>\n",
              "      <td>8.04777</td>\n",
              "      <td>8.045049</td>\n",
              "      <td>0.047209</td>\n",
              "      <td>0.018925</td>\n",
              "      <td>0.021912</td>\n",
              "      <td>0.827722</td>\n",
              "      <td>0.685268</td>\n",
              "      <td>0.749750</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5ded5e3-5f79-47e3-bb4f-18e185966c9a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f5ded5e3-5f79-47e3-bb4f-18e185966c9a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f5ded5e3-5f79-47e3-bb4f-18e185966c9a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/99dac6621f6ae8c4/data_table.js\";\n\n      window.createDataTable({\n        data: [[{\n            'v': 0,\n            'f': \"0\",\n        },\n\"zero_baseline\",\n\"seed=42\",\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': 0.8277316683164547,\n            'f': \"0.8277316683164547\",\n        },\n{\n            'v': 0.6851397147339414,\n            'f': \"0.6851397147339414\",\n        },\n{\n            'v': 0.7497158654202581,\n            'f': \"0.7497158654202581\",\n        },\n{\n            'v': 0.8277216866919457,\n            'f': \"0.8277216866919457\",\n        },\n{\n            'v': 0.6851231906201596,\n            'f': \"0.6851231906201596\",\n        },\n{\n            'v': 0.7497018781455581,\n            'f': \"0.7497018781455581\",\n        },\n{\n            'v': 0.8276082587246483,\n            'f': \"0.8276082587246483\",\n        },\n{\n            'v': 0.6849354299092444,\n            'f': \"0.6849354299092444\",\n        },\n{\n            'v': 0.7495429358446977,\n            'f': \"0.7495429358446977\",\n        }],\n [{\n            'v': 1,\n            'f': \"1\",\n        },\n\"gru\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.0007, 'batch_size': 128, 'hidden_size': 32, 'num_layers': 1}\",\n{\n            'v': 41,\n            'f': \"41\",\n        },\n{\n            'v': 5.507614932274097,\n            'f': \"5.507614932274097\",\n        },\n{\n            'v': 5.509488628009624,\n            'f': \"5.509488628009624\",\n        },\n{\n            'v': 0.3568415442016295,\n            'f': \"0.3568415442016295\",\n        },\n{\n            'v': 0.8256916678170723,\n            'f': \"0.8256916678170723\",\n        },\n{\n            'v': 0.43381446358436343,\n            'f': \"0.43381446358436343\",\n        },\n{\n            'v': 0.3730184110740555,\n            'f': \"0.3730184110740555\",\n        },\n{\n            'v': 0.8244220540949647,\n            'f': \"0.8244220540949647\",\n        },\n{\n            'v': 0.4512051344351721,\n            'f': \"0.4512051344351721\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 2,\n            'f': \"2\",\n        },\n\"gru\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.0005, 'batch_size': 128, 'hidden_size': 32, 'num_layers': 1}\",\n{\n            'v': 31,\n            'f': \"31\",\n        },\n{\n            'v': 5.983451240717898,\n            'f': \"5.983451240717898\",\n        },\n{\n            'v': 6.0932123053803116,\n            'f': \"6.0932123053803116\",\n        },\n{\n            'v': 0.3926444833625219,\n            'f': \"0.3926444833625219\",\n        },\n{\n            'v': 0.804988595547416,\n            'f': \"0.804988595547416\",\n        },\n{\n            'v': 0.474623652496336,\n            'f': \"0.474623652496336\",\n        },\n{\n            'v': 0.4508657316460323,\n            'f': \"0.4508657316460323\",\n        },\n{\n            'v': 0.8167604275762758,\n            'f': \"0.8167604275762758\",\n        },\n{\n            'v': 0.5415964601265059,\n            'f': \"0.5415964601265059\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 3,\n            'f': \"3\",\n        },\n\"gru\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.0001, 'batch_size': 128, 'hidden_size': 32, 'num_layers': 1}\",\n{\n            'v': 45,\n            'f': \"45\",\n        },\n{\n            'v': 6.741658943035103,\n            'f': \"6.741658943035103\",\n        },\n{\n            'v': 6.704004760396078,\n            'f': \"6.704004760396078\",\n        },\n{\n            'v': 0.22151831264752914,\n            'f': \"0.22151831264752914\",\n        },\n{\n            'v': 0.8127644637416019,\n            'f': \"0.8127644637416019\",\n        },\n{\n            'v': 0.2602808084672521,\n            'f': \"0.2602808084672521\",\n        },\n{\n            'v': 0.2261409840559185,\n            'f': \"0.2261409840559185\",\n        },\n{\n            'v': 0.8167132825529796,\n            'f': \"0.8167132825529796\",\n        },\n{\n            'v': 0.26745297834508336,\n            'f': \"0.26745297834508336\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 4,\n            'f': \"4\",\n        },\n\"gru\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.001, 'batch_size': 128, 'hidden_size': 32, 'num_layers': 1}\",\n{\n            'v': 4,\n            'f': \"4\",\n        },\n{\n            'v': 7.8103873997842745,\n            'f': \"7.8103873997842745\",\n        },\n{\n            'v': 7.883294439744947,\n            'f': \"7.883294439744947\",\n        },\n{\n            'v': 0.12446508794639458,\n            'f': \"0.12446508794639458\",\n        },\n{\n            'v': 0.5768252494222211,\n            'f': \"0.5768252494222211\",\n        },\n{\n            'v': 0.12846651783101395,\n            'f': \"0.12846651783101395\",\n        },\n{\n            'v': 0.5738041938873407,\n            'f': \"0.5738041938873407\",\n        },\n{\n            'v': 0.7426786712948427,\n            'f': \"0.7426786712948427\",\n        },\n{\n            'v': 0.6321163572367791,\n            'f': \"0.6321163572367791\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 5,\n            'f': \"5\",\n        },\n\"gru\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.001, 'batch_size': 128, 'hidden_size': 32, 'num_layers': 2}\",\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 8.031377988283536,\n            'f': \"8.031377988283536\",\n        },\n{\n            'v': 7.965182493753488,\n            'f': \"7.965182493753488\",\n        },\n{\n            'v': 0.14047057031904364,\n            'f': \"0.14047057031904364\",\n        },\n{\n            'v': 0.10934377855107942,\n            'f': \"0.10934377855107942\",\n        },\n{\n            'v': 0.1143916738210928,\n            'f': \"0.1143916738210928\",\n        },\n{\n            'v': 0.8212344099776143,\n            'f': \"0.8212344099776143\",\n        },\n{\n            'v': 0.7115922302210648,\n            'f': \"0.7115922302210648\",\n        },\n{\n            'v': 0.7548551419094334,\n            'f': \"0.7548551419094334\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 6,\n            'f': \"6\",\n        },\n\"gru\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.001, 'batch_size': 128, 'hidden_size': 64, 'num_layers': 1}\",\n{\n            'v': 40,\n            'f': \"40\",\n        },\n{\n            'v': 3.9966633700865164,\n            'f': \"3.9966633700865164\",\n        },\n{\n            'v': 4.038585996577703,\n            'f': \"4.038585996577703\",\n        },\n{\n            'v': 0.4453057184192492,\n            'f': \"0.4453057184192492\",\n        },\n{\n            'v': 0.8496976832473455,\n            'f': \"0.8496976832473455\",\n        },\n{\n            'v': 0.5269968847654715,\n            'f': \"0.5269968847654715\",\n        },\n{\n            'v': 0.4646626159258075,\n            'f': \"0.4646626159258075\",\n        },\n{\n            'v': 0.8490466643073519,\n            'f': \"0.8490466643073519\",\n        },\n{\n            'v': 0.5461545091288852,\n            'f': \"0.5461545091288852\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 7,\n            'f': \"7\",\n        },\n\"gru\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.001, 'batch_size': 128, 'hidden_size': 64, 'num_layers': 2}\",\n{\n            'v': 22,\n            'f': \"22\",\n        },\n{\n            'v': 5.2723602206511115,\n            'f': \"5.2723602206511115\",\n        },\n{\n            'v': 4.760894384165876,\n            'f': \"4.760894384165876\",\n        },\n{\n            'v': 0.4995050635802939,\n            'f': \"0.4995050635802939\",\n        },\n{\n            'v': 0.8273666884414758,\n            'f': \"0.8273666884414758\",\n        },\n{\n            'v': 0.5829736865012313,\n            'f': \"0.5829736865012313\",\n        },\n{\n            'v': 0.5558499703047193,\n            'f': \"0.5558499703047193\",\n        },\n{\n            'v': 0.8344630313617457,\n            'f': \"0.8344630313617457\",\n        },\n{\n            'v': 0.6344601160667206,\n            'f': \"0.6344601160667206\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 8,\n            'f': \"8\",\n        },\n\"gru\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.0007, 'batch_size': 128, 'hidden_size': 32, 'num_layers': 1}\",\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 8.027389599493958,\n            'f': \"8.027389599493958\",\n        },\n{\n            'v': 7.880352040915215,\n            'f': \"7.880352040915215\",\n        },\n{\n            'v': 0.2102337622782304,\n            'f': \"0.2102337622782304\",\n        },\n{\n            'v': 0.16982360136253113,\n            'f': \"0.16982360136253113\",\n        },\n{\n            'v': 0.18214257944490095,\n            'f': \"0.18214257944490095\",\n        },\n{\n            'v': 0.7511992324912057,\n            'f': \"0.7511992324912057\",\n        },\n{\n            'v': 0.6940372545356985,\n            'f': \"0.6940372545356985\",\n        },\n{\n            'v': 0.7187924553604571,\n            'f': \"0.7187924553604571\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 9,\n            'f': \"9\",\n        },\n\"gru\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.0007, 'batch_size': 128, 'hidden_size': 32, 'num_layers': 2}\",\n{\n            'v': 2,\n            'f': \"2\",\n        },\n{\n            'v': 7.979831332787514,\n            'f': \"7.979831332787514\",\n        },\n{\n            'v': 7.847589151480999,\n            'f': \"7.847589151480999\",\n        },\n{\n            'v': 0.09775375009518009,\n            'f': \"0.09775375009518009\",\n        },\n{\n            'v': 0.08239450298506773,\n            'f': \"0.08239450298506773\",\n        },\n{\n            'v': 0.059244851293035194,\n            'f': \"0.059244851293035194\",\n        },\n{\n            'v': 0.7074786422403947,\n            'f': \"0.7074786422403947\",\n        },\n{\n            'v': 0.6893109743246425,\n            'f': \"0.6893109743246425\",\n        },\n{\n            'v': 0.6976258680093479,\n            'f': \"0.6976258680093479\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 10,\n            'f': \"10\",\n        },\n\"gru\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.0007, 'batch_size': 128, 'hidden_size': 64, 'num_layers': 1}\",\n{\n            'v': 40,\n            'f': \"40\",\n        },\n{\n            'v': 4.906158107245476,\n            'f': \"4.906158107245476\",\n        },\n{\n            'v': 4.826031305370708,\n            'f': \"4.826031305370708\",\n        },\n{\n            'v': 0.49620041117794866,\n            'f': \"0.49620041117794866\",\n        },\n{\n            'v': 0.8354849831106961,\n            'f': \"0.8354849831106961\",\n        },\n{\n            'v': 0.5774392280427413,\n            'f': \"0.5774392280427413\",\n        },\n{\n            'v': 0.5029466855498196,\n            'f': \"0.5029466855498196\",\n        },\n{\n            'v': 0.8325971126656635,\n            'f': \"0.8325971126656635\",\n        },\n{\n            'v': 0.5816070537229479,\n            'f': \"0.5816070537229479\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 11,\n            'f': \"11\",\n        },\n\"gru\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.0007, 'batch_size': 128, 'hidden_size': 64, 'num_layers': 2}\",\n{\n            'v': 26,\n            'f': \"26\",\n        },\n{\n            'v': 5.84533774354421,\n            'f': \"5.84533774354421\",\n        },\n{\n            'v': 5.961467830667195,\n            'f': \"5.961467830667195\",\n        },\n{\n            'v': 0.308215944567121,\n            'f': \"0.308215944567121\",\n        },\n{\n            'v': 0.8078663790705302,\n            'f': \"0.8078663790705302\",\n        },\n{\n            'v': 0.3760881580733837,\n            'f': \"0.3760881580733837\",\n        },\n{\n            'v': 0.41418063867696103,\n            'f': \"0.41418063867696103\",\n        },\n{\n            'v': 0.8043547781806835,\n            'f': \"0.8043547781806835\",\n        },\n{\n            'v': 0.495541650094848,\n            'f': \"0.495541650094848\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 12,\n            'f': \"12\",\n        },\n\"lstm\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.001, 'batch_size': 128, 'hidden_size': 32, 'num_layers': 1}\",\n{\n            'v': 26,\n            'f': \"26\",\n        },\n{\n            'v': 5.864016027996276,\n            'f': \"5.864016027996276\",\n        },\n{\n            'v': 5.790076607528102,\n            'f': \"5.790076607528102\",\n        },\n{\n            'v': 0.3540089849996193,\n            'f': \"0.3540089849996193\",\n        },\n{\n            'v': 0.8057611087962436,\n            'f': \"0.8057611087962436\",\n        },\n{\n            'v': 0.43065253520590807,\n            'f': \"0.43065253520590807\",\n        },\n{\n            'v': 0.41057151994152313,\n            'f': \"0.41057151994152313\",\n        },\n{\n            'v': 0.8020272944499927,\n            'f': \"0.8020272944499927\",\n        },\n{\n            'v': 0.4917363401942384,\n            'f': \"0.4917363401942384\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 13,\n            'f': \"13\",\n        },\n\"lstm\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.001, 'batch_size': 128, 'hidden_size': 32, 'num_layers': 2}\",\n{\n            'v': 10,\n            'f': \"10\",\n        },\n{\n            'v': 8.048462614620629,\n            'f': \"8.048462614620629\",\n        },\n{\n            'v': 8.04495843733706,\n            'f': \"8.04495843733706\",\n        },\n{\n            'v': 0.05642275184649356,\n            'f': \"0.05642275184649356\",\n        },\n{\n            'v': 0.007672585281352318,\n            'f': \"0.007672585281352318\",\n        },\n{\n            'v': 0.011213340897468008,\n            'f': \"0.011213340897468008\",\n        },\n{\n            'v': 0.8277216866919457,\n            'f': \"0.8277216866919457\",\n        },\n{\n            'v': 0.6852681704859168,\n            'f': \"0.6852681704859168\",\n        },\n{\n            'v': 0.749749548792234,\n            'f': \"0.749749548792234\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 14,\n            'f': \"14\",\n        },\n\"lstm\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.001, 'batch_size': 128, 'hidden_size': 64, 'num_layers': 1}\",\n{\n            'v': 21,\n            'f': \"21\",\n        },\n{\n            'v': 7.867058732703318,\n            'f': \"7.867058732703318\",\n        },\n{\n            'v': 7.897568186430962,\n            'f': \"7.897568186430962\",\n        },\n{\n            'v': 0.15524251884565599,\n            'f': \"0.15524251884565599\",\n        },\n{\n            'v': 0.7154641944986406,\n            'f': \"0.7154641944986406\",\n        },\n{\n            'v': 0.1765839946390177,\n            'f': \"0.1765839946390177\",\n        },\n{\n            'v': 0.786239663758052,\n            'f': \"0.786239663758052\",\n        },\n{\n            'v': 0.7021038825095346,\n            'f': \"0.7021038825095346\",\n        },\n{\n            'v': 0.7408684332231934,\n            'f': \"0.7408684332231934\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 15,\n            'f': \"15\",\n        },\n\"lstm\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.001, 'batch_size': 128, 'hidden_size': 64, 'num_layers': 2}\",\n{\n            'v': 2,\n            'f': \"2\",\n        },\n{\n            'v': 8.04980544505856,\n            'f': \"8.04980544505856\",\n        },\n{\n            'v': 8.0458136935663,\n            'f': \"8.0458136935663\",\n        },\n{\n            'v': 0.15262316302444223,\n            'f': \"0.15262316302444223\",\n        },\n{\n            'v': 0.11404798503769131,\n            'f': \"0.11404798503769131\",\n        },\n{\n            'v': 0.1252346957567576,\n            'f': \"0.1252346957567576\",\n        },\n{\n            'v': 0.8277216866919457,\n            'f': \"0.8277216866919457\",\n        },\n{\n            'v': 0.6852681704859168,\n            'f': \"0.6852681704859168\",\n        },\n{\n            'v': 0.749749548792234,\n            'f': \"0.749749548792234\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 16,\n            'f': \"16\",\n        },\n\"lstm\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.0007, 'batch_size': 128, 'hidden_size': 32, 'num_layers': 1}\",\n{\n            'v': 25,\n            'f': \"25\",\n        },\n{\n            'v': 8.047500555242795,\n            'f': \"8.047500555242795\",\n        },\n{\n            'v': 8.03031379009231,\n            'f': \"8.03031379009231\",\n        },\n{\n            'v': 0.09711413995279068,\n            'f': \"0.09711413995279068\",\n        },\n{\n            'v': 0.06558696619074902,\n            'f': \"0.06558696619074902\",\n        },\n{\n            'v': 0.06739145353830464,\n            'f': \"0.06739145353830464\",\n        },\n{\n            'v': 0.8018639499291882,\n            'f': \"0.8018639499291882\",\n        },\n{\n            'v': 0.6923563773079917,\n            'f': \"0.6923563773079917\",\n        },\n{\n            'v': 0.7429418578613375,\n            'f': \"0.7429418578613375\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 17,\n            'f': \"17\",\n        },\n\"lstm\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.0007, 'batch_size': 128, 'hidden_size': 32, 'num_layers': 2}\",\n{\n            'v': 2,\n            'f': \"2\",\n        },\n{\n            'v': 8.049438494097602,\n            'f': \"8.049438494097602\",\n        },\n{\n            'v': 8.044965663982934,\n            'f': \"8.044965663982934\",\n        },\n{\n            'v': 0.1378055280590878,\n            'f': \"0.1378055280590878\",\n        },\n{\n            'v': 0.09367498345132332,\n            'f': \"0.09367498345132332\",\n        },\n{\n            'v': 0.10375417509740538,\n            'f': \"0.10375417509740538\",\n        },\n{\n            'v': 0.8277216866919457,\n            'f': \"0.8277216866919457\",\n        },\n{\n            'v': 0.6852681704859168,\n            'f': \"0.6852681704859168\",\n        },\n{\n            'v': 0.749749548792234,\n            'f': \"0.749749548792234\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 18,\n            'f': \"18\",\n        },\n\"lstm\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.0007, 'batch_size': 128, 'hidden_size': 64, 'num_layers': 1}\",\n{\n            'v': 10,\n            'f': \"10\",\n        },\n{\n            'v': 7.791250187780818,\n            'f': \"7.791250187780818\",\n        },\n{\n            'v': 7.774258605526224,\n            'f': \"7.774258605526224\",\n        },\n{\n            'v': 0.06315388715449631,\n            'f': \"0.06315388715449631\",\n        },\n{\n            'v': 0.4393761037543724,\n            'f': \"0.4393761037543724\",\n        },\n{\n            'v': 0.06376215242951365,\n            'f': \"0.06376215242951365\",\n        },\n{\n            'v': 0.34894239115537484,\n            'f': \"0.34894239115537484\",\n        },\n{\n            'v': 0.6324877237952132,\n            'f': \"0.6324877237952132\",\n        },\n{\n            'v': 0.4363285487243902,\n            'f': \"0.4363285487243902\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 19,\n            'f': \"19\",\n        },\n\"lstm\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.0007, 'batch_size': 128, 'hidden_size': 64, 'num_layers': 2}\",\n{\n            'v': 19,\n            'f': \"19\",\n        },\n{\n            'v': 8.047769785479254,\n            'f': \"8.047769785479254\",\n        },\n{\n            'v': 8.045048813913775,\n            'f': \"8.045048813913775\",\n        },\n{\n            'v': 0.04720932003350339,\n            'f': \"0.04720932003350339\",\n        },\n{\n            'v': 0.01892501237341049,\n            'f': \"0.01892501237341049\",\n        },\n{\n            'v': 0.02191201717418135,\n            'f': \"0.02191201717418135\",\n        },\n{\n            'v': 0.8277216866919457,\n            'f': \"0.8277216866919457\",\n        },\n{\n            'v': 0.6852681704859168,\n            'f': \"0.6852681704859168\",\n        },\n{\n            'v': 0.749749548792234,\n            'f': \"0.749749548792234\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }]],\n        columns: [[\"number\", \"index\"], [\"string\", \"model_name\"], [\"string\", \"hyperparameter\"], [\"number\", \"best_epoch\"], [\"number\", \"best_train_cost\"], [\"number\", \"best_val_cost\"], [\"number\", \"best_train_recall\"], [\"number\", \"best_train_precision\"], [\"number\", \"best_train_f1\"], [\"number\", \"best_val_recall\"], [\"number\", \"best_val_precision\"], [\"number\", \"best_val_f1\"], [\"number\", \"best_test_recall\"], [\"number\", \"best_test_precision\"], [\"number\", \"best_test_f1\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: \"0\",\n      });\n    "
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although the validation f1 score of the best sequence model seems to be good, it is not significant when compared to the zero baseline. Moreover, the cost function for this model is relatively high, indicating that the model learned to predict most observations as class zero (normal).\n",
        "\n",
        "The best model's highest validation f1 score being at epoch 1 can be attributed to parameter initialization, causing the model to predict everything as class zero.\n",
        "\n",
        "During the first 45 epochs of training, the sequence models (RNN-based) struggled to learn. This difficulty may have been due to zero-padding and a long sequence length (187), leading to issues with long-term dependencies. To truly assess their performance, we may need to train these models for a longer duration, say 100 epochs. However, before doing so, we will first train the DeepResCNN architecture, which should theoretically converge faster to the local minima.\n",
        "\n",
        "The best sequence model, based on the validation f1 score, appeared to learn to predict almost every ECG heartbeat signal as zero, resulting in similar performance to the zero baseline."
      ],
      "metadata": {
        "id": "2_YcglwDq4HN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the benchmark\n",
        "\n",
        "# benchmark.to_csv('/content/drive/MyDrive/arrhythmia_classification/benchmark.csv',index=False)"
      ],
      "metadata": {
        "id": "jhqB57sTy83t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's try"
      ],
      "metadata": {
        "id": "hAVV-PBvRfpe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "# Define the hyperparameters to search over\n",
        "def experiment_2(benchmark):\n",
        "    name = ['log_reg','deep_rescnn']\n",
        "    weight_decay = [1e-2]\n",
        "    lr = [1e-3,7e-4]\n",
        "    batch_size = [128]\n",
        "\n",
        "    # Create a Cartesian product of all hyperparameter combinations\n",
        "    hyperparams = list(itertools.product(name, weight_decay, lr, batch_size))\n",
        "    print(f'grid search : perform {len(hyperparams)} searchs')\n",
        "\n",
        "    # Loop over each combination of hyperparameters and train/evaluate the model\n",
        "    best_val_f1 = 0.0\n",
        "    num_epochs = 50\n",
        "    for i, (name, wd, lr, bs) in enumerate(hyperparams):\n",
        "\n",
        "        print(f'\\n üîé search {i} : {name} --- lr : {lr}, weight_decay : {wd}, batch_size : {bs}')\n",
        "\n",
        "        # Setup Device\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        # Create the model, optimizer, and loss function\n",
        "        model = get_architecture(name = name, device = device)\n",
        "        class_weights_normalized = get_weighted_for_ce(y_train)\n",
        "        criterion = nn.CrossEntropyLoss(weight=class_weights_normalized.to(device))\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), weight_decay=wd)\n",
        "\n",
        "        # Create the data loaders\n",
        "        train_loader, val_loader, test_loader = get_loader(train_set, val_set, test_set, train_batch_size=bs)\n",
        "\n",
        "        # Train and evaluate the model\n",
        "        scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=0)\n",
        "        model, model_stat = train(model, optimizer, scheduler, criterion, train_loader, val_loader, num_epochs)\n",
        "\n",
        "        \n",
        "        # save the best model configuration based on validation F1 score\n",
        "        if model_stat['best_val_f1'] > best_val_f1:\n",
        "            best_val_f1 = model_stat['best_val_f1']\n",
        "            best_model = deepcopy(model.state_dict())\n",
        "        \n",
        "        row = {'model_name' : name,\n",
        "            'hyperparameter' : {'weight_decay' : wd, 'learning_rate' : lr,\n",
        "                                'batch_size' : bs,},\n",
        "            'best_epoch' : model_stat['best_epoch'],\n",
        "            'best_train_cost' : model_stat['best_train_cost'],\n",
        "            'best_val_cost' : model_stat['best_val_cost'],\n",
        "            'best_train_recall' : model_stat['best_train_recall'],\n",
        "            'best_train_precision' : model_stat['best_train_precision'],\n",
        "            'best_train_f1' : model_stat['best_train_f1'],\n",
        "            'best_val_recall' : model_stat['best_val_recall'],\n",
        "            'best_val_precision' : model_stat['best_val_precision'],\n",
        "            'best_val_f1' : model_stat['best_val_f1'],\n",
        "            'best_test_recall' : None,\n",
        "            'best_test_precision' : None,\n",
        "            'best_test_f1' : None,\n",
        "            }\n",
        "\n",
        "        benchmark =benchmark.append(row, ignore_index=True)\n",
        "\n",
        "    return benchmark, best_model"
      ],
      "metadata": {
        "id": "AlyedXgFsmal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#benchmark, best_model = experiment_2(benchmark)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtOkuRN7tFE1",
        "outputId": "bdb34ba6-35ab-46d4-c3c9-04e285d46533"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grid search : perform 4 searchs\n",
            "\n",
            " üîé search 0 : log_reg --- lr : 0.001, weight_decay : 0.01, batch_size : 128\n",
            "Epoch: 1/50, Train Loss: 5.9745, Train Acc: 0.4343, Train F1: 0.4982, Val Loss: 4.9149, Val Acc: 0.5574, Val F1: 0.6340\n",
            "Epoch: 2/50, Train Loss: 4.6835, Train Acc: 0.5583, Train F1: 0.6389, Val Loss: 4.3519, Val Acc: 0.6321, Val F1: 0.7035\n",
            "Epoch: 3/50, Train Loss: 4.3425, Train Acc: 0.5848, Train F1: 0.6664, Val Loss: 4.1180, Val Acc: 0.5978, Val F1: 0.6774\n",
            "Epoch: 4/50, Train Loss: 4.1665, Train Acc: 0.5945, Train F1: 0.6766, Val Loss: 4.0161, Val Acc: 0.5933, Val F1: 0.6758\n",
            "Epoch: 5/50, Train Loss: 4.0654, Train Acc: 0.6015, Train F1: 0.6829, Val Loss: 3.9628, Val Acc: 0.6026, Val F1: 0.6840\n",
            "Epoch: 6/50, Train Loss: 3.9913, Train Acc: 0.6033, Train F1: 0.6847, Val Loss: 3.8782, Val Acc: 0.6137, Val F1: 0.6941\n",
            "Epoch: 7/50, Train Loss: 3.9352, Train Acc: 0.6118, Train F1: 0.6916, Val Loss: 3.8357, Val Acc: 0.6390, Val F1: 0.7131\n",
            "Epoch: 8/50, Train Loss: 3.8910, Train Acc: 0.6105, Train F1: 0.6909, Val Loss: 3.7946, Val Acc: 0.6250, Val F1: 0.7023\n",
            "Epoch: 9/50, Train Loss: 3.8479, Train Acc: 0.6141, Train F1: 0.6940, Val Loss: 3.7617, Val Acc: 0.5930, Val F1: 0.6743\n",
            "Epoch: 10/50, Train Loss: 3.8222, Train Acc: 0.6092, Train F1: 0.6894, Val Loss: 3.7371, Val Acc: 0.6433, Val F1: 0.7146\n",
            "Epoch: 11/50, Train Loss: 3.8065, Train Acc: 0.6177, Train F1: 0.6964, Val Loss: 3.7083, Val Acc: 0.6059, Val F1: 0.6858\n",
            "Epoch: 12/50, Train Loss: 3.7731, Train Acc: 0.6101, Train F1: 0.6900, Val Loss: 3.7267, Val Acc: 0.6466, Val F1: 0.7192\n",
            "Epoch: 13/50, Train Loss: 3.7568, Train Acc: 0.6191, Train F1: 0.6976, Val Loss: 3.6834, Val Acc: 0.6222, Val F1: 0.6983\n",
            "Epoch: 14/50, Train Loss: 3.7375, Train Acc: 0.6173, Train F1: 0.6962, Val Loss: 3.6793, Val Acc: 0.5884, Val F1: 0.6690\n",
            "Epoch: 15/50, Train Loss: 3.7275, Train Acc: 0.6143, Train F1: 0.6932, Val Loss: 3.6717, Val Acc: 0.6230, Val F1: 0.7001\n",
            "Epoch: 16/50, Train Loss: 3.7141, Train Acc: 0.6171, Train F1: 0.6954, Val Loss: 3.6481, Val Acc: 0.6427, Val F1: 0.7145\n",
            "Epoch: 17/50, Train Loss: 3.7004, Train Acc: 0.6209, Train F1: 0.6989, Val Loss: 3.6806, Val Acc: 0.5954, Val F1: 0.6772\n",
            "Epoch: 18/50, Train Loss: 3.6946, Train Acc: 0.6162, Train F1: 0.6951, Val Loss: 3.6350, Val Acc: 0.6102, Val F1: 0.6881\n",
            "Epoch: 19/50, Train Loss: 3.6863, Train Acc: 0.6149, Train F1: 0.6937, Val Loss: 3.6291, Val Acc: 0.6478, Val F1: 0.7183\n",
            "Epoch: 20/50, Train Loss: 3.6776, Train Acc: 0.6213, Train F1: 0.6991, Val Loss: 3.6256, Val Acc: 0.6489, Val F1: 0.7198\n",
            "Epoch: 21/50, Train Loss: 3.6699, Train Acc: 0.6178, Train F1: 0.6960, Val Loss: 3.6177, Val Acc: 0.6321, Val F1: 0.7060\n",
            "Epoch: 22/50, Train Loss: 3.6611, Train Acc: 0.6196, Train F1: 0.6973, Val Loss: 3.6163, Val Acc: 0.6112, Val F1: 0.6894\n",
            "Epoch: 23/50, Train Loss: 3.6556, Train Acc: 0.6233, Train F1: 0.7003, Val Loss: 3.6258, Val Acc: 0.5754, Val F1: 0.6594\n",
            "Epoch: 24/50, Train Loss: 3.6539, Train Acc: 0.6208, Train F1: 0.6985, Val Loss: 3.6088, Val Acc: 0.6127, Val F1: 0.6909\n",
            "Epoch: 25/50, Train Loss: 3.6489, Train Acc: 0.6205, Train F1: 0.6981, Val Loss: 3.6007, Val Acc: 0.6414, Val F1: 0.7138\n",
            "Epoch: 26/50, Train Loss: 3.6453, Train Acc: 0.6196, Train F1: 0.6976, Val Loss: 3.5942, Val Acc: 0.6080, Val F1: 0.6861\n",
            "Epoch: 27/50, Train Loss: 3.6417, Train Acc: 0.6077, Train F1: 0.6871, Val Loss: 3.5984, Val Acc: 0.6344, Val F1: 0.7082\n",
            "Epoch: 28/50, Train Loss: 3.6350, Train Acc: 0.6233, Train F1: 0.7006, Val Loss: 3.5937, Val Acc: 0.6330, Val F1: 0.7075\n",
            "Epoch: 29/50, Train Loss: 3.6318, Train Acc: 0.6220, Train F1: 0.6997, Val Loss: 3.5863, Val Acc: 0.6131, Val F1: 0.6901\n",
            "Epoch: 30/50, Train Loss: 3.6318, Train Acc: 0.6211, Train F1: 0.6987, Val Loss: 3.5848, Val Acc: 0.6380, Val F1: 0.7107\n",
            "Epoch: 31/50, Train Loss: 3.6258, Train Acc: 0.6221, Train F1: 0.6995, Val Loss: 3.5852, Val Acc: 0.6101, Val F1: 0.6876\n",
            "Epoch: 32/50, Train Loss: 3.6236, Train Acc: 0.6237, Train F1: 0.7006, Val Loss: 3.5900, Val Acc: 0.6152, Val F1: 0.6921\n",
            "Epoch: 33/50, Train Loss: 3.6218, Train Acc: 0.6228, Train F1: 0.7001, Val Loss: 3.5877, Val Acc: 0.5909, Val F1: 0.6722\n",
            "Epoch: 34/50, Train Loss: 3.6207, Train Acc: 0.6208, Train F1: 0.6983, Val Loss: 3.5882, Val Acc: 0.6103, Val F1: 0.6889\n",
            "Epoch: 35/50, Train Loss: 3.6186, Train Acc: 0.6196, Train F1: 0.6975, Val Loss: 3.5851, Val Acc: 0.6403, Val F1: 0.7126\n",
            "Epoch: 36/50, Train Loss: 3.6176, Train Acc: 0.6248, Train F1: 0.7014, Val Loss: 3.5828, Val Acc: 0.6050, Val F1: 0.6836\n",
            "Epoch: 37/50, Train Loss: 3.6162, Train Acc: 0.6219, Train F1: 0.6990, Val Loss: 3.5806, Val Acc: 0.6163, Val F1: 0.6935\n",
            "Epoch: 38/50, Train Loss: 3.6147, Train Acc: 0.6221, Train F1: 0.6999, Val Loss: 3.5785, Val Acc: 0.6227, Val F1: 0.6984\n",
            "Epoch: 39/50, Train Loss: 3.6133, Train Acc: 0.6224, Train F1: 0.6997, Val Loss: 3.5787, Val Acc: 0.6303, Val F1: 0.7045\n",
            "Epoch: 40/50, Train Loss: 3.6119, Train Acc: 0.6214, Train F1: 0.6990, Val Loss: 3.5769, Val Acc: 0.6374, Val F1: 0.7104\n",
            "Epoch: 41/50, Train Loss: 3.6116, Train Acc: 0.6300, Train F1: 0.7061, Val Loss: 3.5784, Val Acc: 0.6122, Val F1: 0.6900\n",
            "Epoch: 42/50, Train Loss: 3.6110, Train Acc: 0.6196, Train F1: 0.6976, Val Loss: 3.5771, Val Acc: 0.6211, Val F1: 0.6969\n",
            "Epoch: 43/50, Train Loss: 3.6098, Train Acc: 0.6233, Train F1: 0.7004, Val Loss: 3.5771, Val Acc: 0.6216, Val F1: 0.6975\n",
            "Epoch: 44/50, Train Loss: 3.6089, Train Acc: 0.6210, Train F1: 0.6987, Val Loss: 3.5767, Val Acc: 0.6279, Val F1: 0.7025\n",
            "Epoch: 45/50, Train Loss: 3.6085, Train Acc: 0.6227, Train F1: 0.6999, Val Loss: 3.5760, Val Acc: 0.6280, Val F1: 0.7027\n",
            "Epoch: 46/50, Train Loss: 3.6079, Train Acc: 0.6260, Train F1: 0.7030, Val Loss: 3.5763, Val Acc: 0.6250, Val F1: 0.7002\n",
            "Epoch: 47/50, Train Loss: 3.6076, Train Acc: 0.6238, Train F1: 0.7010, Val Loss: 3.5763, Val Acc: 0.6241, Val F1: 0.6995\n",
            "Epoch: 48/50, Train Loss: 3.6073, Train Acc: 0.6237, Train F1: 0.7009, Val Loss: 3.5763, Val Acc: 0.6240, Val F1: 0.6994\n",
            "Epoch: 49/50, Train Loss: 3.6072, Train Acc: 0.6244, Train F1: 0.7015, Val Loss: 3.5763, Val Acc: 0.6240, Val F1: 0.6994\n",
            "Epoch: 50/50, Train Loss: 3.6071, Train Acc: 0.6234, Train F1: 0.7006, Val Loss: 3.5763, Val Acc: 0.6240, Val F1: 0.6994\n",
            "\n",
            " üîé search 1 : log_reg --- lr : 0.0007, weight_decay : 0.01, batch_size : 128\n",
            "Epoch: 1/50, Train Loss: 6.1996, Train Acc: 0.3810, Train F1: 0.4420, Val Loss: 5.2242, Val Acc: 0.4944, Val F1: 0.5732\n",
            "Epoch: 2/50, Train Loss: 4.9634, Train Acc: 0.5281, Train F1: 0.6088, Val Loss: 4.6241, Val Acc: 0.4801, Val F1: 0.5649\n",
            "Epoch: 3/50, Train Loss: 4.5994, Train Acc: 0.5317, Train F1: 0.6134, Val Loss: 4.3741, Val Acc: 0.5868, Val F1: 0.6639\n",
            "Epoch: 4/50, Train Loss: 4.4001, Train Acc: 0.5808, Train F1: 0.6619, Val Loss: 4.2254, Val Acc: 0.5998, Val F1: 0.6773\n",
            "Epoch: 5/50, Train Loss: 4.2735, Train Acc: 0.5939, Train F1: 0.6747, Val Loss: 4.1189, Val Acc: 0.6072, Val F1: 0.6852\n",
            "Epoch: 6/50, Train Loss: 4.1737, Train Acc: 0.6003, Train F1: 0.6812, Val Loss: 4.0381, Val Acc: 0.5656, Val F1: 0.6497\n",
            "Epoch: 7/50, Train Loss: 4.0979, Train Acc: 0.6044, Train F1: 0.6849, Val Loss: 3.9838, Val Acc: 0.6114, Val F1: 0.6896\n",
            "Epoch: 8/50, Train Loss: 4.0357, Train Acc: 0.6041, Train F1: 0.6855, Val Loss: 3.9223, Val Acc: 0.6183, Val F1: 0.6948\n",
            "Epoch: 9/50, Train Loss: 3.9924, Train Acc: 0.6063, Train F1: 0.6870, Val Loss: 3.8901, Val Acc: 0.6381, Val F1: 0.7114\n",
            "Epoch: 10/50, Train Loss: 3.9492, Train Acc: 0.6099, Train F1: 0.6903, Val Loss: 3.8448, Val Acc: 0.6111, Val F1: 0.6895\n",
            "Epoch: 11/50, Train Loss: 3.9155, Train Acc: 0.6068, Train F1: 0.6875, Val Loss: 3.8172, Val Acc: 0.6207, Val F1: 0.6971\n",
            "Epoch: 12/50, Train Loss: 3.8858, Train Acc: 0.6087, Train F1: 0.6886, Val Loss: 3.8036, Val Acc: 0.5860, Val F1: 0.6694\n",
            "Epoch: 13/50, Train Loss: 3.8663, Train Acc: 0.5999, Train F1: 0.6813, Val Loss: 3.7835, Val Acc: 0.6142, Val F1: 0.6930\n",
            "Epoch: 14/50, Train Loss: 3.8406, Train Acc: 0.6122, Train F1: 0.6919, Val Loss: 3.7652, Val Acc: 0.6101, Val F1: 0.6895\n",
            "Epoch: 15/50, Train Loss: 3.8221, Train Acc: 0.6148, Train F1: 0.6943, Val Loss: 3.7531, Val Acc: 0.6138, Val F1: 0.6917\n",
            "Epoch: 16/50, Train Loss: 3.8059, Train Acc: 0.6148, Train F1: 0.6941, Val Loss: 3.7362, Val Acc: 0.6029, Val F1: 0.6831\n",
            "Epoch: 17/50, Train Loss: 3.7927, Train Acc: 0.6112, Train F1: 0.6913, Val Loss: 3.7143, Val Acc: 0.6109, Val F1: 0.6890\n",
            "Epoch: 18/50, Train Loss: 3.7787, Train Acc: 0.6139, Train F1: 0.6932, Val Loss: 3.7177, Val Acc: 0.5691, Val F1: 0.6534\n",
            "Epoch: 19/50, Train Loss: 3.7655, Train Acc: 0.6131, Train F1: 0.6925, Val Loss: 3.6978, Val Acc: 0.6150, Val F1: 0.6927\n",
            "Epoch: 20/50, Train Loss: 3.7576, Train Acc: 0.6150, Train F1: 0.6942, Val Loss: 3.6920, Val Acc: 0.6372, Val F1: 0.7107\n",
            "Epoch: 21/50, Train Loss: 3.7466, Train Acc: 0.6167, Train F1: 0.6957, Val Loss: 3.6871, Val Acc: 0.6395, Val F1: 0.7126\n",
            "Epoch: 22/50, Train Loss: 3.7374, Train Acc: 0.6185, Train F1: 0.6970, Val Loss: 3.6879, Val Acc: 0.5882, Val F1: 0.6704\n",
            "Epoch: 23/50, Train Loss: 3.7280, Train Acc: 0.6094, Train F1: 0.6896, Val Loss: 3.6854, Val Acc: 0.6527, Val F1: 0.7230\n",
            "Epoch: 24/50, Train Loss: 3.7239, Train Acc: 0.6195, Train F1: 0.6976, Val Loss: 3.6755, Val Acc: 0.6019, Val F1: 0.6811\n",
            "Epoch: 25/50, Train Loss: 3.7130, Train Acc: 0.6159, Train F1: 0.6949, Val Loss: 3.6594, Val Acc: 0.6318, Val F1: 0.7061\n",
            "Epoch: 26/50, Train Loss: 3.7109, Train Acc: 0.6190, Train F1: 0.6973, Val Loss: 3.6550, Val Acc: 0.6091, Val F1: 0.6879\n",
            "Epoch: 27/50, Train Loss: 3.7049, Train Acc: 0.6162, Train F1: 0.6951, Val Loss: 3.6606, Val Acc: 0.6079, Val F1: 0.6879\n",
            "Epoch: 28/50, Train Loss: 3.7007, Train Acc: 0.6159, Train F1: 0.6949, Val Loss: 3.6563, Val Acc: 0.6249, Val F1: 0.7002\n",
            "Epoch: 29/50, Train Loss: 3.6959, Train Acc: 0.6173, Train F1: 0.6959, Val Loss: 3.6464, Val Acc: 0.6249, Val F1: 0.7001\n",
            "Epoch: 30/50, Train Loss: 3.6912, Train Acc: 0.6144, Train F1: 0.6934, Val Loss: 3.6450, Val Acc: 0.6395, Val F1: 0.7119\n",
            "Epoch: 31/50, Train Loss: 3.6875, Train Acc: 0.6227, Train F1: 0.7001, Val Loss: 3.6492, Val Acc: 0.6136, Val F1: 0.6919\n",
            "Epoch: 32/50, Train Loss: 3.6837, Train Acc: 0.6160, Train F1: 0.6946, Val Loss: 3.6418, Val Acc: 0.6083, Val F1: 0.6865\n",
            "Epoch: 33/50, Train Loss: 3.6806, Train Acc: 0.6166, Train F1: 0.6953, Val Loss: 3.6383, Val Acc: 0.6077, Val F1: 0.6862\n",
            "Epoch: 34/50, Train Loss: 3.6811, Train Acc: 0.6099, Train F1: 0.6897, Val Loss: 3.6372, Val Acc: 0.6163, Val F1: 0.6940\n",
            "Epoch: 35/50, Train Loss: 3.6783, Train Acc: 0.6083, Train F1: 0.6885, Val Loss: 3.6347, Val Acc: 0.6132, Val F1: 0.6910\n",
            "Epoch: 36/50, Train Loss: 3.6739, Train Acc: 0.6168, Train F1: 0.6955, Val Loss: 3.6327, Val Acc: 0.6251, Val F1: 0.7008\n",
            "Epoch: 37/50, Train Loss: 3.6723, Train Acc: 0.6203, Train F1: 0.6983, Val Loss: 3.6315, Val Acc: 0.6207, Val F1: 0.6971\n",
            "Epoch: 38/50, Train Loss: 3.6716, Train Acc: 0.6176, Train F1: 0.6959, Val Loss: 3.6295, Val Acc: 0.6207, Val F1: 0.6968\n",
            "Epoch: 39/50, Train Loss: 3.6701, Train Acc: 0.6126, Train F1: 0.6917, Val Loss: 3.6306, Val Acc: 0.6145, Val F1: 0.6917\n",
            "Epoch: 40/50, Train Loss: 3.6686, Train Acc: 0.6189, Train F1: 0.6972, Val Loss: 3.6298, Val Acc: 0.6151, Val F1: 0.6925\n",
            "Epoch: 41/50, Train Loss: 3.6676, Train Acc: 0.6153, Train F1: 0.6943, Val Loss: 3.6289, Val Acc: 0.6192, Val F1: 0.6958\n",
            "Epoch: 42/50, Train Loss: 3.6666, Train Acc: 0.6195, Train F1: 0.6975, Val Loss: 3.6291, Val Acc: 0.6226, Val F1: 0.6989\n",
            "Epoch: 43/50, Train Loss: 3.6663, Train Acc: 0.6209, Train F1: 0.6989, Val Loss: 3.6287, Val Acc: 0.6212, Val F1: 0.6976\n",
            "Epoch: 44/50, Train Loss: 3.6655, Train Acc: 0.6180, Train F1: 0.6966, Val Loss: 3.6282, Val Acc: 0.6209, Val F1: 0.6972\n",
            "Epoch: 45/50, Train Loss: 3.6647, Train Acc: 0.6212, Train F1: 0.6991, Val Loss: 3.6282, Val Acc: 0.6179, Val F1: 0.6947\n",
            "Epoch: 46/50, Train Loss: 3.6644, Train Acc: 0.6198, Train F1: 0.6978, Val Loss: 3.6280, Val Acc: 0.6178, Val F1: 0.6946\n",
            "Epoch: 47/50, Train Loss: 3.6641, Train Acc: 0.6178, Train F1: 0.6963, Val Loss: 3.6280, Val Acc: 0.6175, Val F1: 0.6944\n",
            "Epoch: 48/50, Train Loss: 3.6638, Train Acc: 0.6179, Train F1: 0.6961, Val Loss: 3.6279, Val Acc: 0.6179, Val F1: 0.6947\n",
            "Epoch: 49/50, Train Loss: 3.6636, Train Acc: 0.6175, Train F1: 0.6960, Val Loss: 3.6278, Val Acc: 0.6181, Val F1: 0.6949\n",
            "Epoch: 50/50, Train Loss: 3.6636, Train Acc: 0.6174, Train F1: 0.6959, Val Loss: 3.6278, Val Acc: 0.6182, Val F1: 0.6949\n",
            "\n",
            " üîé search 2 : deep_rescnn --- lr : 0.001, weight_decay : 0.01, batch_size : 128\n",
            "Epoch: 1/50, Train Loss: 3.2889, Train Acc: 0.6749, Train F1: 0.7371, Val Loss: 2.3779, Val Acc: 0.9194, Val F1: 0.9309\n",
            "Epoch: 2/50, Train Loss: 1.9695, Train Acc: 0.8094, Train F1: 0.8561, Val Loss: 1.9094, Val Acc: 0.8105, Val F1: 0.8483\n",
            "Epoch: 3/50, Train Loss: 1.6189, Train Acc: 0.8535, Train F1: 0.8893, Val Loss: 1.6170, Val Acc: 0.7907, Val F1: 0.8401\n",
            "Epoch: 4/50, Train Loss: 1.4923, Train Acc: 0.8652, Train F1: 0.8975, Val Loss: 1.4219, Val Acc: 0.8784, Val F1: 0.9067\n",
            "Epoch: 5/50, Train Loss: 1.2994, Train Acc: 0.8755, Train F1: 0.9051, Val Loss: 1.7643, Val Acc: 0.8590, Val F1: 0.8973\n",
            "Epoch: 6/50, Train Loss: 1.1742, Train Acc: 0.8817, Train F1: 0.9100, Val Loss: 1.6800, Val Acc: 0.9081, Val F1: 0.9265\n",
            "Epoch: 7/50, Train Loss: 1.1579, Train Acc: 0.8868, Train F1: 0.9148, Val Loss: 3.2766, Val Acc: 0.4853, Val F1: 0.5746\n",
            "Epoch: 8/50, Train Loss: 2.5445, Train Acc: 0.7388, Train F1: 0.7921, Val Loss: 1.9188, Val Acc: 0.7607, Val F1: 0.8281\n",
            "Epoch: 9/50, Train Loss: 1.6379, Train Acc: 0.8426, Train F1: 0.8801, Val Loss: 1.5618, Val Acc: 0.8776, Val F1: 0.9038\n",
            "Epoch: 10/50, Train Loss: 1.3849, Train Acc: 0.8671, Train F1: 0.8987, Val Loss: 1.4659, Val Acc: 0.8918, Val F1: 0.9118\n",
            "Epoch: 11/50, Train Loss: 1.2932, Train Acc: 0.8797, Train F1: 0.9083, Val Loss: 1.3166, Val Acc: 0.8933, Val F1: 0.9129\n",
            "Epoch: 12/50, Train Loss: 1.1885, Train Acc: 0.8878, Train F1: 0.9142, Val Loss: 1.4494, Val Acc: 0.9214, Val F1: 0.9316\n",
            "Epoch: 13/50, Train Loss: 1.1275, Train Acc: 0.8900, Train F1: 0.9153, Val Loss: 1.3262, Val Acc: 0.8181, Val F1: 0.8655\n",
            "Epoch: 14/50, Train Loss: 1.0299, Train Acc: 0.9013, Train F1: 0.9236, Val Loss: 1.2763, Val Acc: 0.8709, Val F1: 0.9020\n",
            "Epoch: 15/50, Train Loss: 0.9884, Train Acc: 0.9008, Train F1: 0.9237, Val Loss: 1.3006, Val Acc: 0.9277, Val F1: 0.9382\n",
            "Epoch: 16/50, Train Loss: 0.9652, Train Acc: 0.9080, Train F1: 0.9291, Val Loss: 1.2764, Val Acc: 0.9027, Val F1: 0.9238\n",
            "Epoch: 17/50, Train Loss: 0.9043, Train Acc: 0.9113, Train F1: 0.9311, Val Loss: 1.5000, Val Acc: 0.8568, Val F1: 0.8903\n",
            "Epoch: 18/50, Train Loss: 0.8561, Train Acc: 0.9150, Train F1: 0.9343, Val Loss: 1.0180, Val Acc: 0.9403, Val F1: 0.9490\n",
            "Epoch: 19/50, Train Loss: 0.8060, Train Acc: 0.9157, Train F1: 0.9348, Val Loss: 1.0922, Val Acc: 0.9163, Val F1: 0.9341\n",
            "Epoch: 20/50, Train Loss: 0.7970, Train Acc: 0.9178, Train F1: 0.9362, Val Loss: 1.0201, Val Acc: 0.9527, Val F1: 0.9597\n",
            "Epoch: 21/50, Train Loss: 0.7546, Train Acc: 0.9188, Train F1: 0.9370, Val Loss: 0.9333, Val Acc: 0.9363, Val F1: 0.9464\n",
            "Epoch: 22/50, Train Loss: 0.7097, Train Acc: 0.9273, Train F1: 0.9433, Val Loss: 1.0343, Val Acc: 0.9371, Val F1: 0.9467\n",
            "Epoch: 23/50, Train Loss: 0.6541, Train Acc: 0.9297, Train F1: 0.9448, Val Loss: 1.0919, Val Acc: 0.9599, Val F1: 0.9635\n",
            "Epoch: 24/50, Train Loss: 0.6475, Train Acc: 0.9317, Train F1: 0.9467, Val Loss: 1.0084, Val Acc: 0.9342, Val F1: 0.9461\n",
            "Epoch: 25/50, Train Loss: 0.6299, Train Acc: 0.9330, Train F1: 0.9475, Val Loss: 0.8568, Val Acc: 0.9416, Val F1: 0.9510\n",
            "Epoch: 26/50, Train Loss: 0.5747, Train Acc: 0.9388, Train F1: 0.9516, Val Loss: 1.0198, Val Acc: 0.9499, Val F1: 0.9553\n",
            "Epoch: 27/50, Train Loss: 0.5377, Train Acc: 0.9424, Train F1: 0.9543, Val Loss: 0.9070, Val Acc: 0.9260, Val F1: 0.9396\n",
            "Epoch: 28/50, Train Loss: 0.4840, Train Acc: 0.9452, Train F1: 0.9564, Val Loss: 0.9966, Val Acc: 0.9370, Val F1: 0.9470\n",
            "Epoch: 29/50, Train Loss: 0.4688, Train Acc: 0.9479, Train F1: 0.9581, Val Loss: 1.0837, Val Acc: 0.9555, Val F1: 0.9610\n",
            "Epoch: 30/50, Train Loss: 0.4438, Train Acc: 0.9515, Train F1: 0.9611, Val Loss: 1.1015, Val Acc: 0.9497, Val F1: 0.9569\n",
            "Epoch: 31/50, Train Loss: 0.4229, Train Acc: 0.9506, Train F1: 0.9605, Val Loss: 0.9520, Val Acc: 0.9432, Val F1: 0.9516\n",
            "Epoch: 32/50, Train Loss: 0.3866, Train Acc: 0.9568, Train F1: 0.9647, Val Loss: 0.8976, Val Acc: 0.9335, Val F1: 0.9459\n",
            "Epoch: 33/50, Train Loss: 0.3810, Train Acc: 0.9568, Train F1: 0.9646, Val Loss: 1.0497, Val Acc: 0.9502, Val F1: 0.9581\n",
            "Epoch: 34/50, Train Loss: 0.3512, Train Acc: 0.9585, Train F1: 0.9662, Val Loss: 0.9761, Val Acc: 0.9550, Val F1: 0.9599\n",
            "Epoch: 35/50, Train Loss: 0.3398, Train Acc: 0.9604, Train F1: 0.9674, Val Loss: 1.0033, Val Acc: 0.9590, Val F1: 0.9634\n",
            "Epoch: 36/50, Train Loss: 0.3049, Train Acc: 0.9649, Train F1: 0.9707, Val Loss: 0.9093, Val Acc: 0.9591, Val F1: 0.9635\n",
            "Epoch: 37/50, Train Loss: 0.2851, Train Acc: 0.9654, Train F1: 0.9712, Val Loss: 0.9693, Val Acc: 0.9478, Val F1: 0.9547\n",
            "Epoch: 38/50, Train Loss: 0.2937, Train Acc: 0.9646, Train F1: 0.9706, Val Loss: 0.9284, Val Acc: 0.9508, Val F1: 0.9566\n",
            "Epoch: 39/50, Train Loss: 0.2625, Train Acc: 0.9684, Train F1: 0.9735, Val Loss: 0.9732, Val Acc: 0.9593, Val F1: 0.9637\n",
            "Epoch: 40/50, Train Loss: 0.2460, Train Acc: 0.9698, Train F1: 0.9746, Val Loss: 1.0664, Val Acc: 0.9662, Val F1: 0.9687\n",
            "Epoch: 41/50, Train Loss: 0.2356, Train Acc: 0.9712, Train F1: 0.9754, Val Loss: 1.0473, Val Acc: 0.9633, Val F1: 0.9669\n",
            "Epoch: 42/50, Train Loss: 0.2263, Train Acc: 0.9731, Train F1: 0.9771, Val Loss: 0.9761, Val Acc: 0.9611, Val F1: 0.9651\n",
            "Epoch: 43/50, Train Loss: 0.2170, Train Acc: 0.9734, Train F1: 0.9773, Val Loss: 1.0076, Val Acc: 0.9628, Val F1: 0.9664\n",
            "Epoch: 44/50, Train Loss: 0.2072, Train Acc: 0.9745, Train F1: 0.9782, Val Loss: 1.0483, Val Acc: 0.9677, Val F1: 0.9703\n",
            "Epoch: 45/50, Train Loss: 0.2018, Train Acc: 0.9752, Train F1: 0.9788, Val Loss: 1.0455, Val Acc: 0.9651, Val F1: 0.9680\n",
            "Epoch: 46/50, Train Loss: 0.1963, Train Acc: 0.9757, Train F1: 0.9791, Val Loss: 1.0811, Val Acc: 0.9655, Val F1: 0.9683\n",
            "Epoch: 47/50, Train Loss: 0.1917, Train Acc: 0.9759, Train F1: 0.9793, Val Loss: 1.0999, Val Acc: 0.9675, Val F1: 0.9699\n",
            "Epoch: 48/50, Train Loss: 0.1887, Train Acc: 0.9767, Train F1: 0.9800, Val Loss: 1.0939, Val Acc: 0.9672, Val F1: 0.9698\n",
            "Epoch: 49/50, Train Loss: 0.1867, Train Acc: 0.9766, Train F1: 0.9798, Val Loss: 1.1066, Val Acc: 0.9676, Val F1: 0.9701\n",
            "Epoch: 50/50, Train Loss: 0.1850, Train Acc: 0.9770, Train F1: 0.9802, Val Loss: 1.1075, Val Acc: 0.9673, Val F1: 0.9698\n",
            "\n",
            " üîé search 3 : deep_rescnn --- lr : 0.0007, weight_decay : 0.01, batch_size : 128\n",
            "Epoch: 1/50, Train Loss: 3.4882, Train Acc: 0.7042, Train F1: 0.7610, Val Loss: 2.1233, Val Acc: 0.8293, Val F1: 0.8535\n",
            "Epoch: 2/50, Train Loss: 2.0099, Train Acc: 0.8268, Train F1: 0.8656, Val Loss: 2.1833, Val Acc: 0.7122, Val F1: 0.7820\n",
            "Epoch: 3/50, Train Loss: 1.7051, Train Acc: 0.8552, Train F1: 0.8880, Val Loss: 1.7123, Val Acc: 0.8543, Val F1: 0.8844\n",
            "Epoch: 4/50, Train Loss: 1.5829, Train Acc: 0.8648, Train F1: 0.8949, Val Loss: 1.4588, Val Acc: 0.8770, Val F1: 0.9013\n",
            "Epoch: 5/50, Train Loss: 1.4034, Train Acc: 0.8788, Train F1: 0.9060, Val Loss: 1.4451, Val Acc: 0.8398, Val F1: 0.8796\n",
            "Epoch: 6/50, Train Loss: 1.3317, Train Acc: 0.8871, Train F1: 0.9119, Val Loss: 1.4012, Val Acc: 0.8577, Val F1: 0.8931\n",
            "Epoch: 7/50, Train Loss: 1.1586, Train Acc: 0.8999, Train F1: 0.9224, Val Loss: 1.6390, Val Acc: 0.9173, Val F1: 0.9354\n",
            "Epoch: 8/50, Train Loss: 1.1470, Train Acc: 0.8962, Train F1: 0.9201, Val Loss: 1.3199, Val Acc: 0.8941, Val F1: 0.9166\n",
            "Epoch: 9/50, Train Loss: 1.0175, Train Acc: 0.9043, Train F1: 0.9265, Val Loss: 1.1847, Val Acc: 0.8979, Val F1: 0.9186\n",
            "Epoch: 10/50, Train Loss: 0.9557, Train Acc: 0.9115, Train F1: 0.9319, Val Loss: 1.2165, Val Acc: 0.9211, Val F1: 0.9384\n",
            "Epoch: 11/50, Train Loss: 0.9316, Train Acc: 0.9100, Train F1: 0.9307, Val Loss: 1.0888, Val Acc: 0.9254, Val F1: 0.9378\n",
            "Epoch: 12/50, Train Loss: 0.8536, Train Acc: 0.9188, Train F1: 0.9369, Val Loss: 1.2091, Val Acc: 0.9583, Val F1: 0.9621\n",
            "Epoch: 13/50, Train Loss: 0.8497, Train Acc: 0.9215, Train F1: 0.9391, Val Loss: 1.2075, Val Acc: 0.8751, Val F1: 0.9082\n",
            "Epoch: 14/50, Train Loss: 0.7725, Train Acc: 0.9227, Train F1: 0.9402, Val Loss: 1.0944, Val Acc: 0.9425, Val F1: 0.9505\n",
            "Epoch: 15/50, Train Loss: 0.7518, Train Acc: 0.9248, Train F1: 0.9419, Val Loss: 0.9675, Val Acc: 0.9407, Val F1: 0.9499\n",
            "Epoch: 16/50, Train Loss: 0.6629, Train Acc: 0.9320, Train F1: 0.9470, Val Loss: 1.1871, Val Acc: 0.8629, Val F1: 0.8999\n",
            "Epoch: 17/50, Train Loss: 0.6581, Train Acc: 0.9331, Train F1: 0.9475, Val Loss: 1.0435, Val Acc: 0.8893, Val F1: 0.9165\n",
            "Epoch: 18/50, Train Loss: 0.6007, Train Acc: 0.9373, Train F1: 0.9509, Val Loss: 1.1307, Val Acc: 0.8170, Val F1: 0.8655\n",
            "Epoch: 19/50, Train Loss: 0.5869, Train Acc: 0.9334, Train F1: 0.9482, Val Loss: 0.9635, Val Acc: 0.9176, Val F1: 0.9340\n",
            "Epoch: 20/50, Train Loss: 0.5753, Train Acc: 0.9389, Train F1: 0.9520, Val Loss: 1.1769, Val Acc: 0.9556, Val F1: 0.9625\n",
            "Epoch: 21/50, Train Loss: 0.5466, Train Acc: 0.9413, Train F1: 0.9539, Val Loss: 1.0479, Val Acc: 0.9550, Val F1: 0.9612\n",
            "Epoch: 22/50, Train Loss: 0.5010, Train Acc: 0.9462, Train F1: 0.9574, Val Loss: 1.1018, Val Acc: 0.9629, Val F1: 0.9671\n",
            "Epoch: 23/50, Train Loss: 0.4384, Train Acc: 0.9495, Train F1: 0.9599, Val Loss: 1.0653, Val Acc: 0.9161, Val F1: 0.9339\n",
            "Epoch: 24/50, Train Loss: 0.4435, Train Acc: 0.9490, Train F1: 0.9592, Val Loss: 0.9960, Val Acc: 0.9185, Val F1: 0.9361\n",
            "Epoch: 25/50, Train Loss: 0.4636, Train Acc: 0.9473, Train F1: 0.9582, Val Loss: 1.1744, Val Acc: 0.9642, Val F1: 0.9668\n",
            "Epoch: 26/50, Train Loss: 0.3913, Train Acc: 0.9530, Train F1: 0.9623, Val Loss: 1.0521, Val Acc: 0.9593, Val F1: 0.9636\n",
            "Epoch: 27/50, Train Loss: 0.3713, Train Acc: 0.9561, Train F1: 0.9646, Val Loss: 1.1294, Val Acc: 0.9385, Val F1: 0.9492\n",
            "Epoch: 28/50, Train Loss: 0.3516, Train Acc: 0.9574, Train F1: 0.9654, Val Loss: 1.0968, Val Acc: 0.9343, Val F1: 0.9455\n",
            "Epoch: 29/50, Train Loss: 0.3502, Train Acc: 0.9580, Train F1: 0.9660, Val Loss: 1.1451, Val Acc: 0.9591, Val F1: 0.9631\n",
            "Epoch: 30/50, Train Loss: 0.3182, Train Acc: 0.9606, Train F1: 0.9682, Val Loss: 1.0972, Val Acc: 0.9631, Val F1: 0.9668\n",
            "Epoch: 31/50, Train Loss: 0.2973, Train Acc: 0.9645, Train F1: 0.9708, Val Loss: 1.1121, Val Acc: 0.9413, Val F1: 0.9508\n",
            "Epoch: 32/50, Train Loss: 0.2943, Train Acc: 0.9626, Train F1: 0.9698, Val Loss: 1.0963, Val Acc: 0.9664, Val F1: 0.9697\n",
            "Epoch: 33/50, Train Loss: 0.2821, Train Acc: 0.9657, Train F1: 0.9717, Val Loss: 1.0838, Val Acc: 0.9642, Val F1: 0.9689\n",
            "Epoch: 34/50, Train Loss: 0.2388, Train Acc: 0.9694, Train F1: 0.9745, Val Loss: 1.1994, Val Acc: 0.9695, Val F1: 0.9716\n",
            "Epoch: 35/50, Train Loss: 0.2424, Train Acc: 0.9711, Train F1: 0.9759, Val Loss: 1.4964, Val Acc: 0.9665, Val F1: 0.9687\n",
            "Epoch: 36/50, Train Loss: 0.2269, Train Acc: 0.9721, Train F1: 0.9767, Val Loss: 1.1319, Val Acc: 0.9553, Val F1: 0.9626\n",
            "Epoch: 37/50, Train Loss: 0.2163, Train Acc: 0.9717, Train F1: 0.9765, Val Loss: 1.2047, Val Acc: 0.9578, Val F1: 0.9632\n",
            "Epoch: 38/50, Train Loss: 0.2018, Train Acc: 0.9746, Train F1: 0.9787, Val Loss: 1.1736, Val Acc: 0.9726, Val F1: 0.9748\n",
            "Epoch: 39/50, Train Loss: 0.1968, Train Acc: 0.9752, Train F1: 0.9789, Val Loss: 1.1777, Val Acc: 0.9704, Val F1: 0.9726\n",
            "Epoch: 40/50, Train Loss: 0.1823, Train Acc: 0.9766, Train F1: 0.9804, Val Loss: 1.1582, Val Acc: 0.9651, Val F1: 0.9687\n",
            "Epoch: 41/50, Train Loss: 0.1715, Train Acc: 0.9783, Train F1: 0.9815, Val Loss: 1.2518, Val Acc: 0.9704, Val F1: 0.9729\n",
            "Epoch: 42/50, Train Loss: 0.1646, Train Acc: 0.9788, Train F1: 0.9821, Val Loss: 1.2997, Val Acc: 0.9732, Val F1: 0.9749\n",
            "Epoch: 43/50, Train Loss: 0.1569, Train Acc: 0.9807, Train F1: 0.9836, Val Loss: 1.1789, Val Acc: 0.9662, Val F1: 0.9698\n",
            "Epoch: 44/50, Train Loss: 0.1539, Train Acc: 0.9805, Train F1: 0.9833, Val Loss: 1.3439, Val Acc: 0.9781, Val F1: 0.9791\n",
            "Epoch: 45/50, Train Loss: 0.1506, Train Acc: 0.9814, Train F1: 0.9840, Val Loss: 1.2686, Val Acc: 0.9710, Val F1: 0.9731\n",
            "Epoch: 46/50, Train Loss: 0.1463, Train Acc: 0.9817, Train F1: 0.9842, Val Loss: 1.3084, Val Acc: 0.9727, Val F1: 0.9744\n",
            "Epoch: 47/50, Train Loss: 0.1434, Train Acc: 0.9818, Train F1: 0.9844, Val Loss: 1.2879, Val Acc: 0.9745, Val F1: 0.9760\n",
            "Epoch: 48/50, Train Loss: 0.1408, Train Acc: 0.9820, Train F1: 0.9845, Val Loss: 1.3646, Val Acc: 0.9764, Val F1: 0.9776\n",
            "Epoch: 49/50, Train Loss: 0.1395, Train Acc: 0.9831, Train F1: 0.9854, Val Loss: 1.3157, Val Acc: 0.9741, Val F1: 0.9756\n",
            "Epoch: 50/50, Train Loss: 0.1385, Train Acc: 0.9820, Train F1: 0.9844, Val Loss: 1.3236, Val Acc: 0.9745, Val F1: 0.9759\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is evident that the Deep-ResCNN model significantly outperformed the logistic regression, LSTM, and GRU models. Additionally, the model's training speed per epoch was impressive.\n",
        "\n",
        "In our next experiment, we will perform a thorough hyperparameter tuning process for this architecture to further improve its performance. We have observed that the Deep-ResCNN model was still converging after epoch 50, and as a result, we will increase the number of epochs up to 80 in the next experiment."
      ],
      "metadata": {
        "id": "H-BYrbXEVfgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3467
        },
        "id": "PHUD94szX2Ga",
        "outputId": "0268e401-3d21-4006-90be-400a0cc2bb93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       model_name                                     hyperparameter  \\\n",
              "0   zero_baseline                                            seed=42   \n",
              "1             gru  {'weight_decay': 0.01, 'learning_rate': 0.0007...   \n",
              "2             gru  {'weight_decay': 0.01, 'learning_rate': 0.0005...   \n",
              "3             gru  {'weight_decay': 0.01, 'learning_rate': 0.0001...   \n",
              "4             gru  {'weight_decay': 0.01, 'learning_rate': 0.001,...   \n",
              "5             gru  {'weight_decay': 0.01, 'learning_rate': 0.001,...   \n",
              "6             gru  {'weight_decay': 0.01, 'learning_rate': 0.001,...   \n",
              "7             gru  {'weight_decay': 0.01, 'learning_rate': 0.001,...   \n",
              "8             gru  {'weight_decay': 0.01, 'learning_rate': 0.0007...   \n",
              "9             gru  {'weight_decay': 0.01, 'learning_rate': 0.0007...   \n",
              "10            gru  {'weight_decay': 0.01, 'learning_rate': 0.0007...   \n",
              "11            gru  {'weight_decay': 0.01, 'learning_rate': 0.0007...   \n",
              "12           lstm  {'weight_decay': 0.01, 'learning_rate': 0.001,...   \n",
              "13           lstm  {'weight_decay': 0.01, 'learning_rate': 0.001,...   \n",
              "14           lstm  {'weight_decay': 0.01, 'learning_rate': 0.001,...   \n",
              "15           lstm  {'weight_decay': 0.01, 'learning_rate': 0.001,...   \n",
              "16           lstm  {'weight_decay': 0.01, 'learning_rate': 0.0007...   \n",
              "17           lstm  {'weight_decay': 0.01, 'learning_rate': 0.0007...   \n",
              "18           lstm  {'weight_decay': 0.01, 'learning_rate': 0.0007...   \n",
              "19           lstm  {'weight_decay': 0.01, 'learning_rate': 0.0007...   \n",
              "20        log_reg  {'weight_decay': 0.01, 'learning_rate': 0.001,...   \n",
              "21        log_reg  {'weight_decay': 0.01, 'learning_rate': 0.0007...   \n",
              "22    deep_rescnn  {'weight_decay': 0.01, 'learning_rate': 0.001,...   \n",
              "23    deep_rescnn  {'weight_decay': 0.01, 'learning_rate': 0.0007...   \n",
              "\n",
              "    best_epoch best_train_cost best_val_cost  best_train_recall  \\\n",
              "0            1            None          None           0.827732   \n",
              "1           41        5.507615      5.509489           0.356842   \n",
              "2           31        5.983451      6.093212           0.392644   \n",
              "3           45        6.741659      6.704005           0.221518   \n",
              "4            4        7.810387      7.883294           0.124465   \n",
              "5            1        8.031378      7.965182           0.140471   \n",
              "6           40        3.996663      4.038586           0.445306   \n",
              "7           22         5.27236      4.760894           0.499505   \n",
              "8            1         8.02739      7.880352           0.210234   \n",
              "9            2        7.979831      7.847589           0.097754   \n",
              "10          40        4.906158      4.826031           0.496200   \n",
              "11          26        5.845338      5.961468           0.308216   \n",
              "12          26        5.864016      5.790077           0.354009   \n",
              "13          10        8.048463      8.044958           0.056423   \n",
              "14          21        7.867059      7.897568           0.155243   \n",
              "15           2        8.049805      8.045814           0.152623   \n",
              "16          25        8.047501      8.030314           0.097114   \n",
              "17           2        8.049438      8.044966           0.137806   \n",
              "18          10         7.79125      7.774259           0.063154   \n",
              "19          19         8.04777      8.045049           0.047209   \n",
              "20          20          3.6071        3.5763           0.621290   \n",
              "21          23          3.6636        3.6278           0.609366   \n",
              "22          44           0.185        1.1075           0.974537   \n",
              "23          44          0.1385        1.3236           0.980507   \n",
              "\n",
              "    best_train_precision  best_train_f1  best_val_recall  best_val_precision  \\\n",
              "0               0.685140       0.749716         0.827722            0.685123   \n",
              "1               0.825692       0.433814         0.373018            0.824422   \n",
              "2               0.804989       0.474624         0.450866            0.816760   \n",
              "3               0.812764       0.260281         0.226141            0.816713   \n",
              "4               0.576825       0.128467         0.573804            0.742679   \n",
              "5               0.109344       0.114392         0.821234            0.711592   \n",
              "6               0.849698       0.526997         0.464663            0.849047   \n",
              "7               0.827367       0.582974         0.555850            0.834463   \n",
              "8               0.169824       0.182143         0.751199            0.694037   \n",
              "9               0.082395       0.059245         0.707479            0.689311   \n",
              "10              0.835485       0.577439         0.502947            0.832597   \n",
              "11              0.807866       0.376088         0.414181            0.804355   \n",
              "12              0.805761       0.430653         0.410572            0.802027   \n",
              "13              0.007673       0.011213         0.827722            0.685268   \n",
              "14              0.715464       0.176584         0.786240            0.702104   \n",
              "15              0.114048       0.125235         0.827722            0.685268   \n",
              "16              0.065587       0.067391         0.801864            0.692356   \n",
              "17              0.093675       0.103754         0.827722            0.685268   \n",
              "18              0.439376       0.063762         0.348942            0.632488   \n",
              "19              0.018925       0.021912         0.827722            0.685268   \n",
              "20              0.876706       0.699095         0.648910            0.874387   \n",
              "21              0.875767       0.689628         0.652748            0.872700   \n",
              "22              0.985160       0.978240         0.967655            0.975596   \n",
              "23              0.988372       0.983303         0.978117            0.981256   \n",
              "\n",
              "    best_val_f1 best_test_recall best_test_precision best_test_f1  \n",
              "0      0.749702         0.827608            0.684935     0.749543  \n",
              "1      0.451205             None                None         None  \n",
              "2      0.541596             None                None         None  \n",
              "3      0.267453             None                None         None  \n",
              "4      0.632116             None                None         None  \n",
              "5      0.754855             None                None         None  \n",
              "6      0.546155             None                None         None  \n",
              "7      0.634460             None                None         None  \n",
              "8      0.718792             None                None         None  \n",
              "9      0.697626             None                None         None  \n",
              "10     0.581607             None                None         None  \n",
              "11     0.495542             None                None         None  \n",
              "12     0.491736             None                None         None  \n",
              "13     0.749750             None                None         None  \n",
              "14     0.740868             None                None         None  \n",
              "15     0.749750             None                None         None  \n",
              "16     0.742942             None                None         None  \n",
              "17     0.749750             None                None         None  \n",
              "18     0.436329             None                None         None  \n",
              "19     0.749750             None                None         None  \n",
              "20     0.719839             None                None         None  \n",
              "21     0.723000             None                None         None  \n",
              "22     0.970309             None                None         None  \n",
              "23     0.979149             None                None         None  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-268d22b3-e03c-405c-96e3-d20886c6e1ce\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>hyperparameter</th>\n",
              "      <th>best_epoch</th>\n",
              "      <th>best_train_cost</th>\n",
              "      <th>best_val_cost</th>\n",
              "      <th>best_train_recall</th>\n",
              "      <th>best_train_precision</th>\n",
              "      <th>best_train_f1</th>\n",
              "      <th>best_val_recall</th>\n",
              "      <th>best_val_precision</th>\n",
              "      <th>best_val_f1</th>\n",
              "      <th>best_test_recall</th>\n",
              "      <th>best_test_precision</th>\n",
              "      <th>best_test_f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>zero_baseline</td>\n",
              "      <td>seed=42</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>0.827732</td>\n",
              "      <td>0.685140</td>\n",
              "      <td>0.749716</td>\n",
              "      <td>0.827722</td>\n",
              "      <td>0.685123</td>\n",
              "      <td>0.749702</td>\n",
              "      <td>0.827608</td>\n",
              "      <td>0.684935</td>\n",
              "      <td>0.749543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gru</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.0007...</td>\n",
              "      <td>41</td>\n",
              "      <td>5.507615</td>\n",
              "      <td>5.509489</td>\n",
              "      <td>0.356842</td>\n",
              "      <td>0.825692</td>\n",
              "      <td>0.433814</td>\n",
              "      <td>0.373018</td>\n",
              "      <td>0.824422</td>\n",
              "      <td>0.451205</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gru</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.0005...</td>\n",
              "      <td>31</td>\n",
              "      <td>5.983451</td>\n",
              "      <td>6.093212</td>\n",
              "      <td>0.392644</td>\n",
              "      <td>0.804989</td>\n",
              "      <td>0.474624</td>\n",
              "      <td>0.450866</td>\n",
              "      <td>0.816760</td>\n",
              "      <td>0.541596</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gru</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.0001...</td>\n",
              "      <td>45</td>\n",
              "      <td>6.741659</td>\n",
              "      <td>6.704005</td>\n",
              "      <td>0.221518</td>\n",
              "      <td>0.812764</td>\n",
              "      <td>0.260281</td>\n",
              "      <td>0.226141</td>\n",
              "      <td>0.816713</td>\n",
              "      <td>0.267453</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gru</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.001,...</td>\n",
              "      <td>4</td>\n",
              "      <td>7.810387</td>\n",
              "      <td>7.883294</td>\n",
              "      <td>0.124465</td>\n",
              "      <td>0.576825</td>\n",
              "      <td>0.128467</td>\n",
              "      <td>0.573804</td>\n",
              "      <td>0.742679</td>\n",
              "      <td>0.632116</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>gru</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.001,...</td>\n",
              "      <td>1</td>\n",
              "      <td>8.031378</td>\n",
              "      <td>7.965182</td>\n",
              "      <td>0.140471</td>\n",
              "      <td>0.109344</td>\n",
              "      <td>0.114392</td>\n",
              "      <td>0.821234</td>\n",
              "      <td>0.711592</td>\n",
              "      <td>0.754855</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>gru</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.001,...</td>\n",
              "      <td>40</td>\n",
              "      <td>3.996663</td>\n",
              "      <td>4.038586</td>\n",
              "      <td>0.445306</td>\n",
              "      <td>0.849698</td>\n",
              "      <td>0.526997</td>\n",
              "      <td>0.464663</td>\n",
              "      <td>0.849047</td>\n",
              "      <td>0.546155</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>gru</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.001,...</td>\n",
              "      <td>22</td>\n",
              "      <td>5.27236</td>\n",
              "      <td>4.760894</td>\n",
              "      <td>0.499505</td>\n",
              "      <td>0.827367</td>\n",
              "      <td>0.582974</td>\n",
              "      <td>0.555850</td>\n",
              "      <td>0.834463</td>\n",
              "      <td>0.634460</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>gru</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.0007...</td>\n",
              "      <td>1</td>\n",
              "      <td>8.02739</td>\n",
              "      <td>7.880352</td>\n",
              "      <td>0.210234</td>\n",
              "      <td>0.169824</td>\n",
              "      <td>0.182143</td>\n",
              "      <td>0.751199</td>\n",
              "      <td>0.694037</td>\n",
              "      <td>0.718792</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>gru</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.0007...</td>\n",
              "      <td>2</td>\n",
              "      <td>7.979831</td>\n",
              "      <td>7.847589</td>\n",
              "      <td>0.097754</td>\n",
              "      <td>0.082395</td>\n",
              "      <td>0.059245</td>\n",
              "      <td>0.707479</td>\n",
              "      <td>0.689311</td>\n",
              "      <td>0.697626</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>gru</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.0007...</td>\n",
              "      <td>40</td>\n",
              "      <td>4.906158</td>\n",
              "      <td>4.826031</td>\n",
              "      <td>0.496200</td>\n",
              "      <td>0.835485</td>\n",
              "      <td>0.577439</td>\n",
              "      <td>0.502947</td>\n",
              "      <td>0.832597</td>\n",
              "      <td>0.581607</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>gru</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.0007...</td>\n",
              "      <td>26</td>\n",
              "      <td>5.845338</td>\n",
              "      <td>5.961468</td>\n",
              "      <td>0.308216</td>\n",
              "      <td>0.807866</td>\n",
              "      <td>0.376088</td>\n",
              "      <td>0.414181</td>\n",
              "      <td>0.804355</td>\n",
              "      <td>0.495542</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>lstm</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.001,...</td>\n",
              "      <td>26</td>\n",
              "      <td>5.864016</td>\n",
              "      <td>5.790077</td>\n",
              "      <td>0.354009</td>\n",
              "      <td>0.805761</td>\n",
              "      <td>0.430653</td>\n",
              "      <td>0.410572</td>\n",
              "      <td>0.802027</td>\n",
              "      <td>0.491736</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>lstm</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.001,...</td>\n",
              "      <td>10</td>\n",
              "      <td>8.048463</td>\n",
              "      <td>8.044958</td>\n",
              "      <td>0.056423</td>\n",
              "      <td>0.007673</td>\n",
              "      <td>0.011213</td>\n",
              "      <td>0.827722</td>\n",
              "      <td>0.685268</td>\n",
              "      <td>0.749750</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>lstm</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.001,...</td>\n",
              "      <td>21</td>\n",
              "      <td>7.867059</td>\n",
              "      <td>7.897568</td>\n",
              "      <td>0.155243</td>\n",
              "      <td>0.715464</td>\n",
              "      <td>0.176584</td>\n",
              "      <td>0.786240</td>\n",
              "      <td>0.702104</td>\n",
              "      <td>0.740868</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>lstm</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.001,...</td>\n",
              "      <td>2</td>\n",
              "      <td>8.049805</td>\n",
              "      <td>8.045814</td>\n",
              "      <td>0.152623</td>\n",
              "      <td>0.114048</td>\n",
              "      <td>0.125235</td>\n",
              "      <td>0.827722</td>\n",
              "      <td>0.685268</td>\n",
              "      <td>0.749750</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>lstm</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.0007...</td>\n",
              "      <td>25</td>\n",
              "      <td>8.047501</td>\n",
              "      <td>8.030314</td>\n",
              "      <td>0.097114</td>\n",
              "      <td>0.065587</td>\n",
              "      <td>0.067391</td>\n",
              "      <td>0.801864</td>\n",
              "      <td>0.692356</td>\n",
              "      <td>0.742942</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>lstm</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.0007...</td>\n",
              "      <td>2</td>\n",
              "      <td>8.049438</td>\n",
              "      <td>8.044966</td>\n",
              "      <td>0.137806</td>\n",
              "      <td>0.093675</td>\n",
              "      <td>0.103754</td>\n",
              "      <td>0.827722</td>\n",
              "      <td>0.685268</td>\n",
              "      <td>0.749750</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>lstm</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.0007...</td>\n",
              "      <td>10</td>\n",
              "      <td>7.79125</td>\n",
              "      <td>7.774259</td>\n",
              "      <td>0.063154</td>\n",
              "      <td>0.439376</td>\n",
              "      <td>0.063762</td>\n",
              "      <td>0.348942</td>\n",
              "      <td>0.632488</td>\n",
              "      <td>0.436329</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>lstm</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.0007...</td>\n",
              "      <td>19</td>\n",
              "      <td>8.04777</td>\n",
              "      <td>8.045049</td>\n",
              "      <td>0.047209</td>\n",
              "      <td>0.018925</td>\n",
              "      <td>0.021912</td>\n",
              "      <td>0.827722</td>\n",
              "      <td>0.685268</td>\n",
              "      <td>0.749750</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>log_reg</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.001,...</td>\n",
              "      <td>20</td>\n",
              "      <td>3.6071</td>\n",
              "      <td>3.5763</td>\n",
              "      <td>0.621290</td>\n",
              "      <td>0.876706</td>\n",
              "      <td>0.699095</td>\n",
              "      <td>0.648910</td>\n",
              "      <td>0.874387</td>\n",
              "      <td>0.719839</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>log_reg</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.0007...</td>\n",
              "      <td>23</td>\n",
              "      <td>3.6636</td>\n",
              "      <td>3.6278</td>\n",
              "      <td>0.609366</td>\n",
              "      <td>0.875767</td>\n",
              "      <td>0.689628</td>\n",
              "      <td>0.652748</td>\n",
              "      <td>0.872700</td>\n",
              "      <td>0.723000</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>deep_rescnn</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.001,...</td>\n",
              "      <td>44</td>\n",
              "      <td>0.185</td>\n",
              "      <td>1.1075</td>\n",
              "      <td>0.974537</td>\n",
              "      <td>0.985160</td>\n",
              "      <td>0.978240</td>\n",
              "      <td>0.967655</td>\n",
              "      <td>0.975596</td>\n",
              "      <td>0.970309</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>deep_rescnn</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.0007...</td>\n",
              "      <td>44</td>\n",
              "      <td>0.1385</td>\n",
              "      <td>1.3236</td>\n",
              "      <td>0.980507</td>\n",
              "      <td>0.988372</td>\n",
              "      <td>0.983303</td>\n",
              "      <td>0.978117</td>\n",
              "      <td>0.981256</td>\n",
              "      <td>0.979149</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-268d22b3-e03c-405c-96e3-d20886c6e1ce')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-268d22b3-e03c-405c-96e3-d20886c6e1ce button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-268d22b3-e03c-405c-96e3-d20886c6e1ce');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/99dac6621f6ae8c4/data_table.js\";\n\n      window.createDataTable({\n        data: [[{\n            'v': 0,\n            'f': \"0\",\n        },\n\"zero_baseline\",\n\"seed=42\",\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': 0.8277316683164547,\n            'f': \"0.8277316683164547\",\n        },\n{\n            'v': 0.6851397147339414,\n            'f': \"0.6851397147339414\",\n        },\n{\n            'v': 0.7497158654202581,\n            'f': \"0.7497158654202581\",\n        },\n{\n            'v': 0.8277216866919457,\n            'f': \"0.8277216866919457\",\n        },\n{\n            'v': 0.6851231906201596,\n            'f': \"0.6851231906201596\",\n        },\n{\n            'v': 0.7497018781455581,\n            'f': \"0.7497018781455581\",\n        },\n{\n            'v': 0.8276082587246483,\n            'f': \"0.8276082587246483\",\n        },\n{\n            'v': 0.6849354299092444,\n            'f': \"0.6849354299092444\",\n        },\n{\n            'v': 0.7495429358446977,\n            'f': \"0.7495429358446977\",\n        }],\n [{\n            'v': 1,\n            'f': \"1\",\n        },\n\"gru\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.0007, 'batch_size': 128, 'hidden_size': 32, 'num_layers': 1}\",\n{\n            'v': 41,\n            'f': \"41\",\n        },\n{\n            'v': 5.507614932274097,\n            'f': \"5.507614932274097\",\n        },\n{\n            'v': 5.509488628009624,\n            'f': \"5.509488628009624\",\n        },\n{\n            'v': 0.3568415442016295,\n            'f': \"0.3568415442016295\",\n        },\n{\n            'v': 0.8256916678170723,\n            'f': \"0.8256916678170723\",\n        },\n{\n            'v': 0.43381446358436343,\n            'f': \"0.43381446358436343\",\n        },\n{\n            'v': 0.3730184110740555,\n            'f': \"0.3730184110740555\",\n        },\n{\n            'v': 0.8244220540949647,\n            'f': \"0.8244220540949647\",\n        },\n{\n            'v': 0.4512051344351721,\n            'f': \"0.4512051344351721\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 2,\n            'f': \"2\",\n        },\n\"gru\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.0005, 'batch_size': 128, 'hidden_size': 32, 'num_layers': 1}\",\n{\n            'v': 31,\n            'f': \"31\",\n        },\n{\n            'v': 5.983451240717898,\n            'f': \"5.983451240717898\",\n        },\n{\n            'v': 6.0932123053803116,\n            'f': \"6.0932123053803116\",\n        },\n{\n            'v': 0.3926444833625219,\n            'f': \"0.3926444833625219\",\n        },\n{\n            'v': 0.804988595547416,\n            'f': \"0.804988595547416\",\n        },\n{\n            'v': 0.474623652496336,\n            'f': \"0.474623652496336\",\n        },\n{\n            'v': 0.4508657316460323,\n            'f': \"0.4508657316460323\",\n        },\n{\n            'v': 0.8167604275762758,\n            'f': \"0.8167604275762758\",\n        },\n{\n            'v': 0.5415964601265059,\n            'f': \"0.5415964601265059\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 3,\n            'f': \"3\",\n        },\n\"gru\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.0001, 'batch_size': 128, 'hidden_size': 32, 'num_layers': 1}\",\n{\n            'v': 45,\n            'f': \"45\",\n        },\n{\n            'v': 6.741658943035103,\n            'f': \"6.741658943035103\",\n        },\n{\n            'v': 6.704004760396078,\n            'f': \"6.704004760396078\",\n        },\n{\n            'v': 0.22151831264752914,\n            'f': \"0.22151831264752914\",\n        },\n{\n            'v': 0.8127644637416019,\n            'f': \"0.8127644637416019\",\n        },\n{\n            'v': 0.2602808084672521,\n            'f': \"0.2602808084672521\",\n        },\n{\n            'v': 0.2261409840559185,\n            'f': \"0.2261409840559185\",\n        },\n{\n            'v': 0.8167132825529796,\n            'f': \"0.8167132825529796\",\n        },\n{\n            'v': 0.26745297834508336,\n            'f': \"0.26745297834508336\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 4,\n            'f': \"4\",\n        },\n\"gru\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.001, 'batch_size': 128, 'hidden_size': 32, 'num_layers': 1}\",\n{\n            'v': 4,\n            'f': \"4\",\n        },\n{\n            'v': 7.8103873997842745,\n            'f': \"7.8103873997842745\",\n        },\n{\n            'v': 7.883294439744947,\n            'f': \"7.883294439744947\",\n        },\n{\n            'v': 0.12446508794639458,\n            'f': \"0.12446508794639458\",\n        },\n{\n            'v': 0.5768252494222211,\n            'f': \"0.5768252494222211\",\n        },\n{\n            'v': 0.12846651783101395,\n            'f': \"0.12846651783101395\",\n        },\n{\n            'v': 0.5738041938873407,\n            'f': \"0.5738041938873407\",\n        },\n{\n            'v': 0.7426786712948427,\n            'f': \"0.7426786712948427\",\n        },\n{\n            'v': 0.6321163572367791,\n            'f': \"0.6321163572367791\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 5,\n            'f': \"5\",\n        },\n\"gru\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.001, 'batch_size': 128, 'hidden_size': 32, 'num_layers': 2}\",\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 8.031377988283536,\n            'f': \"8.031377988283536\",\n        },\n{\n            'v': 7.965182493753488,\n            'f': \"7.965182493753488\",\n        },\n{\n            'v': 0.14047057031904364,\n            'f': \"0.14047057031904364\",\n        },\n{\n            'v': 0.10934377855107942,\n            'f': \"0.10934377855107942\",\n        },\n{\n            'v': 0.1143916738210928,\n            'f': \"0.1143916738210928\",\n        },\n{\n            'v': 0.8212344099776143,\n            'f': \"0.8212344099776143\",\n        },\n{\n            'v': 0.7115922302210648,\n            'f': \"0.7115922302210648\",\n        },\n{\n            'v': 0.7548551419094334,\n            'f': \"0.7548551419094334\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 6,\n            'f': \"6\",\n        },\n\"gru\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.001, 'batch_size': 128, 'hidden_size': 64, 'num_layers': 1}\",\n{\n            'v': 40,\n            'f': \"40\",\n        },\n{\n            'v': 3.9966633700865164,\n            'f': \"3.9966633700865164\",\n        },\n{\n            'v': 4.038585996577703,\n            'f': \"4.038585996577703\",\n        },\n{\n            'v': 0.4453057184192492,\n            'f': \"0.4453057184192492\",\n        },\n{\n            'v': 0.8496976832473455,\n            'f': \"0.8496976832473455\",\n        },\n{\n            'v': 0.5269968847654715,\n            'f': \"0.5269968847654715\",\n        },\n{\n            'v': 0.4646626159258075,\n            'f': \"0.4646626159258075\",\n        },\n{\n            'v': 0.8490466643073519,\n            'f': \"0.8490466643073519\",\n        },\n{\n            'v': 0.5461545091288852,\n            'f': \"0.5461545091288852\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 7,\n            'f': \"7\",\n        },\n\"gru\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.001, 'batch_size': 128, 'hidden_size': 64, 'num_layers': 2}\",\n{\n            'v': 22,\n            'f': \"22\",\n        },\n{\n            'v': 5.2723602206511115,\n            'f': \"5.2723602206511115\",\n        },\n{\n            'v': 4.760894384165876,\n            'f': \"4.760894384165876\",\n        },\n{\n            'v': 0.4995050635802939,\n            'f': \"0.4995050635802939\",\n        },\n{\n            'v': 0.8273666884414758,\n            'f': \"0.8273666884414758\",\n        },\n{\n            'v': 0.5829736865012313,\n            'f': \"0.5829736865012313\",\n        },\n{\n            'v': 0.5558499703047193,\n            'f': \"0.5558499703047193\",\n        },\n{\n            'v': 0.8344630313617457,\n            'f': \"0.8344630313617457\",\n        },\n{\n            'v': 0.6344601160667206,\n            'f': \"0.6344601160667206\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 8,\n            'f': \"8\",\n        },\n\"gru\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.0007, 'batch_size': 128, 'hidden_size': 32, 'num_layers': 1}\",\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': 8.027389599493958,\n            'f': \"8.027389599493958\",\n        },\n{\n            'v': 7.880352040915215,\n            'f': \"7.880352040915215\",\n        },\n{\n            'v': 0.2102337622782304,\n            'f': \"0.2102337622782304\",\n        },\n{\n            'v': 0.16982360136253113,\n            'f': \"0.16982360136253113\",\n        },\n{\n            'v': 0.18214257944490095,\n            'f': \"0.18214257944490095\",\n        },\n{\n            'v': 0.7511992324912057,\n            'f': \"0.7511992324912057\",\n        },\n{\n            'v': 0.6940372545356985,\n            'f': \"0.6940372545356985\",\n        },\n{\n            'v': 0.7187924553604571,\n            'f': \"0.7187924553604571\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 9,\n            'f': \"9\",\n        },\n\"gru\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.0007, 'batch_size': 128, 'hidden_size': 32, 'num_layers': 2}\",\n{\n            'v': 2,\n            'f': \"2\",\n        },\n{\n            'v': 7.979831332787514,\n            'f': \"7.979831332787514\",\n        },\n{\n            'v': 7.847589151480999,\n            'f': \"7.847589151480999\",\n        },\n{\n            'v': 0.09775375009518009,\n            'f': \"0.09775375009518009\",\n        },\n{\n            'v': 0.08239450298506773,\n            'f': \"0.08239450298506773\",\n        },\n{\n            'v': 0.059244851293035194,\n            'f': \"0.059244851293035194\",\n        },\n{\n            'v': 0.7074786422403947,\n            'f': \"0.7074786422403947\",\n        },\n{\n            'v': 0.6893109743246425,\n            'f': \"0.6893109743246425\",\n        },\n{\n            'v': 0.6976258680093479,\n            'f': \"0.6976258680093479\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 10,\n            'f': \"10\",\n        },\n\"gru\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.0007, 'batch_size': 128, 'hidden_size': 64, 'num_layers': 1}\",\n{\n            'v': 40,\n            'f': \"40\",\n        },\n{\n            'v': 4.906158107245476,\n            'f': \"4.906158107245476\",\n        },\n{\n            'v': 4.826031305370708,\n            'f': \"4.826031305370708\",\n        },\n{\n            'v': 0.49620041117794866,\n            'f': \"0.49620041117794866\",\n        },\n{\n            'v': 0.8354849831106961,\n            'f': \"0.8354849831106961\",\n        },\n{\n            'v': 0.5774392280427413,\n            'f': \"0.5774392280427413\",\n        },\n{\n            'v': 0.5029466855498196,\n            'f': \"0.5029466855498196\",\n        },\n{\n            'v': 0.8325971126656635,\n            'f': \"0.8325971126656635\",\n        },\n{\n            'v': 0.5816070537229479,\n            'f': \"0.5816070537229479\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 11,\n            'f': \"11\",\n        },\n\"gru\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.0007, 'batch_size': 128, 'hidden_size': 64, 'num_layers': 2}\",\n{\n            'v': 26,\n            'f': \"26\",\n        },\n{\n            'v': 5.84533774354421,\n            'f': \"5.84533774354421\",\n        },\n{\n            'v': 5.961467830667195,\n            'f': \"5.961467830667195\",\n        },\n{\n            'v': 0.308215944567121,\n            'f': \"0.308215944567121\",\n        },\n{\n            'v': 0.8078663790705302,\n            'f': \"0.8078663790705302\",\n        },\n{\n            'v': 0.3760881580733837,\n            'f': \"0.3760881580733837\",\n        },\n{\n            'v': 0.41418063867696103,\n            'f': \"0.41418063867696103\",\n        },\n{\n            'v': 0.8043547781806835,\n            'f': \"0.8043547781806835\",\n        },\n{\n            'v': 0.495541650094848,\n            'f': \"0.495541650094848\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 12,\n            'f': \"12\",\n        },\n\"lstm\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.001, 'batch_size': 128, 'hidden_size': 32, 'num_layers': 1}\",\n{\n            'v': 26,\n            'f': \"26\",\n        },\n{\n            'v': 5.864016027996276,\n            'f': \"5.864016027996276\",\n        },\n{\n            'v': 5.790076607528102,\n            'f': \"5.790076607528102\",\n        },\n{\n            'v': 0.3540089849996193,\n            'f': \"0.3540089849996193\",\n        },\n{\n            'v': 0.8057611087962436,\n            'f': \"0.8057611087962436\",\n        },\n{\n            'v': 0.43065253520590807,\n            'f': \"0.43065253520590807\",\n        },\n{\n            'v': 0.41057151994152313,\n            'f': \"0.41057151994152313\",\n        },\n{\n            'v': 0.8020272944499927,\n            'f': \"0.8020272944499927\",\n        },\n{\n            'v': 0.4917363401942384,\n            'f': \"0.4917363401942384\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 13,\n            'f': \"13\",\n        },\n\"lstm\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.001, 'batch_size': 128, 'hidden_size': 32, 'num_layers': 2}\",\n{\n            'v': 10,\n            'f': \"10\",\n        },\n{\n            'v': 8.048462614620629,\n            'f': \"8.048462614620629\",\n        },\n{\n            'v': 8.04495843733706,\n            'f': \"8.04495843733706\",\n        },\n{\n            'v': 0.05642275184649356,\n            'f': \"0.05642275184649356\",\n        },\n{\n            'v': 0.007672585281352318,\n            'f': \"0.007672585281352318\",\n        },\n{\n            'v': 0.011213340897468008,\n            'f': \"0.011213340897468008\",\n        },\n{\n            'v': 0.8277216866919457,\n            'f': \"0.8277216866919457\",\n        },\n{\n            'v': 0.6852681704859168,\n            'f': \"0.6852681704859168\",\n        },\n{\n            'v': 0.749749548792234,\n            'f': \"0.749749548792234\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 14,\n            'f': \"14\",\n        },\n\"lstm\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.001, 'batch_size': 128, 'hidden_size': 64, 'num_layers': 1}\",\n{\n            'v': 21,\n            'f': \"21\",\n        },\n{\n            'v': 7.867058732703318,\n            'f': \"7.867058732703318\",\n        },\n{\n            'v': 7.897568186430962,\n            'f': \"7.897568186430962\",\n        },\n{\n            'v': 0.15524251884565599,\n            'f': \"0.15524251884565599\",\n        },\n{\n            'v': 0.7154641944986406,\n            'f': \"0.7154641944986406\",\n        },\n{\n            'v': 0.1765839946390177,\n            'f': \"0.1765839946390177\",\n        },\n{\n            'v': 0.786239663758052,\n            'f': \"0.786239663758052\",\n        },\n{\n            'v': 0.7021038825095346,\n            'f': \"0.7021038825095346\",\n        },\n{\n            'v': 0.7408684332231934,\n            'f': \"0.7408684332231934\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 15,\n            'f': \"15\",\n        },\n\"lstm\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.001, 'batch_size': 128, 'hidden_size': 64, 'num_layers': 2}\",\n{\n            'v': 2,\n            'f': \"2\",\n        },\n{\n            'v': 8.04980544505856,\n            'f': \"8.04980544505856\",\n        },\n{\n            'v': 8.0458136935663,\n            'f': \"8.0458136935663\",\n        },\n{\n            'v': 0.15262316302444223,\n            'f': \"0.15262316302444223\",\n        },\n{\n            'v': 0.11404798503769131,\n            'f': \"0.11404798503769131\",\n        },\n{\n            'v': 0.1252346957567576,\n            'f': \"0.1252346957567576\",\n        },\n{\n            'v': 0.8277216866919457,\n            'f': \"0.8277216866919457\",\n        },\n{\n            'v': 0.6852681704859168,\n            'f': \"0.6852681704859168\",\n        },\n{\n            'v': 0.749749548792234,\n            'f': \"0.749749548792234\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 16,\n            'f': \"16\",\n        },\n\"lstm\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.0007, 'batch_size': 128, 'hidden_size': 32, 'num_layers': 1}\",\n{\n            'v': 25,\n            'f': \"25\",\n        },\n{\n            'v': 8.047500555242795,\n            'f': \"8.047500555242795\",\n        },\n{\n            'v': 8.03031379009231,\n            'f': \"8.03031379009231\",\n        },\n{\n            'v': 0.09711413995279068,\n            'f': \"0.09711413995279068\",\n        },\n{\n            'v': 0.06558696619074902,\n            'f': \"0.06558696619074902\",\n        },\n{\n            'v': 0.06739145353830464,\n            'f': \"0.06739145353830464\",\n        },\n{\n            'v': 0.8018639499291882,\n            'f': \"0.8018639499291882\",\n        },\n{\n            'v': 0.6923563773079917,\n            'f': \"0.6923563773079917\",\n        },\n{\n            'v': 0.7429418578613375,\n            'f': \"0.7429418578613375\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 17,\n            'f': \"17\",\n        },\n\"lstm\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.0007, 'batch_size': 128, 'hidden_size': 32, 'num_layers': 2}\",\n{\n            'v': 2,\n            'f': \"2\",\n        },\n{\n            'v': 8.049438494097602,\n            'f': \"8.049438494097602\",\n        },\n{\n            'v': 8.044965663982934,\n            'f': \"8.044965663982934\",\n        },\n{\n            'v': 0.1378055280590878,\n            'f': \"0.1378055280590878\",\n        },\n{\n            'v': 0.09367498345132332,\n            'f': \"0.09367498345132332\",\n        },\n{\n            'v': 0.10375417509740538,\n            'f': \"0.10375417509740538\",\n        },\n{\n            'v': 0.8277216866919457,\n            'f': \"0.8277216866919457\",\n        },\n{\n            'v': 0.6852681704859168,\n            'f': \"0.6852681704859168\",\n        },\n{\n            'v': 0.749749548792234,\n            'f': \"0.749749548792234\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 18,\n            'f': \"18\",\n        },\n\"lstm\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.0007, 'batch_size': 128, 'hidden_size': 64, 'num_layers': 1}\",\n{\n            'v': 10,\n            'f': \"10\",\n        },\n{\n            'v': 7.791250187780818,\n            'f': \"7.791250187780818\",\n        },\n{\n            'v': 7.774258605526224,\n            'f': \"7.774258605526224\",\n        },\n{\n            'v': 0.06315388715449631,\n            'f': \"0.06315388715449631\",\n        },\n{\n            'v': 0.4393761037543724,\n            'f': \"0.4393761037543724\",\n        },\n{\n            'v': 0.06376215242951365,\n            'f': \"0.06376215242951365\",\n        },\n{\n            'v': 0.34894239115537484,\n            'f': \"0.34894239115537484\",\n        },\n{\n            'v': 0.6324877237952132,\n            'f': \"0.6324877237952132\",\n        },\n{\n            'v': 0.4363285487243902,\n            'f': \"0.4363285487243902\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 19,\n            'f': \"19\",\n        },\n\"lstm\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.0007, 'batch_size': 128, 'hidden_size': 64, 'num_layers': 2}\",\n{\n            'v': 19,\n            'f': \"19\",\n        },\n{\n            'v': 8.047769785479254,\n            'f': \"8.047769785479254\",\n        },\n{\n            'v': 8.045048813913775,\n            'f': \"8.045048813913775\",\n        },\n{\n            'v': 0.04720932003350339,\n            'f': \"0.04720932003350339\",\n        },\n{\n            'v': 0.01892501237341049,\n            'f': \"0.01892501237341049\",\n        },\n{\n            'v': 0.02191201717418135,\n            'f': \"0.02191201717418135\",\n        },\n{\n            'v': 0.8277216866919457,\n            'f': \"0.8277216866919457\",\n        },\n{\n            'v': 0.6852681704859168,\n            'f': \"0.6852681704859168\",\n        },\n{\n            'v': 0.749749548792234,\n            'f': \"0.749749548792234\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 20,\n            'f': \"20\",\n        },\n\"log_reg\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.001, 'batch_size': 128}\",\n{\n            'v': 20,\n            'f': \"20\",\n        },\n{\n            'v': 3.6071,\n            'f': \"3.6071\",\n        },\n{\n            'v': 3.5763,\n            'f': \"3.5763\",\n        },\n{\n            'v': 0.6212898804538186,\n            'f': \"0.6212898804538186\",\n        },\n{\n            'v': 0.87670612589088,\n            'f': \"0.87670612589088\",\n        },\n{\n            'v': 0.69909520620369,\n            'f': \"0.69909520620369\",\n        },\n{\n            'v': 0.648910411622276,\n            'f': \"0.648910411622276\",\n        },\n{\n            'v': 0.8743865934342219,\n            'f': \"0.8743865934342219\",\n        },\n{\n            'v': 0.719839481558182,\n            'f': \"0.719839481558182\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 21,\n            'f': \"21\",\n        },\n\"log_reg\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.0007, 'batch_size': 128}\",\n{\n            'v': 23,\n            'f': \"23\",\n        },\n{\n            'v': 3.6636,\n            'f': \"3.6636\",\n        },\n{\n            'v': 3.6278,\n            'f': \"3.6278\",\n        },\n{\n            'v': 0.6093657199421305,\n            'f': \"0.6093657199421305\",\n        },\n{\n            'v': 0.875767157994834,\n            'f': \"0.875767157994834\",\n        },\n{\n            'v': 0.6896280382756033,\n            'f': \"0.6896280382756033\",\n        },\n{\n            'v': 0.652747955594134,\n            'f': \"0.652747955594134\",\n        },\n{\n            'v': 0.8726997429241059,\n            'f': \"0.8726997429241059\",\n        },\n{\n            'v': 0.7229997771961647,\n            'f': \"0.7229997771961647\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 22,\n            'f': \"22\",\n        },\n\"deep_rescnn\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.001, 'batch_size': 128}\",\n{\n            'v': 44,\n            'f': \"44\",\n        },\n{\n            'v': 0.185,\n            'f': \"0.185\",\n        },\n{\n            'v': 1.1075,\n            'f': \"1.1075\",\n        },\n{\n            'v': 0.9745374248077362,\n            'f': \"0.9745374248077362\",\n        },\n{\n            'v': 0.9851596263975587,\n            'f': \"0.9851596263975587\",\n        },\n{\n            'v': 0.9782400695060557,\n            'f': \"0.9782400695060557\",\n        },\n{\n            'v': 0.967654986522911,\n            'f': \"0.967654986522911\",\n        },\n{\n            'v': 0.9755955480052275,\n            'f': \"0.9755955480052275\",\n        },\n{\n            'v': 0.9703088331598252,\n            'f': \"0.9703088331598252\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 23,\n            'f': \"23\",\n        },\n\"deep_rescnn\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.0007, 'batch_size': 128}\",\n{\n            'v': 44,\n            'f': \"44\",\n        },\n{\n            'v': 0.1385,\n            'f': \"0.1385\",\n        },\n{\n            'v': 1.3236,\n            'f': \"1.3236\",\n        },\n{\n            'v': 0.9805071194700373,\n            'f': \"0.9805071194700373\",\n        },\n{\n            'v': 0.9883724845291103,\n            'f': \"0.9883724845291103\",\n        },\n{\n            'v': 0.9833026613718588,\n            'f': \"0.9833026613718588\",\n        },\n{\n            'v': 0.9781168623509525,\n            'f': \"0.9781168623509525\",\n        },\n{\n            'v': 0.9812555590024558,\n            'f': \"0.9812555590024558\",\n        },\n{\n            'v': 0.9791492452037855,\n            'f': \"0.9791492452037855\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }]],\n        columns: [[\"number\", \"index\"], [\"string\", \"model_name\"], [\"string\", \"hyperparameter\"], [\"number\", \"best_epoch\"], [\"number\", \"best_train_cost\"], [\"number\", \"best_val_cost\"], [\"number\", \"best_train_recall\"], [\"number\", \"best_train_precision\"], [\"number\", \"best_train_f1\"], [\"number\", \"best_val_recall\"], [\"number\", \"best_val_precision\"], [\"number\", \"best_val_f1\"], [\"number\", \"best_test_recall\"], [\"number\", \"best_test_precision\"], [\"number\", \"best_test_f1\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: \"0\",\n      });\n    "
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save\n",
        "\n",
        "#benchmark.to_csv('/content/drive/MyDrive/arrhythmia_classification/benchmark.csv',index=False)"
      ],
      "metadata": {
        "id": "xY6N8ZpS0ytM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this experiment, we will perform a random search to determine the optimal learning rate for our model. Learning rate is a crucial hyperparameter to fine-tune, and we believe that exploring values between 0.0000794 to 0.0001 will lead to the best results.\n",
        "\n",
        "Based on our intuition, we expect that the optimal learning rate will be within this range. By performing this experiment, we hope to identify the best learning rate for our model and improve its overall performance."
      ],
      "metadata": {
        "id": "EhBZ3_aGbhP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "# Define the hyperparameters to search over\n",
        "def experiment_3(benchmark):\n",
        "    \"\"\"\n",
        "    Random search for learning rate for deep_rescnn\n",
        "    \"\"\"\n",
        "    name = ['deep_rescnn']\n",
        "    weight_decay = [1e-2]\n",
        "    lr = [10**-random.uniform(3,4.1) for i in range(5)] # Random search learning rate\n",
        "    batch_size = [64,128]\n",
        "\n",
        "    # Create a Cartesian product of all hyperparameter combinations\n",
        "    hyperparams = list(itertools.product(name, weight_decay, lr, batch_size))\n",
        "    print(f'random search : perform {len(hyperparams)} searchs')\n",
        "\n",
        "    # Loop over each combination of hyperparameters and train/evaluate the model\n",
        "    best_val_f1 = 0.0\n",
        "    num_epochs = 80\n",
        "    for i, (name, wd, lr, bs) in enumerate(hyperparams):\n",
        "\n",
        "        print(f'\\n üîé search {i} : {name} --- lr : {lr}, weight_decay : {wd}, batch_size : {bs}')\n",
        "\n",
        "        # Setup Device\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        # Create the model, optimizer, and loss function\n",
        "        model = get_architecture(name = name, device = device)\n",
        "        class_weights_normalized = get_weighted_for_ce(y_train)\n",
        "        criterion = nn.CrossEntropyLoss(weight=class_weights_normalized.to(device))\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), weight_decay=wd)\n",
        "\n",
        "        # Create the data loaders\n",
        "        train_loader, val_loader, test_loader = get_loader(train_set, val_set, test_set, train_batch_size=bs)\n",
        "\n",
        "        # Train and evaluate the model\n",
        "        scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=0)\n",
        "        model, model_stat = train(model, optimizer, scheduler, criterion, train_loader, val_loader, num_epochs)\n",
        "\n",
        "        \n",
        "        # save the best model configuration based on validation F1 score\n",
        "        if model_stat['best_val_f1'] > best_val_f1:\n",
        "            best_val_f1 = model_stat['best_val_f1']\n",
        "            best_model = deepcopy(model.state_dict())\n",
        "        \n",
        "        row = {'model_name' : name,\n",
        "            'hyperparameter' : {'weight_decay' : wd, 'learning_rate' : lr,\n",
        "                                'batch_size' : bs,},\n",
        "            'best_epoch' : model_stat['best_epoch'],\n",
        "            'best_train_cost' : model_stat['best_train_cost'],\n",
        "            'best_val_cost' : model_stat['best_val_cost'],\n",
        "            'best_train_recall' : model_stat['best_train_recall'],\n",
        "            'best_train_precision' : model_stat['best_train_precision'],\n",
        "            'best_train_f1' : model_stat['best_train_f1'],\n",
        "            'best_val_recall' : model_stat['best_val_recall'],\n",
        "            'best_val_precision' : model_stat['best_val_precision'],\n",
        "            'best_val_f1' : model_stat['best_val_f1'],\n",
        "            'best_test_recall' : None,\n",
        "            'best_test_precision' : None,\n",
        "            'best_test_f1' : None,\n",
        "            }\n",
        "\n",
        "        benchmark =benchmark.append(row, ignore_index=True)\n",
        "\n",
        "    return benchmark, best_model"
      ],
      "metadata": {
        "id": "TbtJJ3R_YXrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "benchmark, best_model = experiment_3(benchmark)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsalI2AcYetO",
        "outputId": "e326c10c-37c5-489d-ae4b-cc9d69142e1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "random search : perform 10 searchs\n",
            "\n",
            " üîé search 0 : deep_rescnn --- lr : 0.0005417906876661164, weight_decay : 0.01, batch_size : 64\n",
            "Epoch: 1/80, Train Loss: 3.2514, Train Acc: 0.6777, Train F1: 0.7469, Val Loss: 2.0873, Val Acc: 0.7824, Val F1: 0.8353\n",
            "Epoch: 2/80, Train Loss: 2.0275, Train Acc: 0.8036, Train F1: 0.8503, Val Loss: 2.0500, Val Acc: 0.7672, Val F1: 0.8191\n",
            "Epoch: 3/80, Train Loss: 1.6606, Train Acc: 0.8408, Train F1: 0.8792, Val Loss: 1.6263, Val Acc: 0.8719, Val F1: 0.8989\n",
            "Epoch: 4/80, Train Loss: 1.4667, Train Acc: 0.8623, Train F1: 0.8960, Val Loss: 1.8846, Val Acc: 0.6742, Val F1: 0.7589\n",
            "Epoch: 5/80, Train Loss: 1.3631, Train Acc: 0.8692, Train F1: 0.9024, Val Loss: 1.3969, Val Acc: 0.8849, Val F1: 0.9116\n",
            "Epoch: 6/80, Train Loss: 1.2286, Train Acc: 0.8858, Train F1: 0.9148, Val Loss: 1.3722, Val Acc: 0.9218, Val F1: 0.9358\n",
            "Epoch: 7/80, Train Loss: 1.1118, Train Acc: 0.8908, Train F1: 0.9186, Val Loss: 1.4422, Val Acc: 0.8934, Val F1: 0.9186\n",
            "Epoch: 8/80, Train Loss: 1.0256, Train Acc: 0.8991, Train F1: 0.9248, Val Loss: 1.3127, Val Acc: 0.8027, Val F1: 0.8542\n",
            "Epoch: 9/80, Train Loss: 0.9712, Train Acc: 0.9050, Train F1: 0.9290, Val Loss: 1.1494, Val Acc: 0.9346, Val F1: 0.9448\n",
            "Epoch: 10/80, Train Loss: 0.8990, Train Acc: 0.9088, Train F1: 0.9318, Val Loss: 1.1053, Val Acc: 0.8846, Val F1: 0.9130\n",
            "Epoch: 11/80, Train Loss: 0.8695, Train Acc: 0.9128, Train F1: 0.9348, Val Loss: 1.0400, Val Acc: 0.9212, Val F1: 0.9352\n",
            "Epoch: 12/80, Train Loss: 0.7801, Train Acc: 0.9178, Train F1: 0.9384, Val Loss: 1.0771, Val Acc: 0.9264, Val F1: 0.9389\n",
            "Epoch: 13/80, Train Loss: 0.7639, Train Acc: 0.9177, Train F1: 0.9385, Val Loss: 1.5521, Val Acc: 0.8321, Val F1: 0.8846\n",
            "Epoch: 14/80, Train Loss: 0.8033, Train Acc: 0.9198, Train F1: 0.9401, Val Loss: 1.1519, Val Acc: 0.9380, Val F1: 0.9481\n",
            "Epoch: 15/80, Train Loss: 0.6980, Train Acc: 0.9276, Train F1: 0.9454, Val Loss: 1.0663, Val Acc: 0.9451, Val F1: 0.9522\n",
            "Epoch: 16/80, Train Loss: 0.6726, Train Acc: 0.9287, Train F1: 0.9459, Val Loss: 1.1792, Val Acc: 0.9439, Val F1: 0.9527\n",
            "Epoch: 17/80, Train Loss: 0.6846, Train Acc: 0.9264, Train F1: 0.9450, Val Loss: 1.1168, Val Acc: 0.9473, Val F1: 0.9569\n",
            "Epoch: 18/80, Train Loss: 0.6758, Train Acc: 0.9273, Train F1: 0.9454, Val Loss: 0.9985, Val Acc: 0.9448, Val F1: 0.9547\n",
            "Epoch: 19/80, Train Loss: 0.6111, Train Acc: 0.9321, Train F1: 0.9492, Val Loss: 1.1115, Val Acc: 0.9363, Val F1: 0.9466\n",
            "Epoch: 20/80, Train Loss: 0.5535, Train Acc: 0.9391, Train F1: 0.9537, Val Loss: 0.9163, Val Acc: 0.9402, Val F1: 0.9504\n",
            "Epoch: 21/80, Train Loss: 0.5777, Train Acc: 0.9377, Train F1: 0.9534, Val Loss: 1.1217, Val Acc: 0.9574, Val F1: 0.9629\n",
            "Epoch: 22/80, Train Loss: 0.5677, Train Acc: 0.9388, Train F1: 0.9536, Val Loss: 1.0321, Val Acc: 0.9358, Val F1: 0.9460\n",
            "Epoch: 23/80, Train Loss: 0.4978, Train Acc: 0.9430, Train F1: 0.9572, Val Loss: 1.3587, Val Acc: 0.9572, Val F1: 0.9608\n",
            "Epoch: 24/80, Train Loss: 0.5056, Train Acc: 0.9424, Train F1: 0.9561, Val Loss: 0.9340, Val Acc: 0.9377, Val F1: 0.9475\n",
            "Epoch: 25/80, Train Loss: 0.5288, Train Acc: 0.9393, Train F1: 0.9546, Val Loss: 1.1076, Val Acc: 0.9515, Val F1: 0.9592\n",
            "Epoch: 26/80, Train Loss: 0.5121, Train Acc: 0.9418, Train F1: 0.9562, Val Loss: 1.1611, Val Acc: 0.9035, Val F1: 0.9248\n",
            "Epoch: 27/80, Train Loss: 0.4785, Train Acc: 0.9429, Train F1: 0.9571, Val Loss: 1.1088, Val Acc: 0.9492, Val F1: 0.9589\n",
            "Epoch: 28/80, Train Loss: 0.4326, Train Acc: 0.9473, Train F1: 0.9597, Val Loss: 0.9180, Val Acc: 0.9433, Val F1: 0.9511\n",
            "Epoch: 29/80, Train Loss: 0.4287, Train Acc: 0.9493, Train F1: 0.9615, Val Loss: 1.0808, Val Acc: 0.9470, Val F1: 0.9529\n",
            "Epoch: 30/80, Train Loss: 0.4395, Train Acc: 0.9490, Train F1: 0.9613, Val Loss: 0.8803, Val Acc: 0.9392, Val F1: 0.9484\n",
            "Epoch: 31/80, Train Loss: 0.3962, Train Acc: 0.9540, Train F1: 0.9645, Val Loss: 1.0112, Val Acc: 0.9545, Val F1: 0.9622\n",
            "Epoch: 32/80, Train Loss: 0.4074, Train Acc: 0.9520, Train F1: 0.9634, Val Loss: 1.1635, Val Acc: 0.9648, Val F1: 0.9683\n",
            "Epoch: 33/80, Train Loss: 0.3633, Train Acc: 0.9564, Train F1: 0.9665, Val Loss: 1.0583, Val Acc: 0.9178, Val F1: 0.9350\n",
            "Epoch: 34/80, Train Loss: 0.3798, Train Acc: 0.9545, Train F1: 0.9649, Val Loss: 0.9496, Val Acc: 0.9533, Val F1: 0.9604\n",
            "Epoch: 35/80, Train Loss: 0.3987, Train Acc: 0.9526, Train F1: 0.9640, Val Loss: 1.0594, Val Acc: 0.9471, Val F1: 0.9545\n",
            "Epoch: 36/80, Train Loss: 0.3277, Train Acc: 0.9604, Train F1: 0.9695, Val Loss: 1.0503, Val Acc: 0.9663, Val F1: 0.9696\n",
            "Epoch: 37/80, Train Loss: 0.3236, Train Acc: 0.9613, Train F1: 0.9704, Val Loss: 1.0579, Val Acc: 0.9525, Val F1: 0.9591\n",
            "Epoch: 38/80, Train Loss: 0.3421, Train Acc: 0.9583, Train F1: 0.9682, Val Loss: 0.9315, Val Acc: 0.9518, Val F1: 0.9590\n",
            "Epoch: 39/80, Train Loss: 0.3082, Train Acc: 0.9613, Train F1: 0.9702, Val Loss: 0.9964, Val Acc: 0.9391, Val F1: 0.9497\n",
            "Epoch: 40/80, Train Loss: 0.3445, Train Acc: 0.9591, Train F1: 0.9685, Val Loss: 0.9778, Val Acc: 0.9555, Val F1: 0.9618\n",
            "Epoch: 41/80, Train Loss: 0.2780, Train Acc: 0.9657, Train F1: 0.9736, Val Loss: 0.9211, Val Acc: 0.9566, Val F1: 0.9615\n",
            "Epoch: 42/80, Train Loss: 0.2779, Train Acc: 0.9654, Train F1: 0.9731, Val Loss: 1.1964, Val Acc: 0.9628, Val F1: 0.9668\n",
            "Epoch: 43/80, Train Loss: 0.2746, Train Acc: 0.9645, Train F1: 0.9728, Val Loss: 1.1155, Val Acc: 0.9625, Val F1: 0.9668\n",
            "Epoch: 44/80, Train Loss: 0.2324, Train Acc: 0.9700, Train F1: 0.9765, Val Loss: 1.2540, Val Acc: 0.9729, Val F1: 0.9744\n",
            "Epoch: 45/80, Train Loss: 0.2654, Train Acc: 0.9672, Train F1: 0.9745, Val Loss: 0.9955, Val Acc: 0.9578, Val F1: 0.9632\n",
            "Epoch: 46/80, Train Loss: 0.2449, Train Acc: 0.9714, Train F1: 0.9775, Val Loss: 1.1175, Val Acc: 0.9718, Val F1: 0.9739\n",
            "Epoch: 47/80, Train Loss: 0.2262, Train Acc: 0.9715, Train F1: 0.9775, Val Loss: 1.1266, Val Acc: 0.9697, Val F1: 0.9721\n",
            "Epoch: 48/80, Train Loss: 0.2229, Train Acc: 0.9726, Train F1: 0.9786, Val Loss: 1.0350, Val Acc: 0.9641, Val F1: 0.9682\n",
            "Epoch: 49/80, Train Loss: 0.2135, Train Acc: 0.9736, Train F1: 0.9794, Val Loss: 1.0655, Val Acc: 0.9552, Val F1: 0.9603\n",
            "Epoch: 50/80, Train Loss: 0.2328, Train Acc: 0.9721, Train F1: 0.9782, Val Loss: 1.0764, Val Acc: 0.9529, Val F1: 0.9590\n",
            "Epoch: 51/80, Train Loss: 0.1876, Train Acc: 0.9759, Train F1: 0.9810, Val Loss: 0.9578, Val Acc: 0.9548, Val F1: 0.9609\n",
            "Epoch: 52/80, Train Loss: 0.1943, Train Acc: 0.9750, Train F1: 0.9806, Val Loss: 1.1417, Val Acc: 0.9693, Val F1: 0.9720\n",
            "Epoch: 53/80, Train Loss: 0.1753, Train Acc: 0.9775, Train F1: 0.9823, Val Loss: 1.2348, Val Acc: 0.9746, Val F1: 0.9761\n",
            "Epoch: 54/80, Train Loss: 0.1742, Train Acc: 0.9772, Train F1: 0.9822, Val Loss: 1.1057, Val Acc: 0.9719, Val F1: 0.9740\n",
            "Epoch: 55/80, Train Loss: 0.1668, Train Acc: 0.9784, Train F1: 0.9830, Val Loss: 1.1779, Val Acc: 0.9711, Val F1: 0.9737\n",
            "Epoch: 56/80, Train Loss: 0.1569, Train Acc: 0.9798, Train F1: 0.9839, Val Loss: 1.1560, Val Acc: 0.9705, Val F1: 0.9729\n",
            "Epoch: 57/80, Train Loss: 0.1572, Train Acc: 0.9808, Train F1: 0.9849, Val Loss: 1.2555, Val Acc: 0.9779, Val F1: 0.9791\n",
            "Epoch: 58/80, Train Loss: 0.1548, Train Acc: 0.9811, Train F1: 0.9850, Val Loss: 1.1631, Val Acc: 0.9673, Val F1: 0.9708\n",
            "Epoch: 59/80, Train Loss: 0.1397, Train Acc: 0.9823, Train F1: 0.9859, Val Loss: 1.2153, Val Acc: 0.9654, Val F1: 0.9687\n",
            "Epoch: 60/80, Train Loss: 0.1475, Train Acc: 0.9816, Train F1: 0.9856, Val Loss: 1.2615, Val Acc: 0.9757, Val F1: 0.9772\n",
            "Epoch: 61/80, Train Loss: 0.1331, Train Acc: 0.9835, Train F1: 0.9868, Val Loss: 1.2741, Val Acc: 0.9792, Val F1: 0.9802\n",
            "Epoch: 62/80, Train Loss: 0.1312, Train Acc: 0.9836, Train F1: 0.9869, Val Loss: 1.1557, Val Acc: 0.9764, Val F1: 0.9778\n",
            "Epoch: 63/80, Train Loss: 0.1193, Train Acc: 0.9849, Train F1: 0.9880, Val Loss: 1.3898, Val Acc: 0.9614, Val F1: 0.9658\n",
            "Epoch: 64/80, Train Loss: 0.1220, Train Acc: 0.9850, Train F1: 0.9880, Val Loss: 1.2258, Val Acc: 0.9748, Val F1: 0.9765\n",
            "Epoch: 65/80, Train Loss: 0.1190, Train Acc: 0.9850, Train F1: 0.9880, Val Loss: 1.1034, Val Acc: 0.9709, Val F1: 0.9734\n",
            "Epoch: 66/80, Train Loss: 0.1105, Train Acc: 0.9863, Train F1: 0.9889, Val Loss: 1.2312, Val Acc: 0.9784, Val F1: 0.9796\n",
            "Epoch: 67/80, Train Loss: 0.1100, Train Acc: 0.9864, Train F1: 0.9890, Val Loss: 1.2964, Val Acc: 0.9776, Val F1: 0.9787\n",
            "Epoch: 68/80, Train Loss: 0.1042, Train Acc: 0.9872, Train F1: 0.9897, Val Loss: 1.2609, Val Acc: 0.9781, Val F1: 0.9793\n",
            "Epoch: 69/80, Train Loss: 0.1039, Train Acc: 0.9869, Train F1: 0.9894, Val Loss: 1.3082, Val Acc: 0.9781, Val F1: 0.9792\n",
            "Epoch: 70/80, Train Loss: 0.1016, Train Acc: 0.9875, Train F1: 0.9899, Val Loss: 1.2864, Val Acc: 0.9767, Val F1: 0.9781\n",
            "Epoch: 71/80, Train Loss: 0.0993, Train Acc: 0.9878, Train F1: 0.9901, Val Loss: 1.3190, Val Acc: 0.9777, Val F1: 0.9790\n",
            "Epoch: 72/80, Train Loss: 0.0964, Train Acc: 0.9883, Train F1: 0.9904, Val Loss: 1.3429, Val Acc: 0.9799, Val F1: 0.9808\n",
            "Epoch: 73/80, Train Loss: 0.0951, Train Acc: 0.9882, Train F1: 0.9904, Val Loss: 1.3250, Val Acc: 0.9789, Val F1: 0.9799\n",
            "Epoch: 74/80, Train Loss: 0.0936, Train Acc: 0.9886, Train F1: 0.9908, Val Loss: 1.3270, Val Acc: 0.9793, Val F1: 0.9802\n",
            "Epoch: 75/80, Train Loss: 0.0920, Train Acc: 0.9888, Train F1: 0.9910, Val Loss: 1.3268, Val Acc: 0.9781, Val F1: 0.9792\n",
            "Epoch: 76/80, Train Loss: 0.0912, Train Acc: 0.9888, Train F1: 0.9910, Val Loss: 1.3009, Val Acc: 0.9782, Val F1: 0.9793\n",
            "Epoch: 77/80, Train Loss: 0.0901, Train Acc: 0.9890, Train F1: 0.9910, Val Loss: 1.3433, Val Acc: 0.9784, Val F1: 0.9795\n",
            "Epoch: 78/80, Train Loss: 0.0892, Train Acc: 0.9888, Train F1: 0.9909, Val Loss: 1.3625, Val Acc: 0.9794, Val F1: 0.9803\n",
            "Epoch: 79/80, Train Loss: 0.0888, Train Acc: 0.9893, Train F1: 0.9913, Val Loss: 1.3617, Val Acc: 0.9791, Val F1: 0.9800\n",
            "Epoch: 80/80, Train Loss: 0.0885, Train Acc: 0.9892, Train F1: 0.9912, Val Loss: 1.3628, Val Acc: 0.9792, Val F1: 0.9801\n",
            "\n",
            " üîé search 1 : deep_rescnn --- lr : 0.0005417906876661164, weight_decay : 0.01, batch_size : 128\n",
            "Epoch: 1/80, Train Loss: 3.5152, Train Acc: 0.6651, Train F1: 0.7280, Val Loss: 2.2754, Val Acc: 0.7749, Val F1: 0.8262\n",
            "Epoch: 2/80, Train Loss: 2.1147, Train Acc: 0.7926, Train F1: 0.8403, Val Loss: 1.9000, Val Acc: 0.8557, Val F1: 0.8897\n",
            "Epoch: 3/80, Train Loss: 1.8113, Train Acc: 0.8274, Train F1: 0.8661, Val Loss: 1.7667, Val Acc: 0.8560, Val F1: 0.8859\n",
            "Epoch: 4/80, Train Loss: 1.5205, Train Acc: 0.8498, Train F1: 0.8848, Val Loss: 1.5280, Val Acc: 0.8905, Val F1: 0.9114\n",
            "Epoch: 5/80, Train Loss: 1.3950, Train Acc: 0.8639, Train F1: 0.8964, Val Loss: 1.4577, Val Acc: 0.8867, Val F1: 0.9121\n",
            "Epoch: 6/80, Train Loss: 1.2943, Train Acc: 0.8788, Train F1: 0.9075, Val Loss: 1.3161, Val Acc: 0.8856, Val F1: 0.9124\n",
            "Epoch: 7/80, Train Loss: 1.1786, Train Acc: 0.8846, Train F1: 0.9122, Val Loss: 1.2337, Val Acc: 0.8878, Val F1: 0.9103\n",
            "Epoch: 8/80, Train Loss: 1.0380, Train Acc: 0.8983, Train F1: 0.9219, Val Loss: 1.3835, Val Acc: 0.7828, Val F1: 0.8446\n",
            "Epoch: 9/80, Train Loss: 0.9662, Train Acc: 0.8993, Train F1: 0.9228, Val Loss: 1.1967, Val Acc: 0.9275, Val F1: 0.9400\n",
            "Epoch: 10/80, Train Loss: 0.9487, Train Acc: 0.9031, Train F1: 0.9254, Val Loss: 1.6009, Val Acc: 0.7241, Val F1: 0.7997\n",
            "Epoch: 11/80, Train Loss: 0.8709, Train Acc: 0.9081, Train F1: 0.9292, Val Loss: 1.1686, Val Acc: 0.9015, Val F1: 0.9187\n",
            "Epoch: 12/80, Train Loss: 0.8572, Train Acc: 0.9086, Train F1: 0.9298, Val Loss: 1.1435, Val Acc: 0.9338, Val F1: 0.9471\n",
            "Epoch: 13/80, Train Loss: 0.8089, Train Acc: 0.9133, Train F1: 0.9333, Val Loss: 1.1553, Val Acc: 0.8915, Val F1: 0.9158\n",
            "Epoch: 14/80, Train Loss: 0.7301, Train Acc: 0.9220, Train F1: 0.9392, Val Loss: 1.2556, Val Acc: 0.8917, Val F1: 0.9118\n",
            "Epoch: 15/80, Train Loss: 0.7499, Train Acc: 0.9218, Train F1: 0.9389, Val Loss: 1.0920, Val Acc: 0.9241, Val F1: 0.9364\n",
            "Epoch: 16/80, Train Loss: 0.7192, Train Acc: 0.9215, Train F1: 0.9391, Val Loss: 1.1072, Val Acc: 0.9539, Val F1: 0.9602\n",
            "Epoch: 17/80, Train Loss: 0.6497, Train Acc: 0.9320, Train F1: 0.9462, Val Loss: 1.1482, Val Acc: 0.9193, Val F1: 0.9334\n",
            "Epoch: 18/80, Train Loss: 0.6428, Train Acc: 0.9302, Train F1: 0.9453, Val Loss: 1.3312, Val Acc: 0.9222, Val F1: 0.9440\n",
            "Epoch: 19/80, Train Loss: 0.6346, Train Acc: 0.9276, Train F1: 0.9439, Val Loss: 1.2425, Val Acc: 0.9466, Val F1: 0.9534\n",
            "Epoch: 20/80, Train Loss: 0.5960, Train Acc: 0.9350, Train F1: 0.9491, Val Loss: 1.1225, Val Acc: 0.9139, Val F1: 0.9318\n",
            "Epoch: 21/80, Train Loss: 0.5463, Train Acc: 0.9365, Train F1: 0.9502, Val Loss: 0.9778, Val Acc: 0.9275, Val F1: 0.9393\n",
            "Epoch: 22/80, Train Loss: 0.5535, Train Acc: 0.9351, Train F1: 0.9493, Val Loss: 1.1691, Val Acc: 0.9514, Val F1: 0.9573\n",
            "Epoch: 23/80, Train Loss: 0.5356, Train Acc: 0.9380, Train F1: 0.9512, Val Loss: 1.1120, Val Acc: 0.9271, Val F1: 0.9386\n",
            "Epoch: 24/80, Train Loss: 0.5005, Train Acc: 0.9406, Train F1: 0.9529, Val Loss: 1.0145, Val Acc: 0.9147, Val F1: 0.9334\n",
            "Epoch: 25/80, Train Loss: 0.5132, Train Acc: 0.9394, Train F1: 0.9524, Val Loss: 0.9184, Val Acc: 0.9328, Val F1: 0.9464\n",
            "Epoch: 26/80, Train Loss: 0.5154, Train Acc: 0.9410, Train F1: 0.9532, Val Loss: 1.1920, Val Acc: 0.9408, Val F1: 0.9501\n",
            "Epoch: 27/80, Train Loss: 0.4543, Train Acc: 0.9465, Train F1: 0.9571, Val Loss: 0.9523, Val Acc: 0.9361, Val F1: 0.9474\n",
            "Epoch: 28/80, Train Loss: 0.4302, Train Acc: 0.9475, Train F1: 0.9582, Val Loss: 1.0956, Val Acc: 0.9490, Val F1: 0.9563\n",
            "Epoch: 29/80, Train Loss: 0.4403, Train Acc: 0.9473, Train F1: 0.9579, Val Loss: 1.2073, Val Acc: 0.9650, Val F1: 0.9686\n",
            "Epoch: 30/80, Train Loss: 0.4360, Train Acc: 0.9503, Train F1: 0.9601, Val Loss: 1.0158, Val Acc: 0.9461, Val F1: 0.9531\n",
            "Epoch: 31/80, Train Loss: 0.3770, Train Acc: 0.9542, Train F1: 0.9630, Val Loss: 1.1809, Val Acc: 0.9635, Val F1: 0.9669\n",
            "Epoch: 32/80, Train Loss: 0.3765, Train Acc: 0.9531, Train F1: 0.9622, Val Loss: 1.1660, Val Acc: 0.9541, Val F1: 0.9598\n",
            "Epoch: 33/80, Train Loss: 0.3606, Train Acc: 0.9571, Train F1: 0.9652, Val Loss: 1.0063, Val Acc: 0.9444, Val F1: 0.9538\n",
            "Epoch: 34/80, Train Loss: 0.3719, Train Acc: 0.9542, Train F1: 0.9633, Val Loss: 1.0412, Val Acc: 0.9571, Val F1: 0.9628\n",
            "Epoch: 35/80, Train Loss: 0.3444, Train Acc: 0.9575, Train F1: 0.9658, Val Loss: 1.1622, Val Acc: 0.9683, Val F1: 0.9706\n",
            "Epoch: 36/80, Train Loss: 0.3502, Train Acc: 0.9565, Train F1: 0.9650, Val Loss: 1.0061, Val Acc: 0.9503, Val F1: 0.9573\n",
            "Epoch: 37/80, Train Loss: 0.3091, Train Acc: 0.9610, Train F1: 0.9683, Val Loss: 1.1709, Val Acc: 0.9630, Val F1: 0.9668\n",
            "Epoch: 38/80, Train Loss: 0.3497, Train Acc: 0.9581, Train F1: 0.9660, Val Loss: 1.0228, Val Acc: 0.9579, Val F1: 0.9635\n",
            "Epoch: 39/80, Train Loss: 0.2744, Train Acc: 0.9654, Train F1: 0.9714, Val Loss: 1.0496, Val Acc: 0.9336, Val F1: 0.9498\n",
            "Epoch: 40/80, Train Loss: 0.2987, Train Acc: 0.9628, Train F1: 0.9695, Val Loss: 1.0144, Val Acc: 0.9518, Val F1: 0.9577\n",
            "Epoch: 41/80, Train Loss: 0.2994, Train Acc: 0.9643, Train F1: 0.9708, Val Loss: 1.1754, Val Acc: 0.9170, Val F1: 0.9334\n",
            "Epoch: 42/80, Train Loss: 0.2934, Train Acc: 0.9637, Train F1: 0.9707, Val Loss: 1.1168, Val Acc: 0.9704, Val F1: 0.9726\n",
            "Epoch: 43/80, Train Loss: 0.2571, Train Acc: 0.9674, Train F1: 0.9731, Val Loss: 0.9759, Val Acc: 0.9636, Val F1: 0.9673\n",
            "Epoch: 44/80, Train Loss: 0.2709, Train Acc: 0.9655, Train F1: 0.9720, Val Loss: 1.1244, Val Acc: 0.9758, Val F1: 0.9774\n",
            "Epoch: 45/80, Train Loss: 0.2447, Train Acc: 0.9685, Train F1: 0.9740, Val Loss: 1.0654, Val Acc: 0.9668, Val F1: 0.9700\n",
            "Epoch: 46/80, Train Loss: 0.2363, Train Acc: 0.9707, Train F1: 0.9756, Val Loss: 1.0220, Val Acc: 0.9511, Val F1: 0.9588\n",
            "Epoch: 47/80, Train Loss: 0.2283, Train Acc: 0.9714, Train F1: 0.9763, Val Loss: 1.0032, Val Acc: 0.9376, Val F1: 0.9492\n",
            "Epoch: 48/80, Train Loss: 0.2319, Train Acc: 0.9693, Train F1: 0.9748, Val Loss: 1.0363, Val Acc: 0.9665, Val F1: 0.9698\n",
            "Epoch: 49/80, Train Loss: 0.2212, Train Acc: 0.9724, Train F1: 0.9772, Val Loss: 0.9895, Val Acc: 0.9440, Val F1: 0.9514\n",
            "Epoch: 50/80, Train Loss: 0.2053, Train Acc: 0.9731, Train F1: 0.9776, Val Loss: 1.1564, Val Acc: 0.9724, Val F1: 0.9747\n",
            "Epoch: 51/80, Train Loss: 0.2094, Train Acc: 0.9739, Train F1: 0.9783, Val Loss: 1.1628, Val Acc: 0.9711, Val F1: 0.9733\n",
            "Epoch: 52/80, Train Loss: 0.1988, Train Acc: 0.9740, Train F1: 0.9783, Val Loss: 1.0667, Val Acc: 0.9647, Val F1: 0.9680\n",
            "Epoch: 53/80, Train Loss: 0.1907, Train Acc: 0.9756, Train F1: 0.9794, Val Loss: 1.0388, Val Acc: 0.9385, Val F1: 0.9500\n",
            "Epoch: 54/80, Train Loss: 0.1826, Train Acc: 0.9765, Train F1: 0.9805, Val Loss: 1.4118, Val Acc: 0.9718, Val F1: 0.9735\n",
            "Epoch: 55/80, Train Loss: 0.1802, Train Acc: 0.9778, Train F1: 0.9813, Val Loss: 1.0357, Val Acc: 0.9726, Val F1: 0.9751\n",
            "Epoch: 56/80, Train Loss: 0.1761, Train Acc: 0.9776, Train F1: 0.9812, Val Loss: 1.0163, Val Acc: 0.9609, Val F1: 0.9658\n",
            "Epoch: 57/80, Train Loss: 0.1608, Train Acc: 0.9800, Train F1: 0.9831, Val Loss: 1.1307, Val Acc: 0.9696, Val F1: 0.9728\n",
            "Epoch: 58/80, Train Loss: 0.1606, Train Acc: 0.9796, Train F1: 0.9827, Val Loss: 1.0683, Val Acc: 0.9683, Val F1: 0.9720\n",
            "Epoch: 59/80, Train Loss: 0.1558, Train Acc: 0.9795, Train F1: 0.9828, Val Loss: 1.0956, Val Acc: 0.9608, Val F1: 0.9670\n",
            "Epoch: 60/80, Train Loss: 0.1496, Train Acc: 0.9813, Train F1: 0.9842, Val Loss: 1.2055, Val Acc: 0.9762, Val F1: 0.9774\n",
            "Epoch: 61/80, Train Loss: 0.1404, Train Acc: 0.9820, Train F1: 0.9847, Val Loss: 1.4190, Val Acc: 0.9801, Val F1: 0.9807\n",
            "Epoch: 62/80, Train Loss: 0.1411, Train Acc: 0.9824, Train F1: 0.9851, Val Loss: 1.0938, Val Acc: 0.9704, Val F1: 0.9729\n",
            "Epoch: 63/80, Train Loss: 0.1347, Train Acc: 0.9831, Train F1: 0.9856, Val Loss: 1.1158, Val Acc: 0.9754, Val F1: 0.9769\n",
            "Epoch: 64/80, Train Loss: 0.1315, Train Acc: 0.9834, Train F1: 0.9858, Val Loss: 1.2047, Val Acc: 0.9759, Val F1: 0.9772\n",
            "Epoch: 65/80, Train Loss: 0.1388, Train Acc: 0.9830, Train F1: 0.9855, Val Loss: 1.1945, Val Acc: 0.9749, Val F1: 0.9765\n",
            "Epoch: 66/80, Train Loss: 0.1256, Train Acc: 0.9840, Train F1: 0.9863, Val Loss: 1.1458, Val Acc: 0.9724, Val F1: 0.9744\n",
            "Epoch: 67/80, Train Loss: 0.1221, Train Acc: 0.9845, Train F1: 0.9868, Val Loss: 1.2807, Val Acc: 0.9768, Val F1: 0.9781\n",
            "Epoch: 68/80, Train Loss: 0.1185, Train Acc: 0.9853, Train F1: 0.9874, Val Loss: 1.2483, Val Acc: 0.9756, Val F1: 0.9771\n",
            "Epoch: 69/80, Train Loss: 0.1201, Train Acc: 0.9846, Train F1: 0.9867, Val Loss: 1.2141, Val Acc: 0.9756, Val F1: 0.9771\n",
            "Epoch: 70/80, Train Loss: 0.1161, Train Acc: 0.9857, Train F1: 0.9876, Val Loss: 1.2225, Val Acc: 0.9770, Val F1: 0.9783\n",
            "Epoch: 71/80, Train Loss: 0.1145, Train Acc: 0.9857, Train F1: 0.9876, Val Loss: 1.1649, Val Acc: 0.9733, Val F1: 0.9754\n",
            "Epoch: 72/80, Train Loss: 0.1125, Train Acc: 0.9855, Train F1: 0.9875, Val Loss: 1.2159, Val Acc: 0.9760, Val F1: 0.9775\n",
            "Epoch: 73/80, Train Loss: 0.1114, Train Acc: 0.9861, Train F1: 0.9880, Val Loss: 1.2505, Val Acc: 0.9758, Val F1: 0.9772\n",
            "Epoch: 74/80, Train Loss: 0.1103, Train Acc: 0.9860, Train F1: 0.9879, Val Loss: 1.2344, Val Acc: 0.9751, Val F1: 0.9767\n",
            "Epoch: 75/80, Train Loss: 0.1087, Train Acc: 0.9862, Train F1: 0.9880, Val Loss: 1.2573, Val Acc: 0.9768, Val F1: 0.9781\n",
            "Epoch: 76/80, Train Loss: 0.1076, Train Acc: 0.9864, Train F1: 0.9881, Val Loss: 1.2232, Val Acc: 0.9754, Val F1: 0.9769\n",
            "Epoch: 77/80, Train Loss: 0.1065, Train Acc: 0.9862, Train F1: 0.9882, Val Loss: 1.2592, Val Acc: 0.9764, Val F1: 0.9777\n",
            "Epoch: 78/80, Train Loss: 0.1062, Train Acc: 0.9865, Train F1: 0.9884, Val Loss: 1.2466, Val Acc: 0.9765, Val F1: 0.9779\n",
            "Epoch: 79/80, Train Loss: 0.1056, Train Acc: 0.9866, Train F1: 0.9884, Val Loss: 1.2470, Val Acc: 0.9763, Val F1: 0.9777\n",
            "Epoch: 80/80, Train Loss: 0.1052, Train Acc: 0.9865, Train F1: 0.9884, Val Loss: 1.2478, Val Acc: 0.9764, Val F1: 0.9777\n",
            "\n",
            " üîé search 2 : deep_rescnn --- lr : 0.0003401853431884869, weight_decay : 0.01, batch_size : 64\n",
            "Epoch: 1/80, Train Loss: 3.1957, Train Acc: 0.6880, Train F1: 0.7519, Val Loss: 2.1554, Val Acc: 0.7808, Val F1: 0.8323\n",
            "Epoch: 2/80, Train Loss: 1.9221, Train Acc: 0.8103, Train F1: 0.8557, Val Loss: 1.6636, Val Acc: 0.8639, Val F1: 0.8915\n",
            "Epoch: 3/80, Train Loss: 1.5776, Train Acc: 0.8482, Train F1: 0.8858, Val Loss: 1.7038, Val Acc: 0.8809, Val F1: 0.9075\n",
            "Epoch: 4/80, Train Loss: 1.4357, Train Acc: 0.8651, Train F1: 0.8991, Val Loss: 1.4343, Val Acc: 0.8920, Val F1: 0.9161\n",
            "Epoch: 5/80, Train Loss: 1.2911, Train Acc: 0.8742, Train F1: 0.9065, Val Loss: 1.3404, Val Acc: 0.8782, Val F1: 0.9059\n",
            "Epoch: 6/80, Train Loss: 1.2167, Train Acc: 0.8825, Train F1: 0.9124, Val Loss: 1.2713, Val Acc: 0.9096, Val F1: 0.9276\n",
            "Epoch: 7/80, Train Loss: 1.1246, Train Acc: 0.8928, Train F1: 0.9198, Val Loss: 1.2586, Val Acc: 0.8182, Val F1: 0.8648\n",
            "Epoch: 8/80, Train Loss: 1.0449, Train Acc: 0.9011, Train F1: 0.9260, Val Loss: 1.1331, Val Acc: 0.9415, Val F1: 0.9493\n",
            "Epoch: 9/80, Train Loss: 0.9797, Train Acc: 0.9027, Train F1: 0.9271, Val Loss: 1.2856, Val Acc: 0.8666, Val F1: 0.8980\n",
            "Epoch: 10/80, Train Loss: 0.9328, Train Acc: 0.9074, Train F1: 0.9307, Val Loss: 1.3281, Val Acc: 0.9137, Val F1: 0.9284\n",
            "Epoch: 11/80, Train Loss: 0.8784, Train Acc: 0.9142, Train F1: 0.9359, Val Loss: 1.1537, Val Acc: 0.8987, Val F1: 0.9223\n",
            "Epoch: 12/80, Train Loss: 0.8463, Train Acc: 0.9125, Train F1: 0.9352, Val Loss: 1.1324, Val Acc: 0.9385, Val F1: 0.9509\n",
            "Epoch: 13/80, Train Loss: 0.8240, Train Acc: 0.9165, Train F1: 0.9380, Val Loss: 1.1175, Val Acc: 0.9559, Val F1: 0.9604\n",
            "Epoch: 14/80, Train Loss: 0.7707, Train Acc: 0.9187, Train F1: 0.9394, Val Loss: 1.1544, Val Acc: 0.9287, Val F1: 0.9402\n",
            "Epoch: 15/80, Train Loss: 0.7194, Train Acc: 0.9221, Train F1: 0.9420, Val Loss: 1.0198, Val Acc: 0.9412, Val F1: 0.9506\n",
            "Epoch: 16/80, Train Loss: 0.7004, Train Acc: 0.9257, Train F1: 0.9444, Val Loss: 1.0941, Val Acc: 0.8872, Val F1: 0.9156\n",
            "Epoch: 17/80, Train Loss: 0.6915, Train Acc: 0.9239, Train F1: 0.9433, Val Loss: 1.1667, Val Acc: 0.9549, Val F1: 0.9613\n",
            "Epoch: 18/80, Train Loss: 0.6445, Train Acc: 0.9318, Train F1: 0.9488, Val Loss: 1.0366, Val Acc: 0.9380, Val F1: 0.9469\n",
            "Epoch: 19/80, Train Loss: 0.5938, Train Acc: 0.9361, Train F1: 0.9514, Val Loss: 1.2018, Val Acc: 0.8510, Val F1: 0.8892\n",
            "Epoch: 20/80, Train Loss: 0.5646, Train Acc: 0.9360, Train F1: 0.9520, Val Loss: 1.0771, Val Acc: 0.9476, Val F1: 0.9536\n",
            "Epoch: 21/80, Train Loss: 0.5615, Train Acc: 0.9378, Train F1: 0.9530, Val Loss: 0.9316, Val Acc: 0.8994, Val F1: 0.9175\n",
            "Epoch: 22/80, Train Loss: 0.5614, Train Acc: 0.9372, Train F1: 0.9529, Val Loss: 0.9592, Val Acc: 0.9027, Val F1: 0.9249\n",
            "Epoch: 23/80, Train Loss: 0.5206, Train Acc: 0.9425, Train F1: 0.9565, Val Loss: 0.9693, Val Acc: 0.9434, Val F1: 0.9515\n",
            "Epoch: 24/80, Train Loss: 0.5094, Train Acc: 0.9430, Train F1: 0.9568, Val Loss: 1.0943, Val Acc: 0.9004, Val F1: 0.9219\n",
            "Epoch: 25/80, Train Loss: 0.4807, Train Acc: 0.9439, Train F1: 0.9578, Val Loss: 0.9565, Val Acc: 0.9586, Val F1: 0.9633\n",
            "Epoch: 26/80, Train Loss: 0.4582, Train Acc: 0.9479, Train F1: 0.9600, Val Loss: 1.1021, Val Acc: 0.9364, Val F1: 0.9479\n",
            "Epoch: 27/80, Train Loss: 0.4461, Train Acc: 0.9493, Train F1: 0.9613, Val Loss: 1.2332, Val Acc: 0.9690, Val F1: 0.9710\n",
            "Epoch: 28/80, Train Loss: 0.4179, Train Acc: 0.9516, Train F1: 0.9631, Val Loss: 0.9941, Val Acc: 0.9338, Val F1: 0.9432\n",
            "Epoch: 29/80, Train Loss: 0.4152, Train Acc: 0.9516, Train F1: 0.9631, Val Loss: 1.0474, Val Acc: 0.9532, Val F1: 0.9593\n",
            "Epoch: 30/80, Train Loss: 0.4133, Train Acc: 0.9525, Train F1: 0.9637, Val Loss: 1.0751, Val Acc: 0.9580, Val F1: 0.9619\n",
            "Epoch: 31/80, Train Loss: 0.4091, Train Acc: 0.9516, Train F1: 0.9632, Val Loss: 1.1489, Val Acc: 0.9723, Val F1: 0.9742\n",
            "Epoch: 32/80, Train Loss: 0.3594, Train Acc: 0.9569, Train F1: 0.9670, Val Loss: 1.1403, Val Acc: 0.9489, Val F1: 0.9590\n",
            "Epoch: 33/80, Train Loss: 0.3641, Train Acc: 0.9567, Train F1: 0.9669, Val Loss: 1.0340, Val Acc: 0.9673, Val F1: 0.9704\n",
            "Epoch: 34/80, Train Loss: 0.3370, Train Acc: 0.9593, Train F1: 0.9686, Val Loss: 0.9585, Val Acc: 0.9311, Val F1: 0.9436\n",
            "Epoch: 35/80, Train Loss: 0.3399, Train Acc: 0.9590, Train F1: 0.9686, Val Loss: 1.0473, Val Acc: 0.9399, Val F1: 0.9490\n",
            "Epoch: 36/80, Train Loss: 0.3016, Train Acc: 0.9619, Train F1: 0.9709, Val Loss: 1.0499, Val Acc: 0.9640, Val F1: 0.9668\n",
            "Epoch: 37/80, Train Loss: 0.3323, Train Acc: 0.9617, Train F1: 0.9703, Val Loss: 1.0744, Val Acc: 0.9496, Val F1: 0.9575\n",
            "Epoch: 38/80, Train Loss: 0.3083, Train Acc: 0.9603, Train F1: 0.9698, Val Loss: 1.0947, Val Acc: 0.9717, Val F1: 0.9740\n",
            "Epoch: 39/80, Train Loss: 0.2636, Train Acc: 0.9687, Train F1: 0.9756, Val Loss: 1.0982, Val Acc: 0.9543, Val F1: 0.9601\n",
            "Epoch: 40/80, Train Loss: 0.2891, Train Acc: 0.9630, Train F1: 0.9717, Val Loss: 0.9208, Val Acc: 0.9646, Val F1: 0.9688\n",
            "Epoch: 41/80, Train Loss: 0.2551, Train Acc: 0.9678, Train F1: 0.9750, Val Loss: 0.9681, Val Acc: 0.9683, Val F1: 0.9716\n",
            "Epoch: 42/80, Train Loss: 0.2628, Train Acc: 0.9667, Train F1: 0.9742, Val Loss: 1.0829, Val Acc: 0.9326, Val F1: 0.9453\n",
            "Epoch: 43/80, Train Loss: 0.2264, Train Acc: 0.9723, Train F1: 0.9784, Val Loss: 0.9614, Val Acc: 0.9492, Val F1: 0.9573\n",
            "Epoch: 44/80, Train Loss: 0.2642, Train Acc: 0.9661, Train F1: 0.9739, Val Loss: 1.1213, Val Acc: 0.9753, Val F1: 0.9770\n",
            "Epoch: 45/80, Train Loss: 0.2130, Train Acc: 0.9726, Train F1: 0.9785, Val Loss: 0.9950, Val Acc: 0.9488, Val F1: 0.9563\n",
            "Epoch: 46/80, Train Loss: 0.2342, Train Acc: 0.9709, Train F1: 0.9774, Val Loss: 0.9498, Val Acc: 0.9582, Val F1: 0.9653\n",
            "Epoch: 47/80, Train Loss: 0.2004, Train Acc: 0.9749, Train F1: 0.9801, Val Loss: 0.9555, Val Acc: 0.9443, Val F1: 0.9534\n",
            "Epoch: 48/80, Train Loss: 0.2345, Train Acc: 0.9728, Train F1: 0.9785, Val Loss: 1.1072, Val Acc: 0.9702, Val F1: 0.9726\n",
            "Epoch: 49/80, Train Loss: 0.1943, Train Acc: 0.9755, Train F1: 0.9809, Val Loss: 0.9013, Val Acc: 0.9673, Val F1: 0.9706\n",
            "Epoch: 50/80, Train Loss: 0.1948, Train Acc: 0.9747, Train F1: 0.9802, Val Loss: 1.0221, Val Acc: 0.9453, Val F1: 0.9552\n",
            "Epoch: 51/80, Train Loss: 0.1703, Train Acc: 0.9783, Train F1: 0.9828, Val Loss: 1.3054, Val Acc: 0.9755, Val F1: 0.9767\n",
            "Epoch: 52/80, Train Loss: 0.1822, Train Acc: 0.9776, Train F1: 0.9823, Val Loss: 1.1557, Val Acc: 0.9715, Val F1: 0.9738\n",
            "Epoch: 53/80, Train Loss: 0.1779, Train Acc: 0.9774, Train F1: 0.9821, Val Loss: 1.2393, Val Acc: 0.9777, Val F1: 0.9788\n",
            "Epoch: 54/80, Train Loss: 0.1661, Train Acc: 0.9790, Train F1: 0.9834, Val Loss: 1.0244, Val Acc: 0.9697, Val F1: 0.9722\n",
            "Epoch: 55/80, Train Loss: 0.1568, Train Acc: 0.9795, Train F1: 0.9838, Val Loss: 1.2529, Val Acc: 0.9762, Val F1: 0.9773\n",
            "Epoch: 56/80, Train Loss: 0.1533, Train Acc: 0.9806, Train F1: 0.9848, Val Loss: 1.0382, Val Acc: 0.9732, Val F1: 0.9758\n",
            "Epoch: 57/80, Train Loss: 0.1461, Train Acc: 0.9814, Train F1: 0.9853, Val Loss: 1.2799, Val Acc: 0.9791, Val F1: 0.9799\n",
            "Epoch: 58/80, Train Loss: 0.1513, Train Acc: 0.9808, Train F1: 0.9848, Val Loss: 1.0253, Val Acc: 0.9714, Val F1: 0.9735\n",
            "Epoch: 59/80, Train Loss: 0.1393, Train Acc: 0.9823, Train F1: 0.9858, Val Loss: 1.1040, Val Acc: 0.9545, Val F1: 0.9598\n",
            "Epoch: 60/80, Train Loss: 0.1346, Train Acc: 0.9828, Train F1: 0.9863, Val Loss: 1.2076, Val Acc: 0.9722, Val F1: 0.9745\n",
            "Epoch: 61/80, Train Loss: 0.1322, Train Acc: 0.9836, Train F1: 0.9869, Val Loss: 1.1877, Val Acc: 0.9771, Val F1: 0.9783\n",
            "Epoch: 62/80, Train Loss: 0.1301, Train Acc: 0.9836, Train F1: 0.9869, Val Loss: 1.2004, Val Acc: 0.9772, Val F1: 0.9783\n",
            "Epoch: 63/80, Train Loss: 0.1279, Train Acc: 0.9842, Train F1: 0.9874, Val Loss: 1.0729, Val Acc: 0.9741, Val F1: 0.9758\n",
            "Epoch: 64/80, Train Loss: 0.1218, Train Acc: 0.9848, Train F1: 0.9879, Val Loss: 1.0932, Val Acc: 0.9735, Val F1: 0.9759\n",
            "Epoch: 65/80, Train Loss: 0.1173, Train Acc: 0.9848, Train F1: 0.9877, Val Loss: 1.1568, Val Acc: 0.9774, Val F1: 0.9788\n",
            "Epoch: 66/80, Train Loss: 0.1159, Train Acc: 0.9859, Train F1: 0.9886, Val Loss: 1.1985, Val Acc: 0.9789, Val F1: 0.9800\n",
            "Epoch: 67/80, Train Loss: 0.1130, Train Acc: 0.9862, Train F1: 0.9889, Val Loss: 1.1384, Val Acc: 0.9746, Val F1: 0.9765\n",
            "Epoch: 68/80, Train Loss: 0.1098, Train Acc: 0.9860, Train F1: 0.9889, Val Loss: 1.1366, Val Acc: 0.9752, Val F1: 0.9769\n",
            "Epoch: 69/80, Train Loss: 0.1075, Train Acc: 0.9861, Train F1: 0.9888, Val Loss: 1.2402, Val Acc: 0.9784, Val F1: 0.9794\n",
            "Epoch: 70/80, Train Loss: 0.1062, Train Acc: 0.9869, Train F1: 0.9894, Val Loss: 1.1637, Val Acc: 0.9785, Val F1: 0.9797\n",
            "Epoch: 71/80, Train Loss: 0.1037, Train Acc: 0.9870, Train F1: 0.9896, Val Loss: 1.2066, Val Acc: 0.9781, Val F1: 0.9793\n",
            "Epoch: 72/80, Train Loss: 0.1030, Train Acc: 0.9870, Train F1: 0.9895, Val Loss: 1.2665, Val Acc: 0.9791, Val F1: 0.9800\n",
            "Epoch: 73/80, Train Loss: 0.1011, Train Acc: 0.9873, Train F1: 0.9898, Val Loss: 1.2133, Val Acc: 0.9781, Val F1: 0.9793\n",
            "Epoch: 74/80, Train Loss: 0.0997, Train Acc: 0.9875, Train F1: 0.9900, Val Loss: 1.2309, Val Acc: 0.9784, Val F1: 0.9795\n",
            "Epoch: 75/80, Train Loss: 0.0993, Train Acc: 0.9875, Train F1: 0.9899, Val Loss: 1.2299, Val Acc: 0.9794, Val F1: 0.9804\n",
            "Epoch: 76/80, Train Loss: 0.0983, Train Acc: 0.9875, Train F1: 0.9900, Val Loss: 1.2451, Val Acc: 0.9791, Val F1: 0.9801\n",
            "Epoch: 77/80, Train Loss: 0.0977, Train Acc: 0.9877, Train F1: 0.9901, Val Loss: 1.2187, Val Acc: 0.9787, Val F1: 0.9798\n",
            "Epoch: 78/80, Train Loss: 0.0970, Train Acc: 0.9877, Train F1: 0.9900, Val Loss: 1.2325, Val Acc: 0.9789, Val F1: 0.9800\n",
            "Epoch: 79/80, Train Loss: 0.0966, Train Acc: 0.9878, Train F1: 0.9902, Val Loss: 1.2272, Val Acc: 0.9789, Val F1: 0.9800\n",
            "Epoch: 80/80, Train Loss: 0.0963, Train Acc: 0.9878, Train F1: 0.9901, Val Loss: 1.2275, Val Acc: 0.9789, Val F1: 0.9800\n",
            "\n",
            " üîé search 3 : deep_rescnn --- lr : 0.0003401853431884869, weight_decay : 0.01, batch_size : 128\n",
            "Epoch: 1/80, Train Loss: 3.4798, Train Acc: 0.6448, Train F1: 0.7122, Val Loss: 2.3999, Val Acc: 0.7050, Val F1: 0.7559\n",
            "Epoch: 2/80, Train Loss: 2.1306, Train Acc: 0.8005, Train F1: 0.8465, Val Loss: 2.0155, Val Acc: 0.7490, Val F1: 0.8183\n",
            "Epoch: 3/80, Train Loss: 1.8126, Train Acc: 0.8354, Train F1: 0.8733, Val Loss: 1.8660, Val Acc: 0.8124, Val F1: 0.8563\n",
            "Epoch: 4/80, Train Loss: 1.6144, Train Acc: 0.8533, Train F1: 0.8876, Val Loss: 1.5141, Val Acc: 0.8061, Val F1: 0.8572\n",
            "Epoch: 5/80, Train Loss: 1.4144, Train Acc: 0.8690, Train F1: 0.8996, Val Loss: 1.4315, Val Acc: 0.8639, Val F1: 0.8977\n",
            "Epoch: 6/80, Train Loss: 1.3528, Train Acc: 0.8707, Train F1: 0.9015, Val Loss: 1.3933, Val Acc: 0.8548, Val F1: 0.8900\n",
            "Epoch: 7/80, Train Loss: 1.1861, Train Acc: 0.8852, Train F1: 0.9116, Val Loss: 1.3012, Val Acc: 0.9287, Val F1: 0.9399\n",
            "Epoch: 8/80, Train Loss: 1.1742, Train Acc: 0.8870, Train F1: 0.9135, Val Loss: 1.4348, Val Acc: 0.8828, Val F1: 0.9083\n",
            "Epoch: 9/80, Train Loss: 1.0666, Train Acc: 0.8967, Train F1: 0.9204, Val Loss: 1.2602, Val Acc: 0.8624, Val F1: 0.8967\n",
            "Epoch: 10/80, Train Loss: 1.0305, Train Acc: 0.8994, Train F1: 0.9228, Val Loss: 1.5535, Val Acc: 0.8713, Val F1: 0.8949\n",
            "Epoch: 11/80, Train Loss: 0.9465, Train Acc: 0.9026, Train F1: 0.9251, Val Loss: 1.1220, Val Acc: 0.9418, Val F1: 0.9498\n",
            "Epoch: 12/80, Train Loss: 0.9169, Train Acc: 0.9111, Train F1: 0.9312, Val Loss: 1.1721, Val Acc: 0.9126, Val F1: 0.9309\n",
            "Epoch: 13/80, Train Loss: 0.8545, Train Acc: 0.9127, Train F1: 0.9327, Val Loss: 1.3281, Val Acc: 0.9228, Val F1: 0.9373\n",
            "Epoch: 14/80, Train Loss: 0.8048, Train Acc: 0.9175, Train F1: 0.9358, Val Loss: 1.1635, Val Acc: 0.8905, Val F1: 0.9170\n",
            "Epoch: 15/80, Train Loss: 0.8026, Train Acc: 0.9162, Train F1: 0.9352, Val Loss: 1.0032, Val Acc: 0.9227, Val F1: 0.9354\n",
            "Epoch: 16/80, Train Loss: 0.7422, Train Acc: 0.9233, Train F1: 0.9403, Val Loss: 1.0694, Val Acc: 0.9370, Val F1: 0.9458\n",
            "Epoch: 17/80, Train Loss: 0.7202, Train Acc: 0.9252, Train F1: 0.9419, Val Loss: 1.1434, Val Acc: 0.9377, Val F1: 0.9472\n",
            "Epoch: 18/80, Train Loss: 0.6673, Train Acc: 0.9284, Train F1: 0.9441, Val Loss: 1.0929, Val Acc: 0.9389, Val F1: 0.9475\n",
            "Epoch: 19/80, Train Loss: 0.6685, Train Acc: 0.9251, Train F1: 0.9415, Val Loss: 1.1272, Val Acc: 0.9272, Val F1: 0.9436\n",
            "Epoch: 20/80, Train Loss: 0.6355, Train Acc: 0.9298, Train F1: 0.9452, Val Loss: 0.9885, Val Acc: 0.9442, Val F1: 0.9526\n",
            "Epoch: 21/80, Train Loss: 0.6316, Train Acc: 0.9316, Train F1: 0.9463, Val Loss: 1.0849, Val Acc: 0.9346, Val F1: 0.9449\n",
            "Epoch: 22/80, Train Loss: 0.5960, Train Acc: 0.9334, Train F1: 0.9474, Val Loss: 0.9345, Val Acc: 0.8829, Val F1: 0.9119\n",
            "Epoch: 23/80, Train Loss: 0.5833, Train Acc: 0.9359, Train F1: 0.9493, Val Loss: 1.0196, Val Acc: 0.9268, Val F1: 0.9393\n",
            "Epoch: 24/80, Train Loss: 0.6254, Train Acc: 0.9323, Train F1: 0.9465, Val Loss: 0.9357, Val Acc: 0.9550, Val F1: 0.9612\n",
            "Epoch: 25/80, Train Loss: 0.5335, Train Acc: 0.9400, Train F1: 0.9523, Val Loss: 0.8986, Val Acc: 0.9386, Val F1: 0.9496\n",
            "Epoch: 26/80, Train Loss: 0.4987, Train Acc: 0.9421, Train F1: 0.9539, Val Loss: 0.9260, Val Acc: 0.9525, Val F1: 0.9584\n",
            "Epoch: 27/80, Train Loss: 0.4822, Train Acc: 0.9457, Train F1: 0.9568, Val Loss: 1.1021, Val Acc: 0.9425, Val F1: 0.9504\n",
            "Epoch: 28/80, Train Loss: 0.4828, Train Acc: 0.9430, Train F1: 0.9545, Val Loss: 0.8903, Val Acc: 0.9401, Val F1: 0.9488\n",
            "Epoch: 29/80, Train Loss: 0.4420, Train Acc: 0.9479, Train F1: 0.9582, Val Loss: 0.9131, Val Acc: 0.9318, Val F1: 0.9443\n",
            "Epoch: 30/80, Train Loss: 0.4539, Train Acc: 0.9490, Train F1: 0.9591, Val Loss: 1.1069, Val Acc: 0.9598, Val F1: 0.9634\n",
            "Epoch: 31/80, Train Loss: 0.4433, Train Acc: 0.9498, Train F1: 0.9599, Val Loss: 0.9075, Val Acc: 0.9486, Val F1: 0.9558\n",
            "Epoch: 32/80, Train Loss: 0.4067, Train Acc: 0.9507, Train F1: 0.9602, Val Loss: 0.8592, Val Acc: 0.9526, Val F1: 0.9592\n",
            "Epoch: 33/80, Train Loss: 0.3781, Train Acc: 0.9548, Train F1: 0.9634, Val Loss: 0.9965, Val Acc: 0.9584, Val F1: 0.9622\n",
            "Epoch: 34/80, Train Loss: 0.3808, Train Acc: 0.9539, Train F1: 0.9627, Val Loss: 0.9387, Val Acc: 0.9623, Val F1: 0.9662\n",
            "Epoch: 35/80, Train Loss: 0.4070, Train Acc: 0.9543, Train F1: 0.9631, Val Loss: 0.9735, Val Acc: 0.9559, Val F1: 0.9611\n",
            "Epoch: 36/80, Train Loss: 0.3565, Train Acc: 0.9557, Train F1: 0.9639, Val Loss: 0.9354, Val Acc: 0.9348, Val F1: 0.9460\n",
            "Epoch: 37/80, Train Loss: 0.3373, Train Acc: 0.9592, Train F1: 0.9668, Val Loss: 0.8721, Val Acc: 0.9409, Val F1: 0.9504\n",
            "Epoch: 38/80, Train Loss: 0.3362, Train Acc: 0.9570, Train F1: 0.9649, Val Loss: 0.9289, Val Acc: 0.9482, Val F1: 0.9556\n",
            "Epoch: 39/80, Train Loss: 0.3239, Train Acc: 0.9610, Train F1: 0.9681, Val Loss: 1.0100, Val Acc: 0.9533, Val F1: 0.9597\n",
            "Epoch: 40/80, Train Loss: 0.3219, Train Acc: 0.9606, Train F1: 0.9680, Val Loss: 0.8858, Val Acc: 0.9417, Val F1: 0.9507\n",
            "Epoch: 41/80, Train Loss: 0.2992, Train Acc: 0.9633, Train F1: 0.9699, Val Loss: 0.9139, Val Acc: 0.9338, Val F1: 0.9470\n",
            "Epoch: 42/80, Train Loss: 0.2719, Train Acc: 0.9653, Train F1: 0.9713, Val Loss: 1.0944, Val Acc: 0.9592, Val F1: 0.9631\n",
            "Epoch: 43/80, Train Loss: 0.2822, Train Acc: 0.9643, Train F1: 0.9705, Val Loss: 1.0810, Val Acc: 0.9625, Val F1: 0.9658\n",
            "Epoch: 44/80, Train Loss: 0.2827, Train Acc: 0.9644, Train F1: 0.9707, Val Loss: 0.9205, Val Acc: 0.9583, Val F1: 0.9636\n",
            "Epoch: 45/80, Train Loss: 0.2595, Train Acc: 0.9682, Train F1: 0.9738, Val Loss: 0.9783, Val Acc: 0.9479, Val F1: 0.9565\n",
            "Epoch: 46/80, Train Loss: 0.2887, Train Acc: 0.9640, Train F1: 0.9706, Val Loss: 0.9703, Val Acc: 0.9509, Val F1: 0.9574\n",
            "Epoch: 47/80, Train Loss: 0.2372, Train Acc: 0.9701, Train F1: 0.9751, Val Loss: 0.9217, Val Acc: 0.9612, Val F1: 0.9661\n",
            "Epoch: 48/80, Train Loss: 0.2282, Train Acc: 0.9719, Train F1: 0.9765, Val Loss: 1.0648, Val Acc: 0.9535, Val F1: 0.9588\n",
            "Epoch: 49/80, Train Loss: 0.2201, Train Acc: 0.9720, Train F1: 0.9767, Val Loss: 1.0207, Val Acc: 0.9636, Val F1: 0.9677\n",
            "Epoch: 50/80, Train Loss: 0.2139, Train Acc: 0.9725, Train F1: 0.9770, Val Loss: 1.1362, Val Acc: 0.9618, Val F1: 0.9656\n",
            "Epoch: 51/80, Train Loss: 0.1971, Train Acc: 0.9741, Train F1: 0.9781, Val Loss: 1.2107, Val Acc: 0.9651, Val F1: 0.9688\n",
            "Epoch: 52/80, Train Loss: 0.2042, Train Acc: 0.9737, Train F1: 0.9781, Val Loss: 1.0144, Val Acc: 0.9624, Val F1: 0.9668\n",
            "Epoch: 53/80, Train Loss: 0.1926, Train Acc: 0.9755, Train F1: 0.9793, Val Loss: 1.0208, Val Acc: 0.9668, Val F1: 0.9697\n",
            "Epoch: 54/80, Train Loss: 0.1779, Train Acc: 0.9770, Train F1: 0.9804, Val Loss: 0.9686, Val Acc: 0.9602, Val F1: 0.9648\n",
            "Epoch: 55/80, Train Loss: 0.1810, Train Acc: 0.9776, Train F1: 0.9809, Val Loss: 0.9160, Val Acc: 0.9433, Val F1: 0.9528\n",
            "Epoch: 56/80, Train Loss: 0.1772, Train Acc: 0.9773, Train F1: 0.9809, Val Loss: 1.0260, Val Acc: 0.9674, Val F1: 0.9703\n",
            "Epoch: 57/80, Train Loss: 0.1716, Train Acc: 0.9777, Train F1: 0.9811, Val Loss: 1.1264, Val Acc: 0.9687, Val F1: 0.9713\n",
            "Epoch: 58/80, Train Loss: 0.1647, Train Acc: 0.9785, Train F1: 0.9818, Val Loss: 1.1527, Val Acc: 0.9672, Val F1: 0.9698\n",
            "Epoch: 59/80, Train Loss: 0.1583, Train Acc: 0.9797, Train F1: 0.9826, Val Loss: 1.1680, Val Acc: 0.9723, Val F1: 0.9744\n",
            "Epoch: 60/80, Train Loss: 0.1583, Train Acc: 0.9795, Train F1: 0.9825, Val Loss: 1.1275, Val Acc: 0.9709, Val F1: 0.9729\n",
            "Epoch: 61/80, Train Loss: 0.1455, Train Acc: 0.9813, Train F1: 0.9839, Val Loss: 1.1293, Val Acc: 0.9661, Val F1: 0.9687\n",
            "Epoch: 62/80, Train Loss: 0.1457, Train Acc: 0.9809, Train F1: 0.9836, Val Loss: 1.1505, Val Acc: 0.9685, Val F1: 0.9711\n",
            "Epoch: 63/80, Train Loss: 0.1415, Train Acc: 0.9819, Train F1: 0.9844, Val Loss: 1.0758, Val Acc: 0.9626, Val F1: 0.9668\n",
            "Epoch: 64/80, Train Loss: 0.1368, Train Acc: 0.9815, Train F1: 0.9842, Val Loss: 1.1663, Val Acc: 0.9703, Val F1: 0.9734\n",
            "Epoch: 65/80, Train Loss: 0.1364, Train Acc: 0.9821, Train F1: 0.9847, Val Loss: 1.1836, Val Acc: 0.9722, Val F1: 0.9739\n",
            "Epoch: 66/80, Train Loss: 0.1328, Train Acc: 0.9825, Train F1: 0.9850, Val Loss: 1.1491, Val Acc: 0.9716, Val F1: 0.9735\n",
            "Epoch: 67/80, Train Loss: 0.1300, Train Acc: 0.9830, Train F1: 0.9854, Val Loss: 1.1498, Val Acc: 0.9699, Val F1: 0.9721\n",
            "Epoch: 68/80, Train Loss: 0.1276, Train Acc: 0.9834, Train F1: 0.9856, Val Loss: 1.1701, Val Acc: 0.9733, Val F1: 0.9749\n",
            "Epoch: 69/80, Train Loss: 0.1260, Train Acc: 0.9835, Train F1: 0.9859, Val Loss: 1.2362, Val Acc: 0.9734, Val F1: 0.9749\n",
            "Epoch: 70/80, Train Loss: 0.1233, Train Acc: 0.9840, Train F1: 0.9862, Val Loss: 1.1944, Val Acc: 0.9741, Val F1: 0.9756\n",
            "Epoch: 71/80, Train Loss: 0.1220, Train Acc: 0.9842, Train F1: 0.9863, Val Loss: 1.2137, Val Acc: 0.9704, Val F1: 0.9724\n",
            "Epoch: 72/80, Train Loss: 0.1207, Train Acc: 0.9839, Train F1: 0.9861, Val Loss: 1.2181, Val Acc: 0.9715, Val F1: 0.9733\n",
            "Epoch: 73/80, Train Loss: 0.1193, Train Acc: 0.9844, Train F1: 0.9865, Val Loss: 1.2217, Val Acc: 0.9726, Val F1: 0.9743\n",
            "Epoch: 74/80, Train Loss: 0.1166, Train Acc: 0.9848, Train F1: 0.9869, Val Loss: 1.2399, Val Acc: 0.9739, Val F1: 0.9754\n",
            "Epoch: 75/80, Train Loss: 0.1164, Train Acc: 0.9850, Train F1: 0.9869, Val Loss: 1.2094, Val Acc: 0.9736, Val F1: 0.9752\n",
            "Epoch: 76/80, Train Loss: 0.1150, Train Acc: 0.9848, Train F1: 0.9869, Val Loss: 1.2505, Val Acc: 0.9738, Val F1: 0.9752\n",
            "Epoch: 77/80, Train Loss: 0.1147, Train Acc: 0.9849, Train F1: 0.9868, Val Loss: 1.2293, Val Acc: 0.9741, Val F1: 0.9755\n",
            "Epoch: 78/80, Train Loss: 0.1142, Train Acc: 0.9851, Train F1: 0.9871, Val Loss: 1.2319, Val Acc: 0.9738, Val F1: 0.9753\n",
            "Epoch: 79/80, Train Loss: 0.1136, Train Acc: 0.9852, Train F1: 0.9871, Val Loss: 1.2269, Val Acc: 0.9738, Val F1: 0.9753\n",
            "Epoch: 80/80, Train Loss: 0.1134, Train Acc: 0.9849, Train F1: 0.9869, Val Loss: 1.2283, Val Acc: 0.9738, Val F1: 0.9753\n",
            "\n",
            " üîé search 4 : deep_rescnn --- lr : 0.0006333475413534536, weight_decay : 0.01, batch_size : 64\n",
            "Epoch: 1/80, Train Loss: 3.5185, Train Acc: 0.6392, Train F1: 0.7086, Val Loss: 2.4165, Val Acc: 0.6873, Val F1: 0.7574\n",
            "Epoch: 2/80, Train Loss: 2.1144, Train Acc: 0.7835, Train F1: 0.8354, Val Loss: 1.9026, Val Acc: 0.8729, Val F1: 0.8957\n",
            "Epoch: 3/80, Train Loss: 1.7943, Train Acc: 0.8261, Train F1: 0.8684, Val Loss: 1.5775, Val Acc: 0.8587, Val F1: 0.8854\n",
            "Epoch: 4/80, Train Loss: 1.4989, Train Acc: 0.8520, Train F1: 0.8898, Val Loss: 2.0332, Val Acc: 0.8095, Val F1: 0.8617\n",
            "Epoch: 5/80, Train Loss: 1.3780, Train Acc: 0.8652, Train F1: 0.8990, Val Loss: 1.4326, Val Acc: 0.8919, Val F1: 0.9123\n",
            "Epoch: 6/80, Train Loss: 1.2942, Train Acc: 0.8718, Train F1: 0.9045, Val Loss: 1.5294, Val Acc: 0.7410, Val F1: 0.8069\n",
            "Epoch: 7/80, Train Loss: 1.2055, Train Acc: 0.8875, Train F1: 0.9163, Val Loss: 1.3009, Val Acc: 0.8724, Val F1: 0.9012\n",
            "Epoch: 8/80, Train Loss: 1.0950, Train Acc: 0.8909, Train F1: 0.9188, Val Loss: 1.2905, Val Acc: 0.8425, Val F1: 0.8836\n",
            "Epoch: 9/80, Train Loss: 1.0520, Train Acc: 0.8959, Train F1: 0.9230, Val Loss: 1.1431, Val Acc: 0.9291, Val F1: 0.9420\n",
            "Epoch: 10/80, Train Loss: 1.0331, Train Acc: 0.8960, Train F1: 0.9225, Val Loss: 1.3316, Val Acc: 0.8422, Val F1: 0.8839\n",
            "Epoch: 11/80, Train Loss: 0.9174, Train Acc: 0.9071, Train F1: 0.9310, Val Loss: 1.1372, Val Acc: 0.9144, Val F1: 0.9319\n",
            "Epoch: 12/80, Train Loss: 0.8651, Train Acc: 0.9151, Train F1: 0.9366, Val Loss: 1.0829, Val Acc: 0.9255, Val F1: 0.9392\n",
            "Epoch: 13/80, Train Loss: 0.8631, Train Acc: 0.9144, Train F1: 0.9360, Val Loss: 1.1985, Val Acc: 0.8543, Val F1: 0.8877\n",
            "Epoch: 14/80, Train Loss: 0.7937, Train Acc: 0.9217, Train F1: 0.9419, Val Loss: 1.1936, Val Acc: 0.9299, Val F1: 0.9436\n",
            "Epoch: 15/80, Train Loss: 0.7414, Train Acc: 0.9264, Train F1: 0.9450, Val Loss: 1.0202, Val Acc: 0.8716, Val F1: 0.9018\n",
            "Epoch: 16/80, Train Loss: 0.7143, Train Acc: 0.9248, Train F1: 0.9439, Val Loss: 1.0452, Val Acc: 0.9203, Val F1: 0.9365\n",
            "Epoch: 17/80, Train Loss: 0.7180, Train Acc: 0.9269, Train F1: 0.9452, Val Loss: 1.0074, Val Acc: 0.9335, Val F1: 0.9470\n",
            "Epoch: 18/80, Train Loss: 0.6370, Train Acc: 0.9337, Train F1: 0.9501, Val Loss: 1.0692, Val Acc: 0.9132, Val F1: 0.9314\n",
            "Epoch: 19/80, Train Loss: 0.6830, Train Acc: 0.9327, Train F1: 0.9494, Val Loss: 0.9956, Val Acc: 0.9381, Val F1: 0.9481\n",
            "Epoch: 20/80, Train Loss: 0.6147, Train Acc: 0.9381, Train F1: 0.9539, Val Loss: 1.0694, Val Acc: 0.9509, Val F1: 0.9566\n",
            "Epoch: 21/80, Train Loss: 0.6070, Train Acc: 0.9396, Train F1: 0.9543, Val Loss: 0.9874, Val Acc: 0.9377, Val F1: 0.9491\n",
            "Epoch: 22/80, Train Loss: 0.5558, Train Acc: 0.9405, Train F1: 0.9552, Val Loss: 1.0525, Val Acc: 0.8801, Val F1: 0.9087\n",
            "Epoch: 23/80, Train Loss: 0.5626, Train Acc: 0.9384, Train F1: 0.9535, Val Loss: 1.0405, Val Acc: 0.9619, Val F1: 0.9656\n",
            "Epoch: 24/80, Train Loss: 0.5514, Train Acc: 0.9431, Train F1: 0.9569, Val Loss: 1.1507, Val Acc: 0.9575, Val F1: 0.9620\n",
            "Epoch: 25/80, Train Loss: 0.5424, Train Acc: 0.9402, Train F1: 0.9552, Val Loss: 0.9724, Val Acc: 0.9354, Val F1: 0.9475\n",
            "Epoch: 26/80, Train Loss: 0.5448, Train Acc: 0.9427, Train F1: 0.9570, Val Loss: 0.9379, Val Acc: 0.9299, Val F1: 0.9439\n",
            "Epoch: 27/80, Train Loss: 0.4784, Train Acc: 0.9452, Train F1: 0.9586, Val Loss: 1.1145, Val Acc: 0.9580, Val F1: 0.9621\n",
            "Epoch: 28/80, Train Loss: 0.4705, Train Acc: 0.9462, Train F1: 0.9594, Val Loss: 1.1361, Val Acc: 0.9600, Val F1: 0.9642\n",
            "Epoch: 29/80, Train Loss: 0.4636, Train Acc: 0.9516, Train F1: 0.9630, Val Loss: 1.0839, Val Acc: 0.9426, Val F1: 0.9530\n",
            "Epoch: 30/80, Train Loss: 0.4619, Train Acc: 0.9464, Train F1: 0.9598, Val Loss: 1.0391, Val Acc: 0.9391, Val F1: 0.9493\n",
            "Epoch: 31/80, Train Loss: 0.4420, Train Acc: 0.9502, Train F1: 0.9623, Val Loss: 1.4977, Val Acc: 0.8696, Val F1: 0.9044\n",
            "Epoch: 32/80, Train Loss: 0.4334, Train Acc: 0.9517, Train F1: 0.9634, Val Loss: 1.2216, Val Acc: 0.9593, Val F1: 0.9638\n",
            "Epoch: 33/80, Train Loss: 0.4120, Train Acc: 0.9550, Train F1: 0.9655, Val Loss: 1.0149, Val Acc: 0.9476, Val F1: 0.9576\n",
            "Epoch: 34/80, Train Loss: 0.3728, Train Acc: 0.9575, Train F1: 0.9676, Val Loss: 1.0413, Val Acc: 0.9630, Val F1: 0.9665\n",
            "Epoch: 35/80, Train Loss: 0.4359, Train Acc: 0.9510, Train F1: 0.9630, Val Loss: 1.0500, Val Acc: 0.9651, Val F1: 0.9686\n",
            "Epoch: 36/80, Train Loss: 0.3901, Train Acc: 0.9588, Train F1: 0.9680, Val Loss: 0.9662, Val Acc: 0.9320, Val F1: 0.9452\n",
            "Epoch: 37/80, Train Loss: 0.3421, Train Acc: 0.9613, Train F1: 0.9701, Val Loss: 1.0450, Val Acc: 0.9314, Val F1: 0.9445\n",
            "Epoch: 38/80, Train Loss: 0.3467, Train Acc: 0.9593, Train F1: 0.9690, Val Loss: 1.0866, Val Acc: 0.9614, Val F1: 0.9651\n",
            "Epoch: 39/80, Train Loss: 0.3413, Train Acc: 0.9610, Train F1: 0.9698, Val Loss: 1.0020, Val Acc: 0.9260, Val F1: 0.9406\n",
            "Epoch: 40/80, Train Loss: 0.3444, Train Acc: 0.9634, Train F1: 0.9717, Val Loss: 1.0895, Val Acc: 0.9553, Val F1: 0.9625\n",
            "Epoch: 41/80, Train Loss: 0.3006, Train Acc: 0.9645, Train F1: 0.9726, Val Loss: 0.9154, Val Acc: 0.9336, Val F1: 0.9456\n",
            "Epoch: 42/80, Train Loss: 0.2960, Train Acc: 0.9656, Train F1: 0.9734, Val Loss: 1.1393, Val Acc: 0.9565, Val F1: 0.9620\n",
            "Epoch: 43/80, Train Loss: 0.2921, Train Acc: 0.9643, Train F1: 0.9727, Val Loss: 1.1326, Val Acc: 0.9692, Val F1: 0.9717\n",
            "Epoch: 44/80, Train Loss: 0.3061, Train Acc: 0.9655, Train F1: 0.9734, Val Loss: 1.1955, Val Acc: 0.9714, Val F1: 0.9732\n",
            "Epoch: 45/80, Train Loss: 0.2802, Train Acc: 0.9668, Train F1: 0.9744, Val Loss: 0.9916, Val Acc: 0.9584, Val F1: 0.9637\n",
            "Epoch: 46/80, Train Loss: 0.2528, Train Acc: 0.9702, Train F1: 0.9768, Val Loss: 0.9713, Val Acc: 0.9565, Val F1: 0.9613\n",
            "Epoch: 47/80, Train Loss: 0.2595, Train Acc: 0.9696, Train F1: 0.9763, Val Loss: 1.0935, Val Acc: 0.9625, Val F1: 0.9682\n",
            "Epoch: 48/80, Train Loss: 0.2651, Train Acc: 0.9674, Train F1: 0.9748, Val Loss: 1.1073, Val Acc: 0.9609, Val F1: 0.9654\n",
            "Epoch: 49/80, Train Loss: 0.2311, Train Acc: 0.9711, Train F1: 0.9776, Val Loss: 1.1926, Val Acc: 0.9640, Val F1: 0.9683\n",
            "Epoch: 50/80, Train Loss: 0.2522, Train Acc: 0.9722, Train F1: 0.9785, Val Loss: 1.1780, Val Acc: 0.9626, Val F1: 0.9665\n",
            "Epoch: 51/80, Train Loss: 0.2084, Train Acc: 0.9748, Train F1: 0.9803, Val Loss: 1.2495, Val Acc: 0.9752, Val F1: 0.9766\n",
            "Epoch: 52/80, Train Loss: 0.2027, Train Acc: 0.9757, Train F1: 0.9809, Val Loss: 1.2575, Val Acc: 0.9782, Val F1: 0.9791\n",
            "Epoch: 53/80, Train Loss: 0.2183, Train Acc: 0.9746, Train F1: 0.9800, Val Loss: 1.1353, Val Acc: 0.9513, Val F1: 0.9613\n",
            "Epoch: 54/80, Train Loss: 0.1847, Train Acc: 0.9779, Train F1: 0.9826, Val Loss: 1.1004, Val Acc: 0.9638, Val F1: 0.9680\n",
            "Epoch: 55/80, Train Loss: 0.1793, Train Acc: 0.9775, Train F1: 0.9823, Val Loss: 1.2331, Val Acc: 0.9694, Val F1: 0.9721\n",
            "Epoch: 56/80, Train Loss: 0.1806, Train Acc: 0.9783, Train F1: 0.9827, Val Loss: 1.1475, Val Acc: 0.9569, Val F1: 0.9633\n",
            "Epoch: 57/80, Train Loss: 0.1862, Train Acc: 0.9779, Train F1: 0.9829, Val Loss: 1.2305, Val Acc: 0.9718, Val F1: 0.9741\n",
            "Epoch: 58/80, Train Loss: 0.1579, Train Acc: 0.9810, Train F1: 0.9850, Val Loss: 1.1938, Val Acc: 0.9679, Val F1: 0.9714\n",
            "Epoch: 59/80, Train Loss: 0.1532, Train Acc: 0.9808, Train F1: 0.9848, Val Loss: 1.2281, Val Acc: 0.9750, Val F1: 0.9764\n",
            "Epoch: 60/80, Train Loss: 0.1560, Train Acc: 0.9811, Train F1: 0.9852, Val Loss: 1.1097, Val Acc: 0.9687, Val F1: 0.9719\n",
            "Epoch: 61/80, Train Loss: 0.1369, Train Acc: 0.9834, Train F1: 0.9869, Val Loss: 1.3981, Val Acc: 0.9769, Val F1: 0.9781\n",
            "Epoch: 62/80, Train Loss: 0.1432, Train Acc: 0.9829, Train F1: 0.9865, Val Loss: 1.2954, Val Acc: 0.9770, Val F1: 0.9782\n",
            "Epoch: 63/80, Train Loss: 0.1309, Train Acc: 0.9841, Train F1: 0.9875, Val Loss: 1.2837, Val Acc: 0.9680, Val F1: 0.9711\n",
            "Epoch: 64/80, Train Loss: 0.1294, Train Acc: 0.9846, Train F1: 0.9878, Val Loss: 1.3243, Val Acc: 0.9755, Val F1: 0.9769\n",
            "Epoch: 65/80, Train Loss: 0.1225, Train Acc: 0.9860, Train F1: 0.9889, Val Loss: 1.3142, Val Acc: 0.9773, Val F1: 0.9783\n",
            "Epoch: 66/80, Train Loss: 0.1229, Train Acc: 0.9858, Train F1: 0.9887, Val Loss: 1.2606, Val Acc: 0.9755, Val F1: 0.9770\n",
            "Epoch: 67/80, Train Loss: 0.1183, Train Acc: 0.9863, Train F1: 0.9891, Val Loss: 1.2479, Val Acc: 0.9690, Val F1: 0.9723\n",
            "Epoch: 68/80, Train Loss: 0.1127, Train Acc: 0.9865, Train F1: 0.9892, Val Loss: 1.3095, Val Acc: 0.9755, Val F1: 0.9771\n",
            "Epoch: 69/80, Train Loss: 0.1099, Train Acc: 0.9872, Train F1: 0.9897, Val Loss: 1.3203, Val Acc: 0.9788, Val F1: 0.9798\n",
            "Epoch: 70/80, Train Loss: 0.1088, Train Acc: 0.9873, Train F1: 0.9899, Val Loss: 1.3075, Val Acc: 0.9746, Val F1: 0.9763\n",
            "Epoch: 71/80, Train Loss: 0.1045, Train Acc: 0.9876, Train F1: 0.9900, Val Loss: 1.4205, Val Acc: 0.9802, Val F1: 0.9809\n",
            "Epoch: 72/80, Train Loss: 0.1034, Train Acc: 0.9880, Train F1: 0.9904, Val Loss: 1.3047, Val Acc: 0.9773, Val F1: 0.9786\n",
            "Epoch: 73/80, Train Loss: 0.1016, Train Acc: 0.9882, Train F1: 0.9904, Val Loss: 1.3269, Val Acc: 0.9779, Val F1: 0.9790\n",
            "Epoch: 74/80, Train Loss: 0.0989, Train Acc: 0.9885, Train F1: 0.9906, Val Loss: 1.3504, Val Acc: 0.9785, Val F1: 0.9796\n",
            "Epoch: 75/80, Train Loss: 0.0978, Train Acc: 0.9888, Train F1: 0.9910, Val Loss: 1.3571, Val Acc: 0.9782, Val F1: 0.9793\n",
            "Epoch: 76/80, Train Loss: 0.0964, Train Acc: 0.9890, Train F1: 0.9911, Val Loss: 1.4049, Val Acc: 0.9789, Val F1: 0.9798\n",
            "Epoch: 77/80, Train Loss: 0.0955, Train Acc: 0.9890, Train F1: 0.9911, Val Loss: 1.3895, Val Acc: 0.9786, Val F1: 0.9796\n",
            "Epoch: 78/80, Train Loss: 0.0946, Train Acc: 0.9889, Train F1: 0.9911, Val Loss: 1.4008, Val Acc: 0.9791, Val F1: 0.9800\n",
            "Epoch: 79/80, Train Loss: 0.0941, Train Acc: 0.9893, Train F1: 0.9914, Val Loss: 1.3918, Val Acc: 0.9789, Val F1: 0.9798\n",
            "Epoch: 80/80, Train Loss: 0.0936, Train Acc: 0.9891, Train F1: 0.9912, Val Loss: 1.3921, Val Acc: 0.9788, Val F1: 0.9797\n",
            "\n",
            " üîé search 5 : deep_rescnn --- lr : 0.0006333475413534536, weight_decay : 0.01, batch_size : 128\n",
            "Epoch: 1/80, Train Loss: 3.3426, Train Acc: 0.6688, Train F1: 0.7355, Val Loss: 2.1789, Val Acc: 0.8296, Val F1: 0.8634\n",
            "Epoch: 2/80, Train Loss: 1.9709, Train Acc: 0.8156, Train F1: 0.8593, Val Loss: 1.8147, Val Acc: 0.7927, Val F1: 0.8413\n",
            "Epoch: 3/80, Train Loss: 1.7448, Train Acc: 0.8405, Train F1: 0.8783, Val Loss: 1.7439, Val Acc: 0.7893, Val F1: 0.8281\n",
            "Epoch: 4/80, Train Loss: 1.5373, Train Acc: 0.8577, Train F1: 0.8915, Val Loss: 1.5360, Val Acc: 0.8404, Val F1: 0.8806\n",
            "Epoch: 5/80, Train Loss: 1.4028, Train Acc: 0.8655, Train F1: 0.8978, Val Loss: 1.4814, Val Acc: 0.7883, Val F1: 0.8475\n",
            "Epoch: 6/80, Train Loss: 1.2769, Train Acc: 0.8789, Train F1: 0.9074, Val Loss: 1.5896, Val Acc: 0.8055, Val F1: 0.8552\n",
            "Epoch: 7/80, Train Loss: 1.2474, Train Acc: 0.8787, Train F1: 0.9077, Val Loss: 1.3099, Val Acc: 0.8418, Val F1: 0.8846\n",
            "Epoch: 8/80, Train Loss: 1.0686, Train Acc: 0.8924, Train F1: 0.9172, Val Loss: 1.6700, Val Acc: 0.7680, Val F1: 0.8213\n",
            "Epoch: 9/80, Train Loss: 1.5087, Train Acc: 0.8417, Train F1: 0.8772, Val Loss: 1.3349, Val Acc: 0.9185, Val F1: 0.9336\n",
            "Epoch: 10/80, Train Loss: 1.0114, Train Acc: 0.8971, Train F1: 0.9213, Val Loss: 1.2725, Val Acc: 0.8929, Val F1: 0.9186\n",
            "Epoch: 11/80, Train Loss: 0.9277, Train Acc: 0.9038, Train F1: 0.9256, Val Loss: 1.3071, Val Acc: 0.8592, Val F1: 0.8926\n",
            "Epoch: 12/80, Train Loss: 0.8973, Train Acc: 0.9069, Train F1: 0.9284, Val Loss: 1.2397, Val Acc: 0.9397, Val F1: 0.9480\n",
            "Epoch: 13/80, Train Loss: 0.8843, Train Acc: 0.9106, Train F1: 0.9312, Val Loss: 1.1573, Val Acc: 0.8765, Val F1: 0.9041\n",
            "Epoch: 14/80, Train Loss: 0.7922, Train Acc: 0.9176, Train F1: 0.9358, Val Loss: 1.0392, Val Acc: 0.9188, Val F1: 0.9345\n",
            "Epoch: 15/80, Train Loss: 0.7825, Train Acc: 0.9166, Train F1: 0.9357, Val Loss: 1.1771, Val Acc: 0.9226, Val F1: 0.9353\n",
            "Epoch: 16/80, Train Loss: 0.7339, Train Acc: 0.9243, Train F1: 0.9411, Val Loss: 1.0437, Val Acc: 0.9138, Val F1: 0.9299\n",
            "Epoch: 17/80, Train Loss: 0.7138, Train Acc: 0.9230, Train F1: 0.9402, Val Loss: 1.1230, Val Acc: 0.9296, Val F1: 0.9396\n",
            "Epoch: 18/80, Train Loss: 0.6927, Train Acc: 0.9255, Train F1: 0.9418, Val Loss: 1.4613, Val Acc: 0.9392, Val F1: 0.9493\n",
            "Epoch: 19/80, Train Loss: 0.6973, Train Acc: 0.9270, Train F1: 0.9434, Val Loss: 1.0774, Val Acc: 0.9355, Val F1: 0.9478\n",
            "Epoch: 20/80, Train Loss: 0.6143, Train Acc: 0.9329, Train F1: 0.9476, Val Loss: 1.1977, Val Acc: 0.9168, Val F1: 0.9348\n",
            "Epoch: 21/80, Train Loss: 0.6092, Train Acc: 0.9337, Train F1: 0.9481, Val Loss: 1.0964, Val Acc: 0.8753, Val F1: 0.9044\n",
            "Epoch: 22/80, Train Loss: 0.5583, Train Acc: 0.9384, Train F1: 0.9514, Val Loss: 1.0184, Val Acc: 0.9428, Val F1: 0.9514\n",
            "Epoch: 23/80, Train Loss: 0.5523, Train Acc: 0.9410, Train F1: 0.9535, Val Loss: 1.1090, Val Acc: 0.9497, Val F1: 0.9574\n",
            "Epoch: 24/80, Train Loss: 0.5743, Train Acc: 0.9393, Train F1: 0.9524, Val Loss: 1.3929, Val Acc: 0.8227, Val F1: 0.8698\n",
            "Epoch: 25/80, Train Loss: 0.5410, Train Acc: 0.9408, Train F1: 0.9534, Val Loss: 1.1067, Val Acc: 0.9596, Val F1: 0.9634\n",
            "Epoch: 26/80, Train Loss: 0.5236, Train Acc: 0.9406, Train F1: 0.9532, Val Loss: 1.0613, Val Acc: 0.8983, Val F1: 0.9204\n",
            "Epoch: 27/80, Train Loss: 0.5155, Train Acc: 0.9403, Train F1: 0.9531, Val Loss: 1.1524, Val Acc: 0.9023, Val F1: 0.9222\n",
            "Epoch: 28/80, Train Loss: 0.4894, Train Acc: 0.9439, Train F1: 0.9554, Val Loss: 1.0899, Val Acc: 0.9177, Val F1: 0.9328\n",
            "Epoch: 29/80, Train Loss: 0.5113, Train Acc: 0.9436, Train F1: 0.9555, Val Loss: 0.9818, Val Acc: 0.9342, Val F1: 0.9466\n",
            "Epoch: 30/80, Train Loss: 0.5005, Train Acc: 0.9443, Train F1: 0.9559, Val Loss: 0.9454, Val Acc: 0.9224, Val F1: 0.9392\n",
            "Epoch: 31/80, Train Loss: 0.4136, Train Acc: 0.9518, Train F1: 0.9614, Val Loss: 0.9346, Val Acc: 0.9456, Val F1: 0.9536\n",
            "Epoch: 32/80, Train Loss: 0.4026, Train Acc: 0.9503, Train F1: 0.9607, Val Loss: 0.9693, Val Acc: 0.9398, Val F1: 0.9490\n",
            "Epoch: 33/80, Train Loss: 0.4017, Train Acc: 0.9525, Train F1: 0.9621, Val Loss: 1.0262, Val Acc: 0.9659, Val F1: 0.9694\n",
            "Epoch: 34/80, Train Loss: 0.3933, Train Acc: 0.9546, Train F1: 0.9640, Val Loss: 1.0360, Val Acc: 0.9462, Val F1: 0.9531\n",
            "Epoch: 35/80, Train Loss: 0.3656, Train Acc: 0.9567, Train F1: 0.9649, Val Loss: 1.2472, Val Acc: 0.9524, Val F1: 0.9610\n",
            "Epoch: 36/80, Train Loss: 0.3892, Train Acc: 0.9544, Train F1: 0.9634, Val Loss: 0.9681, Val Acc: 0.9464, Val F1: 0.9542\n",
            "Epoch: 37/80, Train Loss: 0.3751, Train Acc: 0.9548, Train F1: 0.9640, Val Loss: 1.1033, Val Acc: 0.9054, Val F1: 0.9265\n",
            "Epoch: 38/80, Train Loss: 0.3489, Train Acc: 0.9582, Train F1: 0.9665, Val Loss: 0.9538, Val Acc: 0.9632, Val F1: 0.9673\n",
            "Epoch: 39/80, Train Loss: 0.3705, Train Acc: 0.9573, Train F1: 0.9658, Val Loss: 1.0620, Val Acc: 0.9432, Val F1: 0.9529\n",
            "Epoch: 40/80, Train Loss: 0.3229, Train Acc: 0.9592, Train F1: 0.9670, Val Loss: 1.0172, Val Acc: 0.9643, Val F1: 0.9682\n",
            "Epoch: 41/80, Train Loss: 0.3151, Train Acc: 0.9622, Train F1: 0.9697, Val Loss: 1.0074, Val Acc: 0.9420, Val F1: 0.9536\n",
            "Epoch: 42/80, Train Loss: 0.2840, Train Acc: 0.9640, Train F1: 0.9708, Val Loss: 0.9933, Val Acc: 0.9544, Val F1: 0.9596\n",
            "Epoch: 43/80, Train Loss: 0.3125, Train Acc: 0.9638, Train F1: 0.9704, Val Loss: 1.0199, Val Acc: 0.9537, Val F1: 0.9633\n",
            "Epoch: 44/80, Train Loss: 0.2581, Train Acc: 0.9683, Train F1: 0.9740, Val Loss: 1.0169, Val Acc: 0.9611, Val F1: 0.9647\n",
            "Epoch: 45/80, Train Loss: 0.2660, Train Acc: 0.9666, Train F1: 0.9729, Val Loss: 1.0379, Val Acc: 0.9577, Val F1: 0.9632\n",
            "Epoch: 46/80, Train Loss: 0.2680, Train Acc: 0.9665, Train F1: 0.9726, Val Loss: 0.9532, Val Acc: 0.9589, Val F1: 0.9644\n",
            "Epoch: 47/80, Train Loss: 0.2236, Train Acc: 0.9721, Train F1: 0.9769, Val Loss: 1.0234, Val Acc: 0.9710, Val F1: 0.9731\n",
            "Epoch: 48/80, Train Loss: 0.2296, Train Acc: 0.9714, Train F1: 0.9763, Val Loss: 1.0009, Val Acc: 0.9662, Val F1: 0.9691\n",
            "Epoch: 49/80, Train Loss: 0.2271, Train Acc: 0.9715, Train F1: 0.9766, Val Loss: 1.1438, Val Acc: 0.9572, Val F1: 0.9622\n",
            "Epoch: 50/80, Train Loss: 0.2149, Train Acc: 0.9717, Train F1: 0.9766, Val Loss: 1.1397, Val Acc: 0.9717, Val F1: 0.9747\n",
            "Epoch: 51/80, Train Loss: 0.2280, Train Acc: 0.9721, Train F1: 0.9770, Val Loss: 0.9540, Val Acc: 0.9666, Val F1: 0.9705\n",
            "Epoch: 52/80, Train Loss: 0.1985, Train Acc: 0.9755, Train F1: 0.9795, Val Loss: 1.0270, Val Acc: 0.9712, Val F1: 0.9736\n",
            "Epoch: 53/80, Train Loss: 0.1901, Train Acc: 0.9771, Train F1: 0.9806, Val Loss: 1.0032, Val Acc: 0.9559, Val F1: 0.9611\n",
            "Epoch: 54/80, Train Loss: 0.1922, Train Acc: 0.9774, Train F1: 0.9810, Val Loss: 0.9557, Val Acc: 0.9680, Val F1: 0.9710\n",
            "Epoch: 55/80, Train Loss: 0.1849, Train Acc: 0.9758, Train F1: 0.9801, Val Loss: 1.2038, Val Acc: 0.9763, Val F1: 0.9777\n",
            "Epoch: 56/80, Train Loss: 0.1769, Train Acc: 0.9787, Train F1: 0.9822, Val Loss: 1.0563, Val Acc: 0.9636, Val F1: 0.9688\n",
            "Epoch: 57/80, Train Loss: 0.1706, Train Acc: 0.9789, Train F1: 0.9823, Val Loss: 0.9852, Val Acc: 0.9750, Val F1: 0.9768\n",
            "Epoch: 58/80, Train Loss: 0.1585, Train Acc: 0.9807, Train F1: 0.9837, Val Loss: 1.1509, Val Acc: 0.9733, Val F1: 0.9749\n",
            "Epoch: 59/80, Train Loss: 0.1580, Train Acc: 0.9800, Train F1: 0.9833, Val Loss: 1.0942, Val Acc: 0.9662, Val F1: 0.9693\n",
            "Epoch: 60/80, Train Loss: 0.1458, Train Acc: 0.9821, Train F1: 0.9848, Val Loss: 1.0951, Val Acc: 0.9721, Val F1: 0.9740\n",
            "Epoch: 61/80, Train Loss: 0.1568, Train Acc: 0.9816, Train F1: 0.9845, Val Loss: 1.1067, Val Acc: 0.9792, Val F1: 0.9801\n",
            "Epoch: 62/80, Train Loss: 0.1379, Train Acc: 0.9832, Train F1: 0.9857, Val Loss: 1.0409, Val Acc: 0.9706, Val F1: 0.9730\n",
            "Epoch: 63/80, Train Loss: 0.1268, Train Acc: 0.9847, Train F1: 0.9868, Val Loss: 1.1419, Val Acc: 0.9750, Val F1: 0.9765\n",
            "Epoch: 64/80, Train Loss: 0.1281, Train Acc: 0.9847, Train F1: 0.9868, Val Loss: 1.1025, Val Acc: 0.9752, Val F1: 0.9768\n",
            "Epoch: 65/80, Train Loss: 0.1253, Train Acc: 0.9854, Train F1: 0.9874, Val Loss: 1.1709, Val Acc: 0.9772, Val F1: 0.9783\n",
            "Epoch: 66/80, Train Loss: 0.1241, Train Acc: 0.9848, Train F1: 0.9870, Val Loss: 1.0863, Val Acc: 0.9754, Val F1: 0.9770\n",
            "Epoch: 67/80, Train Loss: 0.1178, Train Acc: 0.9858, Train F1: 0.9878, Val Loss: 1.1707, Val Acc: 0.9783, Val F1: 0.9793\n",
            "Epoch: 68/80, Train Loss: 0.1163, Train Acc: 0.9864, Train F1: 0.9883, Val Loss: 1.1971, Val Acc: 0.9785, Val F1: 0.9795\n",
            "Epoch: 69/80, Train Loss: 0.1148, Train Acc: 0.9860, Train F1: 0.9880, Val Loss: 1.2107, Val Acc: 0.9786, Val F1: 0.9796\n",
            "Epoch: 70/80, Train Loss: 0.1101, Train Acc: 0.9869, Train F1: 0.9887, Val Loss: 1.2308, Val Acc: 0.9774, Val F1: 0.9785\n",
            "Epoch: 71/80, Train Loss: 0.1088, Train Acc: 0.9873, Train F1: 0.9890, Val Loss: 1.1721, Val Acc: 0.9785, Val F1: 0.9796\n",
            "Epoch: 72/80, Train Loss: 0.1052, Train Acc: 0.9875, Train F1: 0.9892, Val Loss: 1.1473, Val Acc: 0.9769, Val F1: 0.9783\n",
            "Epoch: 73/80, Train Loss: 0.1035, Train Acc: 0.9877, Train F1: 0.9893, Val Loss: 1.1956, Val Acc: 0.9765, Val F1: 0.9778\n",
            "Epoch: 74/80, Train Loss: 0.1023, Train Acc: 0.9876, Train F1: 0.9893, Val Loss: 1.1947, Val Acc: 0.9769, Val F1: 0.9781\n",
            "Epoch: 75/80, Train Loss: 0.1012, Train Acc: 0.9878, Train F1: 0.9894, Val Loss: 1.2002, Val Acc: 0.9775, Val F1: 0.9787\n",
            "Epoch: 76/80, Train Loss: 0.1002, Train Acc: 0.9880, Train F1: 0.9895, Val Loss: 1.2203, Val Acc: 0.9780, Val F1: 0.9790\n",
            "Epoch: 77/80, Train Loss: 0.0997, Train Acc: 0.9881, Train F1: 0.9897, Val Loss: 1.2104, Val Acc: 0.9778, Val F1: 0.9789\n",
            "Epoch: 78/80, Train Loss: 0.0986, Train Acc: 0.9881, Train F1: 0.9897, Val Loss: 1.2154, Val Acc: 0.9783, Val F1: 0.9793\n",
            "Epoch: 79/80, Train Loss: 0.0982, Train Acc: 0.9883, Train F1: 0.9899, Val Loss: 1.2157, Val Acc: 0.9779, Val F1: 0.9790\n",
            "Epoch: 80/80, Train Loss: 0.0979, Train Acc: 0.9883, Train F1: 0.9898, Val Loss: 1.2166, Val Acc: 0.9779, Val F1: 0.9790\n",
            "\n",
            " üîé search 6 : deep_rescnn --- lr : 0.0003070049962923372, weight_decay : 0.01, batch_size : 64\n",
            "Epoch: 1/80, Train Loss: 3.0320, Train Acc: 0.6879, Train F1: 0.7532, Val Loss: 2.0656, Val Acc: 0.8386, Val F1: 0.8709\n",
            "Epoch: 2/80, Train Loss: 1.9024, Train Acc: 0.8152, Train F1: 0.8621, Val Loss: 1.6476, Val Acc: 0.8075, Val F1: 0.8538\n",
            "Epoch: 3/80, Train Loss: 1.6019, Train Acc: 0.8440, Train F1: 0.8833, Val Loss: 2.9665, Val Acc: 0.5921, Val F1: 0.6676\n",
            "Epoch: 4/80, Train Loss: 1.5183, Train Acc: 0.8485, Train F1: 0.8861, Val Loss: 1.4771, Val Acc: 0.8910, Val F1: 0.9106\n",
            "Epoch: 5/80, Train Loss: 1.2949, Train Acc: 0.8754, Train F1: 0.9075, Val Loss: 1.3538, Val Acc: 0.8852, Val F1: 0.9110\n",
            "Epoch: 6/80, Train Loss: 1.1804, Train Acc: 0.8860, Train F1: 0.9153, Val Loss: 1.3146, Val Acc: 0.9203, Val F1: 0.9354\n",
            "Epoch: 7/80, Train Loss: 1.0830, Train Acc: 0.8931, Train F1: 0.9203, Val Loss: 1.6087, Val Acc: 0.8285, Val F1: 0.8582\n",
            "Epoch: 8/80, Train Loss: 0.9903, Train Acc: 0.8996, Train F1: 0.9252, Val Loss: 1.2503, Val Acc: 0.8886, Val F1: 0.9119\n",
            "Epoch: 9/80, Train Loss: 0.9396, Train Acc: 0.9045, Train F1: 0.9290, Val Loss: 1.4211, Val Acc: 0.8572, Val F1: 0.8839\n",
            "Epoch: 10/80, Train Loss: 0.9363, Train Acc: 0.9063, Train F1: 0.9301, Val Loss: 1.0817, Val Acc: 0.9088, Val F1: 0.9238\n",
            "Epoch: 11/80, Train Loss: 0.8442, Train Acc: 0.9136, Train F1: 0.9354, Val Loss: 1.0524, Val Acc: 0.9375, Val F1: 0.9492\n",
            "Epoch: 12/80, Train Loss: 0.7814, Train Acc: 0.9166, Train F1: 0.9378, Val Loss: 1.1256, Val Acc: 0.8589, Val F1: 0.8947\n",
            "Epoch: 13/80, Train Loss: 0.7371, Train Acc: 0.9239, Train F1: 0.9433, Val Loss: 1.0306, Val Acc: 0.9190, Val F1: 0.9323\n",
            "Epoch: 14/80, Train Loss: 0.7215, Train Acc: 0.9240, Train F1: 0.9430, Val Loss: 1.1890, Val Acc: 0.9461, Val F1: 0.9546\n",
            "Epoch: 15/80, Train Loss: 0.6894, Train Acc: 0.9260, Train F1: 0.9445, Val Loss: 0.9820, Val Acc: 0.8978, Val F1: 0.9221\n",
            "Epoch: 16/80, Train Loss: 0.6769, Train Acc: 0.9283, Train F1: 0.9461, Val Loss: 1.0797, Val Acc: 0.9471, Val F1: 0.9551\n",
            "Epoch: 17/80, Train Loss: 0.6179, Train Acc: 0.9302, Train F1: 0.9480, Val Loss: 1.0178, Val Acc: 0.9101, Val F1: 0.9291\n",
            "Epoch: 18/80, Train Loss: 0.6003, Train Acc: 0.9352, Train F1: 0.9510, Val Loss: 1.2478, Val Acc: 0.9125, Val F1: 0.9291\n",
            "Epoch: 19/80, Train Loss: 0.5947, Train Acc: 0.9373, Train F1: 0.9526, Val Loss: 0.9664, Val Acc: 0.9359, Val F1: 0.9468\n",
            "Epoch: 20/80, Train Loss: 0.5174, Train Acc: 0.9400, Train F1: 0.9549, Val Loss: 0.9915, Val Acc: 0.9144, Val F1: 0.9336\n",
            "Epoch: 21/80, Train Loss: 0.5648, Train Acc: 0.9387, Train F1: 0.9536, Val Loss: 1.0115, Val Acc: 0.9012, Val F1: 0.9226\n",
            "Epoch: 22/80, Train Loss: 0.5126, Train Acc: 0.9443, Train F1: 0.9577, Val Loss: 1.0994, Val Acc: 0.9542, Val F1: 0.9591\n",
            "Epoch: 23/80, Train Loss: 0.4855, Train Acc: 0.9430, Train F1: 0.9567, Val Loss: 0.9234, Val Acc: 0.9497, Val F1: 0.9569\n",
            "Epoch: 24/80, Train Loss: 0.4833, Train Acc: 0.9434, Train F1: 0.9571, Val Loss: 0.9741, Val Acc: 0.9476, Val F1: 0.9552\n",
            "Epoch: 25/80, Train Loss: 0.4486, Train Acc: 0.9478, Train F1: 0.9600, Val Loss: 0.9796, Val Acc: 0.9529, Val F1: 0.9601\n",
            "Epoch: 26/80, Train Loss: 0.4627, Train Acc: 0.9472, Train F1: 0.9599, Val Loss: 1.3549, Val Acc: 0.9411, Val F1: 0.9533\n",
            "Epoch: 27/80, Train Loss: 0.4446, Train Acc: 0.9475, Train F1: 0.9602, Val Loss: 0.9457, Val Acc: 0.9352, Val F1: 0.9467\n",
            "Epoch: 28/80, Train Loss: 0.4386, Train Acc: 0.9488, Train F1: 0.9611, Val Loss: 0.9218, Val Acc: 0.9256, Val F1: 0.9399\n",
            "Epoch: 29/80, Train Loss: 0.3974, Train Acc: 0.9527, Train F1: 0.9639, Val Loss: 1.0507, Val Acc: 0.9577, Val F1: 0.9630\n",
            "Epoch: 30/80, Train Loss: 0.3852, Train Acc: 0.9528, Train F1: 0.9639, Val Loss: 0.9458, Val Acc: 0.9483, Val F1: 0.9578\n",
            "Epoch: 31/80, Train Loss: 0.3817, Train Acc: 0.9532, Train F1: 0.9646, Val Loss: 1.0290, Val Acc: 0.9427, Val F1: 0.9521\n",
            "Epoch: 32/80, Train Loss: 0.3579, Train Acc: 0.9570, Train F1: 0.9671, Val Loss: 1.1740, Val Acc: 0.9692, Val F1: 0.9720\n",
            "Epoch: 33/80, Train Loss: 0.3246, Train Acc: 0.9591, Train F1: 0.9685, Val Loss: 0.9582, Val Acc: 0.9533, Val F1: 0.9591\n",
            "Epoch: 34/80, Train Loss: 0.3461, Train Acc: 0.9591, Train F1: 0.9686, Val Loss: 1.0806, Val Acc: 0.9482, Val F1: 0.9545\n",
            "Epoch: 35/80, Train Loss: 0.3496, Train Acc: 0.9599, Train F1: 0.9691, Val Loss: 1.0588, Val Acc: 0.9388, Val F1: 0.9506\n",
            "Epoch: 36/80, Train Loss: 0.3113, Train Acc: 0.9605, Train F1: 0.9696, Val Loss: 0.9602, Val Acc: 0.9656, Val F1: 0.9694\n",
            "Epoch: 37/80, Train Loss: 0.3232, Train Acc: 0.9613, Train F1: 0.9704, Val Loss: 0.9451, Val Acc: 0.9582, Val F1: 0.9637\n",
            "Epoch: 38/80, Train Loss: 0.2787, Train Acc: 0.9652, Train F1: 0.9729, Val Loss: 0.9760, Val Acc: 0.9408, Val F1: 0.9519\n",
            "Epoch: 39/80, Train Loss: 0.2982, Train Acc: 0.9631, Train F1: 0.9718, Val Loss: 1.0255, Val Acc: 0.9553, Val F1: 0.9640\n",
            "Epoch: 40/80, Train Loss: 0.2787, Train Acc: 0.9662, Train F1: 0.9739, Val Loss: 0.9945, Val Acc: 0.9538, Val F1: 0.9601\n",
            "Epoch: 41/80, Train Loss: 0.2615, Train Acc: 0.9664, Train F1: 0.9742, Val Loss: 0.9846, Val Acc: 0.9715, Val F1: 0.9741\n",
            "Epoch: 42/80, Train Loss: 0.2561, Train Acc: 0.9679, Train F1: 0.9750, Val Loss: 1.2912, Val Acc: 0.9677, Val F1: 0.9695\n",
            "Epoch: 43/80, Train Loss: 0.2541, Train Acc: 0.9690, Train F1: 0.9759, Val Loss: 1.0551, Val Acc: 0.9619, Val F1: 0.9661\n",
            "Epoch: 44/80, Train Loss: 0.2444, Train Acc: 0.9703, Train F1: 0.9768, Val Loss: 0.9491, Val Acc: 0.9547, Val F1: 0.9613\n",
            "Epoch: 45/80, Train Loss: 0.2339, Train Acc: 0.9709, Train F1: 0.9772, Val Loss: 0.9213, Val Acc: 0.9585, Val F1: 0.9641\n",
            "Epoch: 46/80, Train Loss: 0.2268, Train Acc: 0.9723, Train F1: 0.9784, Val Loss: 1.1268, Val Acc: 0.9689, Val F1: 0.9720\n",
            "Epoch: 47/80, Train Loss: 0.2239, Train Acc: 0.9716, Train F1: 0.9779, Val Loss: 1.1416, Val Acc: 0.9689, Val F1: 0.9717\n",
            "Epoch: 48/80, Train Loss: 0.2154, Train Acc: 0.9726, Train F1: 0.9787, Val Loss: 1.1255, Val Acc: 0.9591, Val F1: 0.9641\n",
            "Epoch: 49/80, Train Loss: 0.1873, Train Acc: 0.9761, Train F1: 0.9812, Val Loss: 1.1587, Val Acc: 0.9700, Val F1: 0.9723\n",
            "Epoch: 50/80, Train Loss: 0.2064, Train Acc: 0.9742, Train F1: 0.9801, Val Loss: 1.1579, Val Acc: 0.9709, Val F1: 0.9737\n",
            "Epoch: 51/80, Train Loss: 0.1828, Train Acc: 0.9767, Train F1: 0.9817, Val Loss: 1.0954, Val Acc: 0.9689, Val F1: 0.9718\n",
            "Epoch: 52/80, Train Loss: 0.1816, Train Acc: 0.9782, Train F1: 0.9828, Val Loss: 1.1319, Val Acc: 0.9508, Val F1: 0.9582\n",
            "Epoch: 53/80, Train Loss: 0.1731, Train Acc: 0.9782, Train F1: 0.9831, Val Loss: 1.1527, Val Acc: 0.9706, Val F1: 0.9731\n",
            "Epoch: 54/80, Train Loss: 0.1634, Train Acc: 0.9794, Train F1: 0.9838, Val Loss: 1.0400, Val Acc: 0.9711, Val F1: 0.9735\n",
            "Epoch: 55/80, Train Loss: 0.1614, Train Acc: 0.9790, Train F1: 0.9834, Val Loss: 1.1269, Val Acc: 0.9699, Val F1: 0.9739\n",
            "Epoch: 56/80, Train Loss: 0.1525, Train Acc: 0.9801, Train F1: 0.9842, Val Loss: 1.1821, Val Acc: 0.9622, Val F1: 0.9665\n",
            "Epoch: 57/80, Train Loss: 0.1565, Train Acc: 0.9798, Train F1: 0.9841, Val Loss: 1.1413, Val Acc: 0.9617, Val F1: 0.9663\n",
            "Epoch: 58/80, Train Loss: 0.1485, Train Acc: 0.9810, Train F1: 0.9850, Val Loss: 1.2483, Val Acc: 0.9746, Val F1: 0.9764\n",
            "Epoch: 59/80, Train Loss: 0.1397, Train Acc: 0.9822, Train F1: 0.9860, Val Loss: 1.2377, Val Acc: 0.9766, Val F1: 0.9779\n",
            "Epoch: 60/80, Train Loss: 0.1357, Train Acc: 0.9826, Train F1: 0.9862, Val Loss: 1.2381, Val Acc: 0.9743, Val F1: 0.9761\n",
            "Epoch: 61/80, Train Loss: 0.1335, Train Acc: 0.9830, Train F1: 0.9866, Val Loss: 1.1646, Val Acc: 0.9611, Val F1: 0.9653\n",
            "Epoch: 62/80, Train Loss: 0.1272, Train Acc: 0.9832, Train F1: 0.9867, Val Loss: 1.2503, Val Acc: 0.9755, Val F1: 0.9770\n",
            "Epoch: 63/80, Train Loss: 0.1220, Train Acc: 0.9844, Train F1: 0.9877, Val Loss: 1.1691, Val Acc: 0.9767, Val F1: 0.9780\n",
            "Epoch: 64/80, Train Loss: 0.1199, Train Acc: 0.9847, Train F1: 0.9877, Val Loss: 1.2653, Val Acc: 0.9730, Val F1: 0.9748\n",
            "Epoch: 65/80, Train Loss: 0.1182, Train Acc: 0.9848, Train F1: 0.9878, Val Loss: 1.3184, Val Acc: 0.9783, Val F1: 0.9793\n",
            "Epoch: 66/80, Train Loss: 0.1162, Train Acc: 0.9853, Train F1: 0.9882, Val Loss: 1.2532, Val Acc: 0.9761, Val F1: 0.9775\n",
            "Epoch: 67/80, Train Loss: 0.1104, Train Acc: 0.9861, Train F1: 0.9888, Val Loss: 1.2154, Val Acc: 0.9749, Val F1: 0.9766\n",
            "Epoch: 68/80, Train Loss: 0.1086, Train Acc: 0.9859, Train F1: 0.9887, Val Loss: 1.3134, Val Acc: 0.9791, Val F1: 0.9802\n",
            "Epoch: 69/80, Train Loss: 0.1081, Train Acc: 0.9861, Train F1: 0.9888, Val Loss: 1.2698, Val Acc: 0.9780, Val F1: 0.9790\n",
            "Epoch: 70/80, Train Loss: 0.1042, Train Acc: 0.9863, Train F1: 0.9890, Val Loss: 1.3053, Val Acc: 0.9782, Val F1: 0.9792\n",
            "Epoch: 71/80, Train Loss: 0.1027, Train Acc: 0.9864, Train F1: 0.9890, Val Loss: 1.2613, Val Acc: 0.9768, Val F1: 0.9782\n",
            "Epoch: 72/80, Train Loss: 0.1016, Train Acc: 0.9866, Train F1: 0.9893, Val Loss: 1.2590, Val Acc: 0.9775, Val F1: 0.9787\n",
            "Epoch: 73/80, Train Loss: 0.0997, Train Acc: 0.9869, Train F1: 0.9895, Val Loss: 1.2843, Val Acc: 0.9779, Val F1: 0.9790\n",
            "Epoch: 74/80, Train Loss: 0.0989, Train Acc: 0.9865, Train F1: 0.9893, Val Loss: 1.2630, Val Acc: 0.9780, Val F1: 0.9791\n",
            "Epoch: 75/80, Train Loss: 0.0977, Train Acc: 0.9870, Train F1: 0.9895, Val Loss: 1.2706, Val Acc: 0.9781, Val F1: 0.9793\n",
            "Epoch: 76/80, Train Loss: 0.0969, Train Acc: 0.9872, Train F1: 0.9897, Val Loss: 1.2874, Val Acc: 0.9788, Val F1: 0.9797\n",
            "Epoch: 77/80, Train Loss: 0.0962, Train Acc: 0.9874, Train F1: 0.9898, Val Loss: 1.2777, Val Acc: 0.9783, Val F1: 0.9794\n",
            "Epoch: 78/80, Train Loss: 0.0956, Train Acc: 0.9875, Train F1: 0.9898, Val Loss: 1.2698, Val Acc: 0.9780, Val F1: 0.9792\n",
            "Epoch: 79/80, Train Loss: 0.0951, Train Acc: 0.9874, Train F1: 0.9897, Val Loss: 1.2713, Val Acc: 0.9780, Val F1: 0.9792\n",
            "Epoch: 80/80, Train Loss: 0.0949, Train Acc: 0.9874, Train F1: 0.9898, Val Loss: 1.2723, Val Acc: 0.9780, Val F1: 0.9791\n",
            "\n",
            " üîé search 7 : deep_rescnn --- lr : 0.0003070049962923372, weight_decay : 0.01, batch_size : 128\n",
            "Epoch: 1/80, Train Loss: 3.7027, Train Acc: 0.6372, Train F1: 0.7080, Val Loss: 2.6937, Val Acc: 0.7708, Val F1: 0.8144\n",
            "Epoch: 2/80, Train Loss: 2.4728, Train Acc: 0.7620, Train F1: 0.8147, Val Loss: 2.0806, Val Acc: 0.8416, Val F1: 0.8721\n",
            "Epoch: 3/80, Train Loss: 1.9137, Train Acc: 0.8132, Train F1: 0.8571, Val Loss: 2.1290, Val Acc: 0.7586, Val F1: 0.8272\n",
            "Epoch: 4/80, Train Loss: 1.7579, Train Acc: 0.8314, Train F1: 0.8712, Val Loss: 1.7330, Val Acc: 0.8422, Val F1: 0.8788\n",
            "Epoch: 5/80, Train Loss: 1.6335, Train Acc: 0.8378, Train F1: 0.8744, Val Loss: 1.7053, Val Acc: 0.9001, Val F1: 0.9215\n",
            "Epoch: 6/80, Train Loss: 1.3632, Train Acc: 0.8648, Train F1: 0.8964, Val Loss: 1.5784, Val Acc: 0.8805, Val F1: 0.9085\n",
            "Epoch: 7/80, Train Loss: 1.3134, Train Acc: 0.8748, Train F1: 0.9042, Val Loss: 1.6576, Val Acc: 0.7380, Val F1: 0.8048\n",
            "Epoch: 8/80, Train Loss: 1.2099, Train Acc: 0.8788, Train F1: 0.9071, Val Loss: 1.4386, Val Acc: 0.8470, Val F1: 0.8823\n",
            "Epoch: 9/80, Train Loss: 1.1547, Train Acc: 0.8861, Train F1: 0.9129, Val Loss: 1.7495, Val Acc: 0.9431, Val F1: 0.9475\n",
            "Epoch: 10/80, Train Loss: 1.0933, Train Acc: 0.8930, Train F1: 0.9178, Val Loss: 1.3716, Val Acc: 0.9049, Val F1: 0.9248\n",
            "Epoch: 11/80, Train Loss: 1.0329, Train Acc: 0.8957, Train F1: 0.9195, Val Loss: 1.3216, Val Acc: 0.9267, Val F1: 0.9386\n",
            "Epoch: 12/80, Train Loss: 1.0075, Train Acc: 0.8960, Train F1: 0.9199, Val Loss: 1.2144, Val Acc: 0.9063, Val F1: 0.9242\n",
            "Epoch: 13/80, Train Loss: 0.9357, Train Acc: 0.9059, Train F1: 0.9274, Val Loss: 1.3247, Val Acc: 0.9211, Val F1: 0.9348\n",
            "Epoch: 14/80, Train Loss: 0.9076, Train Acc: 0.9053, Train F1: 0.9273, Val Loss: 1.1597, Val Acc: 0.9007, Val F1: 0.9206\n",
            "Epoch: 15/80, Train Loss: 0.8500, Train Acc: 0.9066, Train F1: 0.9280, Val Loss: 1.2253, Val Acc: 0.9328, Val F1: 0.9440\n",
            "Epoch: 16/80, Train Loss: 0.8018, Train Acc: 0.9171, Train F1: 0.9354, Val Loss: 1.0414, Val Acc: 0.9351, Val F1: 0.9465\n",
            "Epoch: 17/80, Train Loss: 0.7731, Train Acc: 0.9220, Train F1: 0.9393, Val Loss: 1.4276, Val Acc: 0.8029, Val F1: 0.8583\n",
            "Epoch: 18/80, Train Loss: 0.7598, Train Acc: 0.9164, Train F1: 0.9349, Val Loss: 1.1100, Val Acc: 0.9241, Val F1: 0.9392\n",
            "Epoch: 19/80, Train Loss: 0.7610, Train Acc: 0.9200, Train F1: 0.9379, Val Loss: 1.0626, Val Acc: 0.9108, Val F1: 0.9284\n",
            "Epoch: 20/80, Train Loss: 0.6531, Train Acc: 0.9278, Train F1: 0.9432, Val Loss: 1.1273, Val Acc: 0.9537, Val F1: 0.9587\n",
            "Epoch: 21/80, Train Loss: 0.6625, Train Acc: 0.9259, Train F1: 0.9419, Val Loss: 1.0771, Val Acc: 0.9358, Val F1: 0.9463\n",
            "Epoch: 22/80, Train Loss: 0.6478, Train Acc: 0.9287, Train F1: 0.9441, Val Loss: 1.4491, Val Acc: 0.9580, Val F1: 0.9608\n",
            "Epoch: 23/80, Train Loss: 0.6197, Train Acc: 0.9325, Train F1: 0.9465, Val Loss: 1.1798, Val Acc: 0.9245, Val F1: 0.9356\n",
            "Epoch: 24/80, Train Loss: 0.5685, Train Acc: 0.9381, Train F1: 0.9508, Val Loss: 1.0822, Val Acc: 0.9448, Val F1: 0.9512\n",
            "Epoch: 25/80, Train Loss: 0.5825, Train Acc: 0.9333, Train F1: 0.9473, Val Loss: 1.0855, Val Acc: 0.9333, Val F1: 0.9458\n",
            "Epoch: 26/80, Train Loss: 0.5546, Train Acc: 0.9371, Train F1: 0.9503, Val Loss: 1.1405, Val Acc: 0.9653, Val F1: 0.9685\n",
            "Epoch: 27/80, Train Loss: 0.5415, Train Acc: 0.9410, Train F1: 0.9528, Val Loss: 1.2663, Val Acc: 0.9033, Val F1: 0.9245\n",
            "Epoch: 28/80, Train Loss: 0.5384, Train Acc: 0.9397, Train F1: 0.9516, Val Loss: 1.0440, Val Acc: 0.9466, Val F1: 0.9565\n",
            "Epoch: 29/80, Train Loss: 0.4967, Train Acc: 0.9429, Train F1: 0.9545, Val Loss: 1.1730, Val Acc: 0.9367, Val F1: 0.9463\n",
            "Epoch: 30/80, Train Loss: 0.4694, Train Acc: 0.9441, Train F1: 0.9549, Val Loss: 1.0481, Val Acc: 0.9325, Val F1: 0.9445\n",
            "Epoch: 31/80, Train Loss: 0.4945, Train Acc: 0.9440, Train F1: 0.9555, Val Loss: 1.0204, Val Acc: 0.9526, Val F1: 0.9588\n",
            "Epoch: 32/80, Train Loss: 0.4248, Train Acc: 0.9498, Train F1: 0.9591, Val Loss: 1.1274, Val Acc: 0.9427, Val F1: 0.9501\n",
            "Epoch: 33/80, Train Loss: 0.4445, Train Acc: 0.9484, Train F1: 0.9585, Val Loss: 1.0003, Val Acc: 0.9560, Val F1: 0.9613\n",
            "Epoch: 34/80, Train Loss: 0.4107, Train Acc: 0.9522, Train F1: 0.9612, Val Loss: 0.9553, Val Acc: 0.9568, Val F1: 0.9620\n",
            "Epoch: 35/80, Train Loss: 0.4050, Train Acc: 0.9515, Train F1: 0.9609, Val Loss: 1.0140, Val Acc: 0.9535, Val F1: 0.9589\n",
            "Epoch: 36/80, Train Loss: 0.4002, Train Acc: 0.9516, Train F1: 0.9607, Val Loss: 1.1867, Val Acc: 0.9606, Val F1: 0.9641\n",
            "Epoch: 37/80, Train Loss: 0.4105, Train Acc: 0.9518, Train F1: 0.9611, Val Loss: 1.0476, Val Acc: 0.9410, Val F1: 0.9503\n",
            "Epoch: 38/80, Train Loss: 0.3702, Train Acc: 0.9548, Train F1: 0.9632, Val Loss: 1.2743, Val Acc: 0.9511, Val F1: 0.9570\n",
            "Epoch: 39/80, Train Loss: 0.3631, Train Acc: 0.9582, Train F1: 0.9657, Val Loss: 1.1389, Val Acc: 0.9519, Val F1: 0.9595\n",
            "Epoch: 40/80, Train Loss: 0.3400, Train Acc: 0.9586, Train F1: 0.9662, Val Loss: 1.1190, Val Acc: 0.9381, Val F1: 0.9468\n",
            "Epoch: 41/80, Train Loss: 0.3339, Train Acc: 0.9580, Train F1: 0.9658, Val Loss: 1.2109, Val Acc: 0.9119, Val F1: 0.9265\n",
            "Epoch: 42/80, Train Loss: 0.3487, Train Acc: 0.9571, Train F1: 0.9652, Val Loss: 1.0077, Val Acc: 0.9439, Val F1: 0.9529\n",
            "Epoch: 43/80, Train Loss: 0.3167, Train Acc: 0.9615, Train F1: 0.9685, Val Loss: 1.2945, Val Acc: 0.9551, Val F1: 0.9587\n",
            "Epoch: 44/80, Train Loss: 0.3049, Train Acc: 0.9617, Train F1: 0.9686, Val Loss: 1.1447, Val Acc: 0.9510, Val F1: 0.9579\n",
            "Epoch: 45/80, Train Loss: 0.2973, Train Acc: 0.9623, Train F1: 0.9692, Val Loss: 1.2126, Val Acc: 0.9656, Val F1: 0.9684\n",
            "Epoch: 46/80, Train Loss: 0.2940, Train Acc: 0.9624, Train F1: 0.9691, Val Loss: 1.1788, Val Acc: 0.9612, Val F1: 0.9647\n",
            "Epoch: 47/80, Train Loss: 0.2613, Train Acc: 0.9671, Train F1: 0.9725, Val Loss: 1.1643, Val Acc: 0.9544, Val F1: 0.9598\n",
            "Epoch: 48/80, Train Loss: 0.2879, Train Acc: 0.9643, Train F1: 0.9705, Val Loss: 1.2472, Val Acc: 0.9603, Val F1: 0.9633\n",
            "Epoch: 49/80, Train Loss: 0.2501, Train Acc: 0.9689, Train F1: 0.9740, Val Loss: 1.0145, Val Acc: 0.9610, Val F1: 0.9654\n",
            "Epoch: 50/80, Train Loss: 0.2506, Train Acc: 0.9679, Train F1: 0.9732, Val Loss: 1.3754, Val Acc: 0.9700, Val F1: 0.9722\n",
            "Epoch: 51/80, Train Loss: 0.2696, Train Acc: 0.9680, Train F1: 0.9733, Val Loss: 1.0748, Val Acc: 0.9555, Val F1: 0.9608\n",
            "Epoch: 52/80, Train Loss: 0.2322, Train Acc: 0.9703, Train F1: 0.9752, Val Loss: 1.1984, Val Acc: 0.9658, Val F1: 0.9687\n",
            "Epoch: 53/80, Train Loss: 0.2255, Train Acc: 0.9720, Train F1: 0.9763, Val Loss: 1.0665, Val Acc: 0.9446, Val F1: 0.9528\n",
            "Epoch: 54/80, Train Loss: 0.2201, Train Acc: 0.9715, Train F1: 0.9762, Val Loss: 1.2290, Val Acc: 0.9654, Val F1: 0.9682\n",
            "Epoch: 55/80, Train Loss: 0.2167, Train Acc: 0.9726, Train F1: 0.9770, Val Loss: 1.2165, Val Acc: 0.9688, Val F1: 0.9709\n",
            "Epoch: 56/80, Train Loss: 0.2102, Train Acc: 0.9727, Train F1: 0.9768, Val Loss: 1.1289, Val Acc: 0.9649, Val F1: 0.9687\n",
            "Epoch: 57/80, Train Loss: 0.2021, Train Acc: 0.9743, Train F1: 0.9784, Val Loss: 1.2165, Val Acc: 0.9633, Val F1: 0.9677\n",
            "Epoch: 58/80, Train Loss: 0.2050, Train Acc: 0.9741, Train F1: 0.9781, Val Loss: 1.3753, Val Acc: 0.9739, Val F1: 0.9750\n",
            "Epoch: 59/80, Train Loss: 0.1890, Train Acc: 0.9759, Train F1: 0.9795, Val Loss: 1.2313, Val Acc: 0.9696, Val F1: 0.9719\n",
            "Epoch: 60/80, Train Loss: 0.1865, Train Acc: 0.9764, Train F1: 0.9799, Val Loss: 1.2540, Val Acc: 0.9727, Val F1: 0.9747\n",
            "Epoch: 61/80, Train Loss: 0.1861, Train Acc: 0.9758, Train F1: 0.9795, Val Loss: 1.2297, Val Acc: 0.9662, Val F1: 0.9687\n",
            "Epoch: 62/80, Train Loss: 0.1803, Train Acc: 0.9768, Train F1: 0.9803, Val Loss: 1.1941, Val Acc: 0.9693, Val F1: 0.9721\n",
            "Epoch: 63/80, Train Loss: 0.1715, Train Acc: 0.9777, Train F1: 0.9809, Val Loss: 1.1885, Val Acc: 0.9678, Val F1: 0.9704\n",
            "Epoch: 64/80, Train Loss: 0.1712, Train Acc: 0.9782, Train F1: 0.9814, Val Loss: 1.3196, Val Acc: 0.9692, Val F1: 0.9715\n",
            "Epoch: 65/80, Train Loss: 0.1675, Train Acc: 0.9787, Train F1: 0.9817, Val Loss: 1.2223, Val Acc: 0.9707, Val F1: 0.9727\n",
            "Epoch: 66/80, Train Loss: 0.1651, Train Acc: 0.9786, Train F1: 0.9816, Val Loss: 1.2026, Val Acc: 0.9680, Val F1: 0.9706\n",
            "Epoch: 67/80, Train Loss: 0.1613, Train Acc: 0.9795, Train F1: 0.9824, Val Loss: 1.2320, Val Acc: 0.9701, Val F1: 0.9724\n",
            "Epoch: 68/80, Train Loss: 0.1577, Train Acc: 0.9797, Train F1: 0.9825, Val Loss: 1.2613, Val Acc: 0.9725, Val F1: 0.9741\n",
            "Epoch: 69/80, Train Loss: 0.1575, Train Acc: 0.9800, Train F1: 0.9828, Val Loss: 1.2560, Val Acc: 0.9686, Val F1: 0.9709\n",
            "Epoch: 70/80, Train Loss: 0.1560, Train Acc: 0.9800, Train F1: 0.9828, Val Loss: 1.3099, Val Acc: 0.9725, Val F1: 0.9742\n",
            "Epoch: 71/80, Train Loss: 0.1522, Train Acc: 0.9805, Train F1: 0.9832, Val Loss: 1.3479, Val Acc: 0.9729, Val F1: 0.9744\n",
            "Epoch: 72/80, Train Loss: 0.1502, Train Acc: 0.9807, Train F1: 0.9834, Val Loss: 1.2851, Val Acc: 0.9710, Val F1: 0.9729\n",
            "Epoch: 73/80, Train Loss: 0.1490, Train Acc: 0.9807, Train F1: 0.9834, Val Loss: 1.3269, Val Acc: 0.9730, Val F1: 0.9746\n",
            "Epoch: 74/80, Train Loss: 0.1475, Train Acc: 0.9806, Train F1: 0.9833, Val Loss: 1.3453, Val Acc: 0.9742, Val F1: 0.9756\n",
            "Epoch: 75/80, Train Loss: 0.1465, Train Acc: 0.9811, Train F1: 0.9837, Val Loss: 1.3696, Val Acc: 0.9737, Val F1: 0.9751\n",
            "Epoch: 76/80, Train Loss: 0.1455, Train Acc: 0.9815, Train F1: 0.9840, Val Loss: 1.3362, Val Acc: 0.9721, Val F1: 0.9738\n",
            "Epoch: 77/80, Train Loss: 0.1446, Train Acc: 0.9813, Train F1: 0.9838, Val Loss: 1.3392, Val Acc: 0.9730, Val F1: 0.9745\n",
            "Epoch: 78/80, Train Loss: 0.1441, Train Acc: 0.9816, Train F1: 0.9841, Val Loss: 1.3330, Val Acc: 0.9724, Val F1: 0.9740\n",
            "Epoch: 79/80, Train Loss: 0.1437, Train Acc: 0.9816, Train F1: 0.9840, Val Loss: 1.3313, Val Acc: 0.9724, Val F1: 0.9740\n",
            "Epoch: 80/80, Train Loss: 0.1433, Train Acc: 0.9816, Train F1: 0.9840, Val Loss: 1.3311, Val Acc: 0.9724, Val F1: 0.9740\n",
            "\n",
            " üîé search 8 : deep_rescnn --- lr : 0.0001887329560876115, weight_decay : 0.01, batch_size : 64\n",
            "Epoch: 1/80, Train Loss: 3.9192, Train Acc: 0.6202, Train F1: 0.6962, Val Loss: 2.3617, Val Acc: 0.7754, Val F1: 0.8236\n",
            "Epoch: 2/80, Train Loss: 2.1919, Train Acc: 0.7772, Train F1: 0.8301, Val Loss: 2.0776, Val Acc: 0.6398, Val F1: 0.7188\n",
            "Epoch: 3/80, Train Loss: 1.8334, Train Acc: 0.8251, Train F1: 0.8679, Val Loss: 1.7551, Val Acc: 0.8322, Val F1: 0.8664\n",
            "Epoch: 4/80, Train Loss: 1.6454, Train Acc: 0.8413, Train F1: 0.8807, Val Loss: 1.5604, Val Acc: 0.8555, Val F1: 0.8872\n",
            "Epoch: 5/80, Train Loss: 1.4653, Train Acc: 0.8614, Train F1: 0.8957, Val Loss: 1.6021, Val Acc: 0.8644, Val F1: 0.8956\n",
            "Epoch: 6/80, Train Loss: 1.3524, Train Acc: 0.8692, Train F1: 0.9024, Val Loss: 1.4883, Val Acc: 0.8272, Val F1: 0.8713\n",
            "Epoch: 7/80, Train Loss: 1.2031, Train Acc: 0.8830, Train F1: 0.9122, Val Loss: 1.4258, Val Acc: 0.8123, Val F1: 0.8610\n",
            "Epoch: 8/80, Train Loss: 1.1499, Train Acc: 0.8866, Train F1: 0.9154, Val Loss: 1.3089, Val Acc: 0.8375, Val F1: 0.8787\n",
            "Epoch: 9/80, Train Loss: 1.0852, Train Acc: 0.8927, Train F1: 0.9198, Val Loss: 1.3184, Val Acc: 0.9280, Val F1: 0.9380\n",
            "Epoch: 10/80, Train Loss: 1.0071, Train Acc: 0.9009, Train F1: 0.9256, Val Loss: 1.3714, Val Acc: 0.8604, Val F1: 0.8881\n",
            "Epoch: 11/80, Train Loss: 0.9606, Train Acc: 0.8994, Train F1: 0.9248, Val Loss: 1.2913, Val Acc: 0.8354, Val F1: 0.8741\n",
            "Epoch: 12/80, Train Loss: 0.9103, Train Acc: 0.9048, Train F1: 0.9288, Val Loss: 1.4139, Val Acc: 0.8451, Val F1: 0.8847\n",
            "Epoch: 13/80, Train Loss: 0.8820, Train Acc: 0.9064, Train F1: 0.9302, Val Loss: 1.2002, Val Acc: 0.8495, Val F1: 0.8836\n",
            "Epoch: 14/80, Train Loss: 0.8306, Train Acc: 0.9129, Train F1: 0.9350, Val Loss: 1.1715, Val Acc: 0.9487, Val F1: 0.9543\n",
            "Epoch: 15/80, Train Loss: 0.7566, Train Acc: 0.9176, Train F1: 0.9377, Val Loss: 1.2469, Val Acc: 0.9046, Val F1: 0.9220\n",
            "Epoch: 16/80, Train Loss: 0.7632, Train Acc: 0.9176, Train F1: 0.9383, Val Loss: 1.0549, Val Acc: 0.9290, Val F1: 0.9414\n",
            "Epoch: 17/80, Train Loss: 0.7179, Train Acc: 0.9240, Train F1: 0.9429, Val Loss: 1.0882, Val Acc: 0.9308, Val F1: 0.9433\n",
            "Epoch: 18/80, Train Loss: 0.7189, Train Acc: 0.9225, Train F1: 0.9421, Val Loss: 1.0913, Val Acc: 0.9480, Val F1: 0.9554\n",
            "Epoch: 19/80, Train Loss: 0.6684, Train Acc: 0.9273, Train F1: 0.9454, Val Loss: 1.1839, Val Acc: 0.9503, Val F1: 0.9564\n",
            "Epoch: 20/80, Train Loss: 0.6245, Train Acc: 0.9294, Train F1: 0.9468, Val Loss: 1.0066, Val Acc: 0.9318, Val F1: 0.9459\n",
            "Epoch: 21/80, Train Loss: 0.6170, Train Acc: 0.9316, Train F1: 0.9487, Val Loss: 1.0496, Val Acc: 0.9559, Val F1: 0.9606\n",
            "Epoch: 22/80, Train Loss: 0.5934, Train Acc: 0.9338, Train F1: 0.9504, Val Loss: 1.0305, Val Acc: 0.9133, Val F1: 0.9298\n",
            "Epoch: 23/80, Train Loss: 0.6085, Train Acc: 0.9294, Train F1: 0.9470, Val Loss: 1.0227, Val Acc: 0.9152, Val F1: 0.9306\n",
            "Epoch: 24/80, Train Loss: 0.5474, Train Acc: 0.9363, Train F1: 0.9520, Val Loss: 1.0128, Val Acc: 0.9369, Val F1: 0.9464\n",
            "Epoch: 25/80, Train Loss: 0.4919, Train Acc: 0.9421, Train F1: 0.9562, Val Loss: 1.0988, Val Acc: 0.9419, Val F1: 0.9521\n",
            "Epoch: 26/80, Train Loss: 0.4879, Train Acc: 0.9419, Train F1: 0.9562, Val Loss: 1.0388, Val Acc: 0.9501, Val F1: 0.9568\n",
            "Epoch: 27/80, Train Loss: 0.4893, Train Acc: 0.9401, Train F1: 0.9548, Val Loss: 1.0353, Val Acc: 0.9372, Val F1: 0.9473\n",
            "Epoch: 28/80, Train Loss: 0.4724, Train Acc: 0.9421, Train F1: 0.9563, Val Loss: 0.9869, Val Acc: 0.9201, Val F1: 0.9366\n",
            "Epoch: 29/80, Train Loss: 0.4688, Train Acc: 0.9451, Train F1: 0.9587, Val Loss: 1.0011, Val Acc: 0.9164, Val F1: 0.9353\n",
            "Epoch: 30/80, Train Loss: 0.4062, Train Acc: 0.9517, Train F1: 0.9635, Val Loss: 1.0237, Val Acc: 0.9384, Val F1: 0.9482\n",
            "Epoch: 31/80, Train Loss: 0.4156, Train Acc: 0.9479, Train F1: 0.9605, Val Loss: 1.1673, Val Acc: 0.9582, Val F1: 0.9622\n",
            "Epoch: 32/80, Train Loss: 0.4128, Train Acc: 0.9497, Train F1: 0.9618, Val Loss: 1.0958, Val Acc: 0.9562, Val F1: 0.9608\n",
            "Epoch: 33/80, Train Loss: 0.4146, Train Acc: 0.9516, Train F1: 0.9631, Val Loss: 0.9694, Val Acc: 0.9428, Val F1: 0.9518\n",
            "Epoch: 34/80, Train Loss: 0.3690, Train Acc: 0.9541, Train F1: 0.9648, Val Loss: 1.1186, Val Acc: 0.9527, Val F1: 0.9588\n",
            "Epoch: 35/80, Train Loss: 0.3646, Train Acc: 0.9567, Train F1: 0.9669, Val Loss: 1.1025, Val Acc: 0.9401, Val F1: 0.9517\n",
            "Epoch: 36/80, Train Loss: 0.3584, Train Acc: 0.9556, Train F1: 0.9663, Val Loss: 1.1962, Val Acc: 0.9550, Val F1: 0.9619\n",
            "Epoch: 37/80, Train Loss: 0.3393, Train Acc: 0.9568, Train F1: 0.9669, Val Loss: 1.0434, Val Acc: 0.9251, Val F1: 0.9395\n",
            "Epoch: 38/80, Train Loss: 0.3277, Train Acc: 0.9575, Train F1: 0.9678, Val Loss: 0.9832, Val Acc: 0.9460, Val F1: 0.9557\n",
            "Epoch: 39/80, Train Loss: 0.3232, Train Acc: 0.9594, Train F1: 0.9689, Val Loss: 1.1652, Val Acc: 0.9696, Val F1: 0.9719\n",
            "Epoch: 40/80, Train Loss: 0.2924, Train Acc: 0.9638, Train F1: 0.9721, Val Loss: 1.0817, Val Acc: 0.9654, Val F1: 0.9695\n",
            "Epoch: 41/80, Train Loss: 0.3170, Train Acc: 0.9609, Train F1: 0.9700, Val Loss: 1.0450, Val Acc: 0.9460, Val F1: 0.9559\n",
            "Epoch: 42/80, Train Loss: 0.2689, Train Acc: 0.9638, Train F1: 0.9723, Val Loss: 1.1736, Val Acc: 0.9549, Val F1: 0.9623\n",
            "Epoch: 43/80, Train Loss: 0.3127, Train Acc: 0.9617, Train F1: 0.9707, Val Loss: 1.0042, Val Acc: 0.9601, Val F1: 0.9647\n",
            "Epoch: 44/80, Train Loss: 0.2620, Train Acc: 0.9660, Train F1: 0.9737, Val Loss: 1.0958, Val Acc: 0.9270, Val F1: 0.9407\n",
            "Epoch: 45/80, Train Loss: 0.2588, Train Acc: 0.9651, Train F1: 0.9730, Val Loss: 1.0978, Val Acc: 0.9690, Val F1: 0.9715\n",
            "Epoch: 46/80, Train Loss: 0.2482, Train Acc: 0.9675, Train F1: 0.9750, Val Loss: 1.1094, Val Acc: 0.9399, Val F1: 0.9481\n",
            "Epoch: 47/80, Train Loss: 0.2618, Train Acc: 0.9668, Train F1: 0.9744, Val Loss: 1.0954, Val Acc: 0.9653, Val F1: 0.9687\n",
            "Epoch: 48/80, Train Loss: 0.2334, Train Acc: 0.9686, Train F1: 0.9758, Val Loss: 1.0862, Val Acc: 0.9649, Val F1: 0.9688\n",
            "Epoch: 49/80, Train Loss: 0.2247, Train Acc: 0.9703, Train F1: 0.9770, Val Loss: 1.2764, Val Acc: 0.9753, Val F1: 0.9767\n",
            "Epoch: 50/80, Train Loss: 0.2267, Train Acc: 0.9713, Train F1: 0.9778, Val Loss: 1.0798, Val Acc: 0.9588, Val F1: 0.9635\n",
            "Epoch: 51/80, Train Loss: 0.2080, Train Acc: 0.9730, Train F1: 0.9788, Val Loss: 1.0728, Val Acc: 0.9561, Val F1: 0.9609\n",
            "Epoch: 52/80, Train Loss: 0.2146, Train Acc: 0.9718, Train F1: 0.9780, Val Loss: 1.1634, Val Acc: 0.9682, Val F1: 0.9706\n",
            "Epoch: 53/80, Train Loss: 0.1982, Train Acc: 0.9744, Train F1: 0.9799, Val Loss: 1.1276, Val Acc: 0.9498, Val F1: 0.9599\n",
            "Epoch: 54/80, Train Loss: 0.1939, Train Acc: 0.9748, Train F1: 0.9801, Val Loss: 1.0553, Val Acc: 0.9560, Val F1: 0.9618\n",
            "Epoch: 55/80, Train Loss: 0.1930, Train Acc: 0.9754, Train F1: 0.9808, Val Loss: 1.2509, Val Acc: 0.9645, Val F1: 0.9676\n",
            "Epoch: 56/80, Train Loss: 0.1807, Train Acc: 0.9761, Train F1: 0.9812, Val Loss: 1.1161, Val Acc: 0.9658, Val F1: 0.9699\n",
            "Epoch: 57/80, Train Loss: 0.1766, Train Acc: 0.9767, Train F1: 0.9817, Val Loss: 1.2208, Val Acc: 0.9738, Val F1: 0.9756\n",
            "Epoch: 58/80, Train Loss: 0.1757, Train Acc: 0.9763, Train F1: 0.9813, Val Loss: 1.2119, Val Acc: 0.9705, Val F1: 0.9730\n",
            "Epoch: 59/80, Train Loss: 0.1661, Train Acc: 0.9784, Train F1: 0.9828, Val Loss: 1.2778, Val Acc: 0.9730, Val F1: 0.9747\n",
            "Epoch: 60/80, Train Loss: 0.1667, Train Acc: 0.9778, Train F1: 0.9825, Val Loss: 1.2904, Val Acc: 0.9710, Val F1: 0.9730\n",
            "Epoch: 61/80, Train Loss: 0.1584, Train Acc: 0.9790, Train F1: 0.9836, Val Loss: 1.1950, Val Acc: 0.9680, Val F1: 0.9709\n",
            "Epoch: 62/80, Train Loss: 0.1595, Train Acc: 0.9788, Train F1: 0.9832, Val Loss: 1.2535, Val Acc: 0.9695, Val F1: 0.9723\n",
            "Epoch: 63/80, Train Loss: 0.1521, Train Acc: 0.9801, Train F1: 0.9842, Val Loss: 1.2136, Val Acc: 0.9683, Val F1: 0.9712\n",
            "Epoch: 64/80, Train Loss: 0.1486, Train Acc: 0.9801, Train F1: 0.9843, Val Loss: 1.3370, Val Acc: 0.9742, Val F1: 0.9756\n",
            "Epoch: 65/80, Train Loss: 0.1453, Train Acc: 0.9806, Train F1: 0.9847, Val Loss: 1.2234, Val Acc: 0.9713, Val F1: 0.9733\n",
            "Epoch: 66/80, Train Loss: 0.1440, Train Acc: 0.9811, Train F1: 0.9851, Val Loss: 1.2131, Val Acc: 0.9666, Val F1: 0.9695\n",
            "Epoch: 67/80, Train Loss: 0.1403, Train Acc: 0.9815, Train F1: 0.9853, Val Loss: 1.2489, Val Acc: 0.9702, Val F1: 0.9724\n",
            "Epoch: 68/80, Train Loss: 0.1385, Train Acc: 0.9816, Train F1: 0.9854, Val Loss: 1.3154, Val Acc: 0.9751, Val F1: 0.9766\n",
            "Epoch: 69/80, Train Loss: 0.1374, Train Acc: 0.9822, Train F1: 0.9858, Val Loss: 1.2648, Val Acc: 0.9724, Val F1: 0.9742\n",
            "Epoch: 70/80, Train Loss: 0.1350, Train Acc: 0.9824, Train F1: 0.9861, Val Loss: 1.2839, Val Acc: 0.9741, Val F1: 0.9757\n",
            "Epoch: 71/80, Train Loss: 0.1337, Train Acc: 0.9824, Train F1: 0.9861, Val Loss: 1.2856, Val Acc: 0.9739, Val F1: 0.9756\n",
            "Epoch: 72/80, Train Loss: 0.1318, Train Acc: 0.9827, Train F1: 0.9863, Val Loss: 1.3179, Val Acc: 0.9746, Val F1: 0.9760\n",
            "Epoch: 73/80, Train Loss: 0.1314, Train Acc: 0.9831, Train F1: 0.9866, Val Loss: 1.3030, Val Acc: 0.9736, Val F1: 0.9753\n",
            "Epoch: 74/80, Train Loss: 0.1298, Train Acc: 0.9829, Train F1: 0.9864, Val Loss: 1.3220, Val Acc: 0.9750, Val F1: 0.9764\n",
            "Epoch: 75/80, Train Loss: 0.1287, Train Acc: 0.9833, Train F1: 0.9867, Val Loss: 1.3345, Val Acc: 0.9750, Val F1: 0.9764\n",
            "Epoch: 76/80, Train Loss: 0.1280, Train Acc: 0.9835, Train F1: 0.9867, Val Loss: 1.2977, Val Acc: 0.9735, Val F1: 0.9752\n",
            "Epoch: 77/80, Train Loss: 0.1269, Train Acc: 0.9834, Train F1: 0.9869, Val Loss: 1.3052, Val Acc: 0.9741, Val F1: 0.9757\n",
            "Epoch: 78/80, Train Loss: 0.1267, Train Acc: 0.9838, Train F1: 0.9870, Val Loss: 1.3013, Val Acc: 0.9732, Val F1: 0.9750\n",
            "Epoch: 79/80, Train Loss: 0.1261, Train Acc: 0.9836, Train F1: 0.9869, Val Loss: 1.3025, Val Acc: 0.9733, Val F1: 0.9750\n",
            "Epoch: 80/80, Train Loss: 0.1258, Train Acc: 0.9836, Train F1: 0.9870, Val Loss: 1.3033, Val Acc: 0.9733, Val F1: 0.9750\n",
            "\n",
            " üîé search 9 : deep_rescnn --- lr : 0.0001887329560876115, weight_decay : 0.01, batch_size : 128\n",
            "Epoch: 1/80, Train Loss: 4.1201, Train Acc: 0.6266, Train F1: 0.6953, Val Loss: 2.9109, Val Acc: 0.7553, Val F1: 0.8197\n",
            "Epoch: 2/80, Train Loss: 2.3795, Train Acc: 0.7713, Train F1: 0.8227, Val Loss: 2.0670, Val Acc: 0.8141, Val F1: 0.8535\n",
            "Epoch: 3/80, Train Loss: 1.9514, Train Acc: 0.8147, Train F1: 0.8573, Val Loss: 1.9716, Val Acc: 0.8249, Val F1: 0.8608\n",
            "Epoch: 4/80, Train Loss: 1.7302, Train Acc: 0.8411, Train F1: 0.8774, Val Loss: 2.0001, Val Acc: 0.6680, Val F1: 0.7471\n",
            "Epoch: 5/80, Train Loss: 1.5567, Train Acc: 0.8530, Train F1: 0.8867, Val Loss: 1.6184, Val Acc: 0.9005, Val F1: 0.9206\n",
            "Epoch: 6/80, Train Loss: 1.4379, Train Acc: 0.8667, Train F1: 0.8981, Val Loss: 1.8294, Val Acc: 0.8687, Val F1: 0.8912\n",
            "Epoch: 7/80, Train Loss: 1.3180, Train Acc: 0.8732, Train F1: 0.9022, Val Loss: 1.5623, Val Acc: 0.8478, Val F1: 0.8889\n",
            "Epoch: 8/80, Train Loss: 1.2174, Train Acc: 0.8802, Train F1: 0.9081, Val Loss: 1.4435, Val Acc: 0.9264, Val F1: 0.9389\n",
            "Epoch: 9/80, Train Loss: 1.1493, Train Acc: 0.8876, Train F1: 0.9140, Val Loss: 1.5617, Val Acc: 0.8809, Val F1: 0.9051\n",
            "Epoch: 10/80, Train Loss: 1.1139, Train Acc: 0.8863, Train F1: 0.9127, Val Loss: 1.4222, Val Acc: 0.9384, Val F1: 0.9443\n",
            "Epoch: 11/80, Train Loss: 1.0173, Train Acc: 0.8975, Train F1: 0.9212, Val Loss: 1.2376, Val Acc: 0.9022, Val F1: 0.9216\n",
            "Epoch: 12/80, Train Loss: 1.0087, Train Acc: 0.8975, Train F1: 0.9212, Val Loss: 1.3108, Val Acc: 0.9298, Val F1: 0.9412\n",
            "Epoch: 13/80, Train Loss: 0.9516, Train Acc: 0.9028, Train F1: 0.9251, Val Loss: 1.2503, Val Acc: 0.9263, Val F1: 0.9381\n",
            "Epoch: 14/80, Train Loss: 0.9039, Train Acc: 0.9068, Train F1: 0.9283, Val Loss: 1.3529, Val Acc: 0.9512, Val F1: 0.9562\n",
            "Epoch: 15/80, Train Loss: 0.8382, Train Acc: 0.9133, Train F1: 0.9326, Val Loss: 1.2743, Val Acc: 0.9090, Val F1: 0.9285\n",
            "Epoch: 16/80, Train Loss: 0.8450, Train Acc: 0.9100, Train F1: 0.9301, Val Loss: 1.2040, Val Acc: 0.8811, Val F1: 0.9061\n",
            "Epoch: 17/80, Train Loss: 0.7811, Train Acc: 0.9158, Train F1: 0.9345, Val Loss: 1.2659, Val Acc: 0.9005, Val F1: 0.9183\n",
            "Epoch: 18/80, Train Loss: 0.7562, Train Acc: 0.9177, Train F1: 0.9363, Val Loss: 1.1510, Val Acc: 0.9156, Val F1: 0.9328\n",
            "Epoch: 19/80, Train Loss: 0.7279, Train Acc: 0.9235, Train F1: 0.9398, Val Loss: 1.1995, Val Acc: 0.9029, Val F1: 0.9256\n",
            "Epoch: 20/80, Train Loss: 0.7202, Train Acc: 0.9226, Train F1: 0.9400, Val Loss: 1.0587, Val Acc: 0.9120, Val F1: 0.9298\n",
            "Epoch: 21/80, Train Loss: 0.6821, Train Acc: 0.9272, Train F1: 0.9427, Val Loss: 1.1110, Val Acc: 0.8956, Val F1: 0.9199\n",
            "Epoch: 22/80, Train Loss: 0.6479, Train Acc: 0.9277, Train F1: 0.9432, Val Loss: 1.2061, Val Acc: 0.9235, Val F1: 0.9374\n",
            "Epoch: 23/80, Train Loss: 0.6195, Train Acc: 0.9301, Train F1: 0.9450, Val Loss: 1.2532, Val Acc: 0.9208, Val F1: 0.9344\n",
            "Epoch: 24/80, Train Loss: 0.6024, Train Acc: 0.9318, Train F1: 0.9464, Val Loss: 1.2228, Val Acc: 0.9494, Val F1: 0.9561\n",
            "Epoch: 25/80, Train Loss: 0.5766, Train Acc: 0.9347, Train F1: 0.9485, Val Loss: 1.2023, Val Acc: 0.9268, Val F1: 0.9405\n",
            "Epoch: 26/80, Train Loss: 0.5678, Train Acc: 0.9348, Train F1: 0.9485, Val Loss: 1.1732, Val Acc: 0.9427, Val F1: 0.9514\n",
            "Epoch: 27/80, Train Loss: 0.5484, Train Acc: 0.9365, Train F1: 0.9496, Val Loss: 1.3448, Val Acc: 0.9465, Val F1: 0.9527\n",
            "Epoch: 28/80, Train Loss: 0.5308, Train Acc: 0.9387, Train F1: 0.9513, Val Loss: 1.0495, Val Acc: 0.9269, Val F1: 0.9404\n",
            "Epoch: 29/80, Train Loss: 0.5260, Train Acc: 0.9366, Train F1: 0.9502, Val Loss: 1.0876, Val Acc: 0.9398, Val F1: 0.9495\n",
            "Epoch: 30/80, Train Loss: 0.4936, Train Acc: 0.9417, Train F1: 0.9537, Val Loss: 1.3746, Val Acc: 0.9533, Val F1: 0.9581\n",
            "Epoch: 31/80, Train Loss: 0.4956, Train Acc: 0.9437, Train F1: 0.9552, Val Loss: 1.1491, Val Acc: 0.9574, Val F1: 0.9621\n",
            "Epoch: 32/80, Train Loss: 0.4517, Train Acc: 0.9458, Train F1: 0.9569, Val Loss: 1.2042, Val Acc: 0.9266, Val F1: 0.9383\n",
            "Epoch: 33/80, Train Loss: 0.4518, Train Acc: 0.9460, Train F1: 0.9570, Val Loss: 1.0896, Val Acc: 0.9301, Val F1: 0.9422\n",
            "Epoch: 34/80, Train Loss: 0.4277, Train Acc: 0.9485, Train F1: 0.9587, Val Loss: 1.2325, Val Acc: 0.9543, Val F1: 0.9594\n",
            "Epoch: 35/80, Train Loss: 0.4575, Train Acc: 0.9472, Train F1: 0.9578, Val Loss: 1.2122, Val Acc: 0.9182, Val F1: 0.9369\n",
            "Epoch: 36/80, Train Loss: 0.3996, Train Acc: 0.9510, Train F1: 0.9602, Val Loss: 1.1009, Val Acc: 0.9353, Val F1: 0.9458\n",
            "Epoch: 37/80, Train Loss: 0.4078, Train Acc: 0.9526, Train F1: 0.9618, Val Loss: 1.1071, Val Acc: 0.9347, Val F1: 0.9472\n",
            "Epoch: 38/80, Train Loss: 0.4027, Train Acc: 0.9509, Train F1: 0.9605, Val Loss: 1.1535, Val Acc: 0.9501, Val F1: 0.9570\n",
            "Epoch: 39/80, Train Loss: 0.3691, Train Acc: 0.9559, Train F1: 0.9639, Val Loss: 1.1549, Val Acc: 0.9423, Val F1: 0.9514\n",
            "Epoch: 40/80, Train Loss: 0.3606, Train Acc: 0.9549, Train F1: 0.9633, Val Loss: 1.1879, Val Acc: 0.9330, Val F1: 0.9433\n",
            "Epoch: 41/80, Train Loss: 0.3395, Train Acc: 0.9580, Train F1: 0.9657, Val Loss: 1.2901, Val Acc: 0.9563, Val F1: 0.9605\n",
            "Epoch: 42/80, Train Loss: 0.3526, Train Acc: 0.9559, Train F1: 0.9642, Val Loss: 1.0905, Val Acc: 0.9290, Val F1: 0.9412\n",
            "Epoch: 43/80, Train Loss: 0.4418, Train Acc: 0.9458, Train F1: 0.9573, Val Loss: 1.2749, Val Acc: 0.9631, Val F1: 0.9662\n",
            "Epoch: 44/80, Train Loss: 0.3105, Train Acc: 0.9609, Train F1: 0.9680, Val Loss: 1.2388, Val Acc: 0.9520, Val F1: 0.9572\n",
            "Epoch: 45/80, Train Loss: 0.3091, Train Acc: 0.9631, Train F1: 0.9697, Val Loss: 1.1229, Val Acc: 0.9372, Val F1: 0.9463\n",
            "Epoch: 46/80, Train Loss: 0.3036, Train Acc: 0.9622, Train F1: 0.9690, Val Loss: 1.1847, Val Acc: 0.9522, Val F1: 0.9585\n",
            "Epoch: 47/80, Train Loss: 0.3001, Train Acc: 0.9632, Train F1: 0.9696, Val Loss: 1.2412, Val Acc: 0.9569, Val F1: 0.9626\n",
            "Epoch: 48/80, Train Loss: 0.2916, Train Acc: 0.9648, Train F1: 0.9711, Val Loss: 1.2644, Val Acc: 0.9619, Val F1: 0.9653\n",
            "Epoch: 49/80, Train Loss: 0.2888, Train Acc: 0.9640, Train F1: 0.9706, Val Loss: 1.4402, Val Acc: 0.9654, Val F1: 0.9680\n",
            "Epoch: 50/80, Train Loss: 0.2774, Train Acc: 0.9659, Train F1: 0.9720, Val Loss: 1.1853, Val Acc: 0.9511, Val F1: 0.9568\n",
            "Epoch: 51/80, Train Loss: 0.2698, Train Acc: 0.9662, Train F1: 0.9721, Val Loss: 1.2832, Val Acc: 0.9603, Val F1: 0.9646\n",
            "Epoch: 52/80, Train Loss: 0.2576, Train Acc: 0.9677, Train F1: 0.9731, Val Loss: 1.1736, Val Acc: 0.9580, Val F1: 0.9625\n",
            "Epoch: 53/80, Train Loss: 0.2594, Train Acc: 0.9675, Train F1: 0.9731, Val Loss: 1.3111, Val Acc: 0.9672, Val F1: 0.9698\n",
            "Epoch: 54/80, Train Loss: 0.2490, Train Acc: 0.9686, Train F1: 0.9740, Val Loss: 1.2614, Val Acc: 0.9525, Val F1: 0.9585\n",
            "Epoch: 55/80, Train Loss: 0.2458, Train Acc: 0.9689, Train F1: 0.9743, Val Loss: 1.2362, Val Acc: 0.9574, Val F1: 0.9623\n",
            "Epoch: 56/80, Train Loss: 0.2374, Train Acc: 0.9692, Train F1: 0.9745, Val Loss: 1.3050, Val Acc: 0.9561, Val F1: 0.9605\n",
            "Epoch: 57/80, Train Loss: 0.2290, Train Acc: 0.9719, Train F1: 0.9764, Val Loss: 1.2065, Val Acc: 0.9606, Val F1: 0.9644\n",
            "Epoch: 58/80, Train Loss: 0.2262, Train Acc: 0.9716, Train F1: 0.9763, Val Loss: 1.3248, Val Acc: 0.9641, Val F1: 0.9671\n",
            "Epoch: 59/80, Train Loss: 0.2309, Train Acc: 0.9712, Train F1: 0.9760, Val Loss: 1.3679, Val Acc: 0.9699, Val F1: 0.9719\n",
            "Epoch: 60/80, Train Loss: 0.2151, Train Acc: 0.9721, Train F1: 0.9768, Val Loss: 1.3295, Val Acc: 0.9656, Val F1: 0.9684\n",
            "Epoch: 61/80, Train Loss: 0.2142, Train Acc: 0.9727, Train F1: 0.9771, Val Loss: 1.2992, Val Acc: 0.9657, Val F1: 0.9687\n",
            "Epoch: 62/80, Train Loss: 0.2064, Train Acc: 0.9741, Train F1: 0.9782, Val Loss: 1.4583, Val Acc: 0.9680, Val F1: 0.9702\n",
            "Epoch: 63/80, Train Loss: 0.2070, Train Acc: 0.9736, Train F1: 0.9777, Val Loss: 1.3177, Val Acc: 0.9622, Val F1: 0.9657\n",
            "Epoch: 64/80, Train Loss: 0.2020, Train Acc: 0.9744, Train F1: 0.9785, Val Loss: 1.3823, Val Acc: 0.9653, Val F1: 0.9680\n",
            "Epoch: 65/80, Train Loss: 0.2014, Train Acc: 0.9739, Train F1: 0.9780, Val Loss: 1.3351, Val Acc: 0.9664, Val F1: 0.9693\n",
            "Epoch: 66/80, Train Loss: 0.1953, Train Acc: 0.9754, Train F1: 0.9793, Val Loss: 1.3393, Val Acc: 0.9633, Val F1: 0.9664\n",
            "Epoch: 67/80, Train Loss: 0.1922, Train Acc: 0.9754, Train F1: 0.9792, Val Loss: 1.2762, Val Acc: 0.9619, Val F1: 0.9658\n",
            "Epoch: 68/80, Train Loss: 0.1898, Train Acc: 0.9756, Train F1: 0.9795, Val Loss: 1.4243, Val Acc: 0.9686, Val F1: 0.9707\n",
            "Epoch: 69/80, Train Loss: 0.1858, Train Acc: 0.9763, Train F1: 0.9800, Val Loss: 1.3494, Val Acc: 0.9666, Val F1: 0.9693\n",
            "Epoch: 70/80, Train Loss: 0.1841, Train Acc: 0.9763, Train F1: 0.9800, Val Loss: 1.3869, Val Acc: 0.9679, Val F1: 0.9703\n",
            "Epoch: 71/80, Train Loss: 0.1832, Train Acc: 0.9762, Train F1: 0.9799, Val Loss: 1.3864, Val Acc: 0.9677, Val F1: 0.9700\n",
            "Epoch: 72/80, Train Loss: 0.1826, Train Acc: 0.9772, Train F1: 0.9807, Val Loss: 1.3530, Val Acc: 0.9659, Val F1: 0.9688\n",
            "Epoch: 73/80, Train Loss: 0.1804, Train Acc: 0.9768, Train F1: 0.9803, Val Loss: 1.3338, Val Acc: 0.9652, Val F1: 0.9682\n",
            "Epoch: 74/80, Train Loss: 0.1784, Train Acc: 0.9770, Train F1: 0.9805, Val Loss: 1.3486, Val Acc: 0.9645, Val F1: 0.9676\n",
            "Epoch: 75/80, Train Loss: 0.1781, Train Acc: 0.9771, Train F1: 0.9807, Val Loss: 1.3734, Val Acc: 0.9661, Val F1: 0.9687\n",
            "Epoch: 76/80, Train Loss: 0.1769, Train Acc: 0.9771, Train F1: 0.9806, Val Loss: 1.3677, Val Acc: 0.9657, Val F1: 0.9684\n",
            "Epoch: 77/80, Train Loss: 0.1760, Train Acc: 0.9771, Train F1: 0.9807, Val Loss: 1.3770, Val Acc: 0.9662, Val F1: 0.9688\n",
            "Epoch: 78/80, Train Loss: 0.1757, Train Acc: 0.9771, Train F1: 0.9806, Val Loss: 1.3799, Val Acc: 0.9664, Val F1: 0.9690\n",
            "Epoch: 79/80, Train Loss: 0.1751, Train Acc: 0.9772, Train F1: 0.9807, Val Loss: 1.3807, Val Acc: 0.9664, Val F1: 0.9690\n",
            "Epoch: 80/80, Train Loss: 0.1748, Train Acc: 0.9772, Train F1: 0.9808, Val Loss: 1.3810, Val Acc: 0.9666, Val F1: 0.9692\n",
            "CPU times: user 2h 35min 4s, sys: 54.9 s, total: 2h 35min 59s\n",
            "Wall time: 2h 36min 24s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark[benchmark.model_name == 'deep_rescnn']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 930
        },
        "id": "H2c26oVbz7W9",
        "outputId": "318fdbd1-3a77-4efe-b7dd-74aa26345601"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     model_name                                     hyperparameter  \\\n",
              "22  deep_rescnn  {'weight_decay': 0.01, 'learning_rate': 0.001,...   \n",
              "23  deep_rescnn  {'weight_decay': 0.01, 'learning_rate': 0.0007...   \n",
              "24  deep_rescnn  {'weight_decay': 0.01, 'learning_rate': 0.0005...   \n",
              "25  deep_rescnn  {'weight_decay': 0.01, 'learning_rate': 0.0005...   \n",
              "26  deep_rescnn  {'weight_decay': 0.01, 'learning_rate': 0.0003...   \n",
              "27  deep_rescnn  {'weight_decay': 0.01, 'learning_rate': 0.0003...   \n",
              "28  deep_rescnn  {'weight_decay': 0.01, 'learning_rate': 0.0006...   \n",
              "29  deep_rescnn  {'weight_decay': 0.01, 'learning_rate': 0.0006...   \n",
              "30  deep_rescnn  {'weight_decay': 0.01, 'learning_rate': 0.0003...   \n",
              "31  deep_rescnn  {'weight_decay': 0.01, 'learning_rate': 0.0003...   \n",
              "32  deep_rescnn  {'weight_decay': 0.01, 'learning_rate': 0.0001...   \n",
              "33  deep_rescnn  {'weight_decay': 0.01, 'learning_rate': 0.0001...   \n",
              "\n",
              "    best_epoch  best_train_cost  best_val_cost  best_train_recall  \\\n",
              "22          44         3.607100       3.576300           0.974537   \n",
              "23          44         0.138500       1.323600           0.980507   \n",
              "24          72         0.096353       1.342869           0.988259   \n",
              "25          61         0.140412       1.419005           0.982045   \n",
              "26          75         0.099314       1.229917           0.987467   \n",
              "27          70         0.123321       1.194450           0.984010   \n",
              "28          71         0.104476       1.420522           0.987573   \n",
              "29          61         0.156813       1.106651           0.981634   \n",
              "30          68         0.108568       1.313386           0.985913   \n",
              "31          74         0.147458       1.345277           0.980629   \n",
              "32          49         0.224650       1.276352           0.970304   \n",
              "33          59         0.230914       1.367863           0.971248   \n",
              "\n",
              "    best_train_precision  best_train_f1  best_val_recall  best_val_precision  \\\n",
              "22              0.985160       0.978240         0.967655            0.975596   \n",
              "23              0.988372       0.983303         0.978117            0.981256   \n",
              "24              0.994000       0.990442         0.979899            0.982619   \n",
              "25              0.989467       0.984707         0.980081            0.981946   \n",
              "26              0.993815       0.989909         0.979442            0.982341   \n",
              "27              0.990327       0.986208         0.974051            0.978484   \n",
              "28              0.993976       0.990042         0.980218            0.982213   \n",
              "29              0.989564       0.984517         0.979168            0.981829   \n",
              "30              0.993164       0.988726         0.979122            0.982259   \n",
              "31              0.988298       0.983313         0.974234            0.978250   \n",
              "32              0.987395       0.976970         0.975284            0.979392   \n",
              "33              0.984540       0.976045         0.969939            0.975483   \n",
              "\n",
              "    best_val_f1 best_test_recall best_test_precision best_test_f1  \n",
              "22     0.970309              NaN                 NaN          NaN  \n",
              "23     0.979149              NaN                 NaN          NaN  \n",
              "24     0.980798             None                None         None  \n",
              "25     0.980693             None                None         None  \n",
              "26     0.980410             None                None         None  \n",
              "27     0.975559             None                None         None  \n",
              "28     0.980881             None                None         None  \n",
              "29     0.980083             None                None         None  \n",
              "30     0.980206             None                None         None  \n",
              "31     0.975581             None                None         None  \n",
              "32     0.976658             None                None         None  \n",
              "33     0.971883             None                None         None  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-055853b6-9f47-4313-b429-e37c6e8672e0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>hyperparameter</th>\n",
              "      <th>best_epoch</th>\n",
              "      <th>best_train_cost</th>\n",
              "      <th>best_val_cost</th>\n",
              "      <th>best_train_recall</th>\n",
              "      <th>best_train_precision</th>\n",
              "      <th>best_train_f1</th>\n",
              "      <th>best_val_recall</th>\n",
              "      <th>best_val_precision</th>\n",
              "      <th>best_val_f1</th>\n",
              "      <th>best_test_recall</th>\n",
              "      <th>best_test_precision</th>\n",
              "      <th>best_test_f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>deep_rescnn</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.001,...</td>\n",
              "      <td>44</td>\n",
              "      <td>3.607100</td>\n",
              "      <td>3.576300</td>\n",
              "      <td>0.974537</td>\n",
              "      <td>0.985160</td>\n",
              "      <td>0.978240</td>\n",
              "      <td>0.967655</td>\n",
              "      <td>0.975596</td>\n",
              "      <td>0.970309</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>deep_rescnn</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.0007...</td>\n",
              "      <td>44</td>\n",
              "      <td>0.138500</td>\n",
              "      <td>1.323600</td>\n",
              "      <td>0.980507</td>\n",
              "      <td>0.988372</td>\n",
              "      <td>0.983303</td>\n",
              "      <td>0.978117</td>\n",
              "      <td>0.981256</td>\n",
              "      <td>0.979149</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>deep_rescnn</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.0005...</td>\n",
              "      <td>72</td>\n",
              "      <td>0.096353</td>\n",
              "      <td>1.342869</td>\n",
              "      <td>0.988259</td>\n",
              "      <td>0.994000</td>\n",
              "      <td>0.990442</td>\n",
              "      <td>0.979899</td>\n",
              "      <td>0.982619</td>\n",
              "      <td>0.980798</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>deep_rescnn</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.0005...</td>\n",
              "      <td>61</td>\n",
              "      <td>0.140412</td>\n",
              "      <td>1.419005</td>\n",
              "      <td>0.982045</td>\n",
              "      <td>0.989467</td>\n",
              "      <td>0.984707</td>\n",
              "      <td>0.980081</td>\n",
              "      <td>0.981946</td>\n",
              "      <td>0.980693</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>deep_rescnn</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.0003...</td>\n",
              "      <td>75</td>\n",
              "      <td>0.099314</td>\n",
              "      <td>1.229917</td>\n",
              "      <td>0.987467</td>\n",
              "      <td>0.993815</td>\n",
              "      <td>0.989909</td>\n",
              "      <td>0.979442</td>\n",
              "      <td>0.982341</td>\n",
              "      <td>0.980410</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>deep_rescnn</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.0003...</td>\n",
              "      <td>70</td>\n",
              "      <td>0.123321</td>\n",
              "      <td>1.194450</td>\n",
              "      <td>0.984010</td>\n",
              "      <td>0.990327</td>\n",
              "      <td>0.986208</td>\n",
              "      <td>0.974051</td>\n",
              "      <td>0.978484</td>\n",
              "      <td>0.975559</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>deep_rescnn</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.0006...</td>\n",
              "      <td>71</td>\n",
              "      <td>0.104476</td>\n",
              "      <td>1.420522</td>\n",
              "      <td>0.987573</td>\n",
              "      <td>0.993976</td>\n",
              "      <td>0.990042</td>\n",
              "      <td>0.980218</td>\n",
              "      <td>0.982213</td>\n",
              "      <td>0.980881</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>deep_rescnn</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.0006...</td>\n",
              "      <td>61</td>\n",
              "      <td>0.156813</td>\n",
              "      <td>1.106651</td>\n",
              "      <td>0.981634</td>\n",
              "      <td>0.989564</td>\n",
              "      <td>0.984517</td>\n",
              "      <td>0.979168</td>\n",
              "      <td>0.981829</td>\n",
              "      <td>0.980083</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>deep_rescnn</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.0003...</td>\n",
              "      <td>68</td>\n",
              "      <td>0.108568</td>\n",
              "      <td>1.313386</td>\n",
              "      <td>0.985913</td>\n",
              "      <td>0.993164</td>\n",
              "      <td>0.988726</td>\n",
              "      <td>0.979122</td>\n",
              "      <td>0.982259</td>\n",
              "      <td>0.980206</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>deep_rescnn</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.0003...</td>\n",
              "      <td>74</td>\n",
              "      <td>0.147458</td>\n",
              "      <td>1.345277</td>\n",
              "      <td>0.980629</td>\n",
              "      <td>0.988298</td>\n",
              "      <td>0.983313</td>\n",
              "      <td>0.974234</td>\n",
              "      <td>0.978250</td>\n",
              "      <td>0.975581</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>deep_rescnn</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.0001...</td>\n",
              "      <td>49</td>\n",
              "      <td>0.224650</td>\n",
              "      <td>1.276352</td>\n",
              "      <td>0.970304</td>\n",
              "      <td>0.987395</td>\n",
              "      <td>0.976970</td>\n",
              "      <td>0.975284</td>\n",
              "      <td>0.979392</td>\n",
              "      <td>0.976658</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>deep_rescnn</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.0001...</td>\n",
              "      <td>59</td>\n",
              "      <td>0.230914</td>\n",
              "      <td>1.367863</td>\n",
              "      <td>0.971248</td>\n",
              "      <td>0.984540</td>\n",
              "      <td>0.976045</td>\n",
              "      <td>0.969939</td>\n",
              "      <td>0.975483</td>\n",
              "      <td>0.971883</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-055853b6-9f47-4313-b429-e37c6e8672e0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-055853b6-9f47-4313-b429-e37c6e8672e0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-055853b6-9f47-4313-b429-e37c6e8672e0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/99dac6621f6ae8c4/data_table.js\";\n\n      window.createDataTable({\n        data: [[{\n            'v': 22,\n            'f': \"22\",\n        },\n\"deep_rescnn\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.001, 'batch_size': 128}\",\n{\n            'v': 44,\n            'f': \"44\",\n        },\n{\n            'v': 3.6071,\n            'f': \"3.6071\",\n        },\n{\n            'v': 3.5763,\n            'f': \"3.5763\",\n        },\n{\n            'v': 0.9745374248077362,\n            'f': \"0.9745374248077362\",\n        },\n{\n            'v': 0.9851596263975588,\n            'f': \"0.9851596263975588\",\n        },\n{\n            'v': 0.9782400695060556,\n            'f': \"0.9782400695060556\",\n        },\n{\n            'v': 0.967654986522911,\n            'f': \"0.967654986522911\",\n        },\n{\n            'v': 0.9755955480052276,\n            'f': \"0.9755955480052276\",\n        },\n{\n            'v': 0.9703088331598252,\n            'f': \"0.9703088331598252\",\n        },\n{\n            'v': NaN,\n            'f': \"NaN\",\n        },\n{\n            'v': NaN,\n            'f': \"NaN\",\n        },\n{\n            'v': NaN,\n            'f': \"NaN\",\n        }],\n [{\n            'v': 23,\n            'f': \"23\",\n        },\n\"deep_rescnn\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.0007, 'batch_size': 128}\",\n{\n            'v': 44,\n            'f': \"44\",\n        },\n{\n            'v': 0.1385,\n            'f': \"0.1385\",\n        },\n{\n            'v': 1.3236,\n            'f': \"1.3236\",\n        },\n{\n            'v': 0.9805071194700372,\n            'f': \"0.9805071194700372\",\n        },\n{\n            'v': 0.9883724845291104,\n            'f': \"0.9883724845291104\",\n        },\n{\n            'v': 0.9833026613718588,\n            'f': \"0.9833026613718588\",\n        },\n{\n            'v': 0.9781168623509524,\n            'f': \"0.9781168623509524\",\n        },\n{\n            'v': 0.9812555590024558,\n            'f': \"0.9812555590024558\",\n        },\n{\n            'v': 0.9791492452037855,\n            'f': \"0.9791492452037855\",\n        },\n{\n            'v': NaN,\n            'f': \"NaN\",\n        },\n{\n            'v': NaN,\n            'f': \"NaN\",\n        },\n{\n            'v': NaN,\n            'f': \"NaN\",\n        }],\n [{\n            'v': 24,\n            'f': \"24\",\n        },\n\"deep_rescnn\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.0005417906876661164, 'batch_size': 64}\",\n{\n            'v': 72,\n            'f': \"72\",\n        },\n{\n            'v': 0.09635254082669287,\n            'f': \"0.09635254082669287\",\n        },\n{\n            'v': 1.3428689582769724,\n            'f': \"1.3428689582769724\",\n        },\n{\n            'v': 0.9882585852432803,\n            'f': \"0.9882585852432803\",\n        },\n{\n            'v': 0.9940000708405137,\n            'f': \"0.9940000708405137\",\n        },\n{\n            'v': 0.9904420212591803,\n            'f': \"0.9904420212591803\",\n        },\n{\n            'v': 0.9798985791950294,\n            'f': \"0.9798985791950294\",\n        },\n{\n            'v': 0.9826188121765251,\n            'f': \"0.9826188121765251\",\n        },\n{\n            'v': 0.9807983749686754,\n            'f': \"0.9807983749686754\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 25,\n            'f': \"25\",\n        },\n\"deep_rescnn\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.0005417906876661164, 'batch_size': 128}\",\n{\n            'v': 61,\n            'f': \"61\",\n        },\n{\n            'v': 0.1404119248146393,\n            'f': \"0.1404119248146393\",\n        },\n{\n            'v': 1.419004797750319,\n            'f': \"1.419004797750319\",\n        },\n{\n            'v': 0.9820452295743547,\n            'f': \"0.9820452295743547\",\n        },\n{\n            'v': 0.9894674259854331,\n            'f': \"0.9894674259854331\",\n        },\n{\n            'v': 0.9847074014525321,\n            'f': \"0.9847074014525321\",\n        },\n{\n            'v': 0.9800813193841655,\n            'f': \"0.9800813193841655\",\n        },\n{\n            'v': 0.9819457620146917,\n            'f': \"0.9819457620146917\",\n        },\n{\n            'v': 0.9806933937385267,\n            'f': \"0.9806933937385267\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 26,\n            'f': \"26\",\n        },\n\"deep_rescnn\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.0003401853431884869, 'batch_size': 64}\",\n{\n            'v': 75,\n            'f': \"75\",\n        },\n{\n            'v': 0.09931406105327369,\n            'f': \"0.09931406105327369\",\n        },\n{\n            'v': 1.2299168437829628,\n            'f': \"1.2299168437829628\",\n        },\n{\n            'v': 0.9874666869717506,\n            'f': \"0.9874666869717506\",\n        },\n{\n            'v': 0.9938145896422755,\n            'f': \"0.9938145896422755\",\n        },\n{\n            'v': 0.9899088867822844,\n            'f': \"0.9899088867822844\",\n        },\n{\n            'v': 0.9794417287221893,\n            'f': \"0.9794417287221893\",\n        },\n{\n            'v': 0.9823414027913749,\n            'f': \"0.9823414027913749\",\n        },\n{\n            'v': 0.9804098803060372,\n            'f': \"0.9804098803060372\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 27,\n            'f': \"27\",\n        },\n\"deep_rescnn\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.0003401853431884869, 'batch_size': 128}\",\n{\n            'v': 70,\n            'f': \"70\",\n        },\n{\n            'v': 0.12332135295512552,\n            'f': \"0.12332135295512552\",\n        },\n{\n            'v': 1.1944497890130181,\n            'f': \"1.1944497890130181\",\n        },\n{\n            'v': 0.984009746440265,\n            'f': \"0.984009746440265\",\n        },\n{\n            'v': 0.990326998055237,\n            'f': \"0.990326998055237\",\n        },\n{\n            'v': 0.9862081831434807,\n            'f': \"0.9862081831434807\",\n        },\n{\n            'v': 0.9740508931426745,\n            'f': \"0.9740508931426745\",\n        },\n{\n            'v': 0.9784838687344952,\n            'f': \"0.9784838687344952\",\n        },\n{\n            'v': 0.9755594196870992,\n            'f': \"0.9755594196870992\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 28,\n            'f': \"28\",\n        },\n\"deep_rescnn\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.0006333475413534536, 'batch_size': 64}\",\n{\n            'v': 71,\n            'f': \"71\",\n        },\n{\n            'v': 0.10447575792283194,\n            'f': \"0.10447575792283194\",\n        },\n{\n            'v': 1.42052245612251,\n            'f': \"1.42052245612251\",\n        },\n{\n            'v': 0.9875732886621488,\n            'f': \"0.9875732886621488\",\n        },\n{\n            'v': 0.9939755655516386,\n            'f': \"0.9939755655516386\",\n        },\n{\n            'v': 0.9900418781026511,\n            'f': \"0.9900418781026511\",\n        },\n{\n            'v': 0.9802183745260177,\n            'f': \"0.9802183745260177\",\n        },\n{\n            'v': 0.9822134032318967,\n            'f': \"0.9822134032318967\",\n        },\n{\n            'v': 0.9808812996680006,\n            'f': \"0.9808812996680006\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 29,\n            'f': \"29\",\n        },\n\"deep_rescnn\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.0006333475413534536, 'batch_size': 128}\",\n{\n            'v': 61,\n            'f': \"61\",\n        },\n{\n            'v': 0.15681349875444062,\n            'f': \"0.15681349875444062\",\n        },\n{\n            'v': 1.1066509152162374,\n            'f': \"1.1066509152162374\",\n        },\n{\n            'v': 0.9816340516256757,\n            'f': \"0.9816340516256757\",\n        },\n{\n            'v': 0.9895643051120895,\n            'f': \"0.9895643051120895\",\n        },\n{\n            'v': 0.9845167023818494,\n            'f': \"0.9845167023818494\",\n        },\n{\n            'v': 0.9791676184384851,\n            'f': \"0.9791676184384851\",\n        },\n{\n            'v': 0.9818290722492224,\n            'f': \"0.9818290722492224\",\n        },\n{\n            'v': 0.9800833215913701,\n            'f': \"0.9800833215913701\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 30,\n            'f': \"30\",\n        },\n\"deep_rescnn\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.0003070049962923372, 'batch_size': 64}\",\n{\n            'v': 68,\n            'f': \"68\",\n        },\n{\n            'v': 0.10856772529955862,\n            'f': \"0.10856772529955862\",\n        },\n{\n            'v': 1.3133861382047138,\n            'f': \"1.3133861382047138\",\n        },\n{\n            'v': 0.9859133480545191,\n            'f': \"0.9859133480545191\",\n        },\n{\n            'v': 0.9931636675598144,\n            'f': \"0.9931636675598144\",\n        },\n{\n            'v': 0.9887259088133415,\n            'f': \"0.9887259088133415\",\n        },\n{\n            'v': 0.979121933391201,\n            'f': \"0.979121933391201\",\n        },\n{\n            'v': 0.9822592028177979,\n            'f': \"0.9822592028177979\",\n        },\n{\n            'v': 0.9802056458820033,\n            'f': \"0.9802056458820033\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 31,\n            'f': \"31\",\n        },\n\"deep_rescnn\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.0003070049962923372, 'batch_size': 128}\",\n{\n            'v': 74,\n            'f': \"74\",\n        },\n{\n            'v': 0.14745825142882812,\n            'f': \"0.14745825142882812\",\n        },\n{\n            'v': 1.345277297893815,\n            'f': \"1.345277297893815\",\n        },\n{\n            'v': 0.9806289499733496,\n            'f': \"0.9806289499733496\",\n        },\n{\n            'v': 0.9882977719772724,\n            'f': \"0.9882977719772724\",\n        },\n{\n            'v': 0.9833132021302206,\n            'f': \"0.9833132021302206\",\n        },\n{\n            'v': 0.9742336333318105,\n            'f': \"0.9742336333318105\",\n        },\n{\n            'v': 0.9782501147682181,\n            'f': \"0.9782501147682181\",\n        },\n{\n            'v': 0.9755807525660216,\n            'f': \"0.9755807525660216\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 32,\n            'f': \"32\",\n        },\n\"deep_rescnn\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.0001887329560876115, 'batch_size': 64}\",\n{\n            'v': 49,\n            'f': \"49\",\n        },\n{\n            'v': 0.2246504163862819,\n            'f': \"0.2246504163862819\",\n        },\n{\n            'v': 1.2763522748748035,\n            'f': \"1.2763522748748035\",\n        },\n{\n            'v': 0.970303814817635,\n            'f': \"0.970303814817635\",\n        },\n{\n            'v': 0.9873954271241311,\n            'f': \"0.9873954271241311\",\n        },\n{\n            'v': 0.9769702122249688,\n            'f': \"0.9769702122249688\",\n        },\n{\n            'v': 0.975284389419343,\n            'f': \"0.975284389419343\",\n        },\n{\n            'v': 0.9793916957377508,\n            'f': \"0.9793916957377508\",\n        },\n{\n            'v': 0.9766576928090119,\n            'f': \"0.9766576928090119\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }],\n [{\n            'v': 33,\n            'f': \"33\",\n        },\n\"deep_rescnn\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.0001887329560876115, 'batch_size': 128}\",\n{\n            'v': 59,\n            'f': \"59\",\n        },\n{\n            'v': 0.23091400833327058,\n            'f': \"0.23091400833327058\",\n        },\n{\n            'v': 1.3678631354796456,\n            'f': \"1.3678631354796456\",\n        },\n{\n            'v': 0.971248001218305,\n            'f': \"0.971248001218305\",\n        },\n{\n            'v': 0.984539834129142,\n            'f': \"0.984539834129142\",\n        },\n{\n            'v': 0.9760445765992567,\n            'f': \"0.9760445765992567\",\n        },\n{\n            'v': 0.9699392388871122,\n            'f': \"0.9699392388871122\",\n        },\n{\n            'v': 0.9754825157553283,\n            'f': \"0.9754825157553283\",\n        },\n{\n            'v': 0.9718829911277047,\n            'f': \"0.9718829911277047\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        },\n{\n            'v': null,\n            'f': \"null\",\n        }]],\n        columns: [[\"number\", \"index\"], [\"string\", \"model_name\"], [\"string\", \"hyperparameter\"], [\"number\", \"best_epoch\"], [\"number\", \"best_train_cost\"], [\"number\", \"best_val_cost\"], [\"number\", \"best_train_recall\"], [\"number\", \"best_train_precision\"], [\"number\", \"best_train_f1\"], [\"number\", \"best_val_recall\"], [\"number\", \"best_val_precision\"], [\"number\", \"best_val_f1\"], [\"number\", \"best_test_recall\"], [\"number\", \"best_test_precision\"], [\"number\", \"best_test_f1\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: \"0\",\n      });\n    "
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on our experimentation, we have determined that the best hyperparameters for our model are \n",
        "`'weight_decay': 0.01, 'learning_rate': 0.0006333475413534536, and 'batch_size': 64. `\n",
        "\n",
        "These hyperparameters were selected based on achieving the highest validation f1 score.\n",
        "\n",
        "During training, our model achieved a train f1 score of 0.9900418781026511, indicating strong performance on the training set. The model also achieved a validation f1 score of 0.9808812996680006, demonstrating its ability to generalize to new data."
      ],
      "metadata": {
        "id": "fvfEBrNr0i-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save\n",
        "\n",
        "#benchmark.to_csv('/content/drive/MyDrive/arrhythmia_classification/benchmark.csv',index=False)"
      ],
      "metadata": {
        "id": "lW8cXgNyi5Xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save best model # 28th model\n",
        "\n",
        "#torch.save(best_model, '/content/drive/MyDrive/arrhythmia_classification/best_deep_rescnn_model_state_dict.pt')"
      ],
      "metadata": {
        "id": "iGouOHzWiC1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This marks the end of our last experiment. However, in the future, we can explore additional experiments such as training for longer periods, searching for optimal weight_decay, trying new architectures, and more.\n",
        "\n",
        "In the next section, we will evaluate the performance of our best model using several evaluation metrics, including the test set score, confusion matrix, and misclassification examples. By analyzing the misclassified examples, we can identify areas where the model struggles and gain insights into potential directions for improvement in the future"
      ],
      "metadata": {
        "id": "HOeakoLUi5cm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What about print (architecture)"
      ],
      "metadata": {
        "id": "UXe8rnK71Oti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To ensure that we can fit the state_dict to the correct architecture in the next section, I have saved the deep_rescnn architecture into a .py file.\n",
        "\n",
        "Now, let's recap on the files in our directory. So far, we have the following files:\n",
        "\n",
        "```\n",
        "arrhythmia_classification\n",
        "‚îÇ   benchmark.csv\n",
        "‚îÇ   best_deep_rescnn_model_state_dict.pt\n",
        "|   deep_rescnn.py\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "pxcqdwXw3KEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title deep_rescnn.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Deep_ResCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Deep_ResCNN, self).__init__()\n",
        "        # kernel size : (5,), number of channel : 32\n",
        "        self.conv1 = nn.Conv1d(1, 32, 5)\n",
        "        \n",
        "        self.conv2_1 = nn.Conv1d(32, 32, 5, padding=2)\n",
        "        self.conv2_2 = nn.Conv1d(32, 32, 5, padding=2)\n",
        "        \n",
        "        self.conv3_1 = nn.Conv1d(32, 32, 5, padding=2)\n",
        "        self.conv3_2 = nn.Conv1d(32, 32, 5, padding=2)\n",
        "        \n",
        "        self.conv4_1 = nn.Conv1d(32, 32, 5, padding=2)\n",
        "        self.conv4_2 = nn.Conv1d(32, 32, 5, padding=2)\n",
        "        \n",
        "        self.conv5_1 = nn.Conv1d(32, 32, 5, padding=2)\n",
        "        self.conv5_2 = nn.Conv1d(32, 32, 5, padding=2)\n",
        "        \n",
        "        self.fc1 = nn.Linear(32*8, 32)\n",
        "        self.fc2 = nn.Linear(32, 32)\n",
        "        self.fc3 = nn.Linear(32, 5)\n",
        "        \n",
        "        self._init_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        \n",
        "        x1 = F.relu(self.conv2_1(x))\n",
        "        x1 = self.conv2_2(x1)\n",
        "        x = F.relu(x + x1)\n",
        "        x = F.max_pool1d(x, kernel_size=5, stride=2)\n",
        "        \n",
        "        x1 = F.relu(self.conv3_1(x))\n",
        "        x1 = self.conv3_2(x1)\n",
        "        x = F.relu(x + x1)\n",
        "        x = F.max_pool1d(x, kernel_size=5, stride=2)\n",
        "        \n",
        "        x1 = F.relu(self.conv4_1(x))\n",
        "        x1 = self.conv4_2(x1)\n",
        "        x = F.relu(x + x1)\n",
        "        x = F.max_pool1d(x, kernel_size=5, stride=2)\n",
        "        \n",
        "        x1 = F.relu(self.conv5_1(x))\n",
        "        x1 = self.conv5_2(x1)\n",
        "        x = F.relu(x + x1)\n",
        "        x = F.max_pool1d(x, kernel_size=5, stride=2)\n",
        "        \n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv1d) or isinstance(m, nn.Linear):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    x = torch.rand(32,1,187)\n",
        "    res_model = Deep_ResCNN()\n",
        "    print(res_model)\n",
        "    out = res_model(x)\n",
        "    print(out.shape)"
      ],
      "metadata": {
        "id": "CvOegmmq4cOz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3440798b-b387-42ba-b525-35f82fe7693f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deep_ResCNN(\n",
            "  (conv1): Conv1d(1, 32, kernel_size=(5,), stride=(1,))\n",
            "  (conv2_1): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "  (conv2_2): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "  (conv3_1): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "  (conv3_2): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "  (conv4_1): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "  (conv4_2): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "  (conv5_1): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "  (conv5_2): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "  (fc1): Linear(in_features=256, out_features=32, bias=True)\n",
            "  (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
            "  (fc3): Linear(in_features=32, out_features=5, bias=True)\n",
            ")\n",
            "torch.Size([32, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In my opinion, it may not be fair to expect LSTM or GRU models to perform well on zero-padded sequence data, as the trailing zeros in the majority of the data can pose challenges for these models due to the long-term dependencies problem. In the future, we may need to explore ways to mask out the zero-padding to enable fair comparisons between different models.\n",
        "\n",
        "Based on a benchmark of various selection models, we have chosen a specific model that we believe performs well in the context of our task. However, before deploying the model, it is essential to estimate its performance on a test set to avoid overfitting to the validation set.\n",
        "\n",
        "While we have identified a promising model, there are still several areas that require tuning, such as increasing the number of CNN channels from 32 to 64 or 128, adding more layers, incorporating fully connected layers, and considering regularization techniques like weight decay or dropout.\n",
        "\n",
        "As we move forward, one potential avenue to consider is the use of a CNN + LSTM architecture. This approach can help preserve the order of feature extraction while leveraging the strengths of both models."
      ],
      "metadata": {
        "id": "tuBURiTl8ZJZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üî∫ Model Evaluation\n",
        "\n",
        "\n",
        "\n",
        "- This section we are going to check the test set score, confusion matrix, demonstrating how to predict"
      ],
      "metadata": {
        "id": "G3ynpeLxWBmL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import our best model"
      ],
      "metadata": {
        "id": "oQX49zZg_R-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's try load the best model by architecture\n",
        "\n",
        "model = Deep_ResCNN().to(device)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/arrhythmia_classification/best_deep_rescnn_model_state_dict.pt'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRU2ZgzX4jXD",
        "outputId": "dadbe8a2-9df2-4b54-b27d-42e45f532dea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's visualize the architecture of our `deep_rescnn`"
      ],
      "metadata": {
        "id": "jJyOfDH_EWgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install torchviz"
      ],
      "metadata": {
        "id": "wlRQJBVfA7Cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import graphviz\n",
        "from torchviz import make_dot\n",
        "graphviz.set_jupyter_format('png')\n",
        "\n",
        "# Create a dummy input tensor with the correct input size\n",
        "input_tensor = torch.randn(32, 1, 187)\n",
        "\n",
        "# Run the model with the input tensor, storing the output in a variable\n",
        "output = model(input_tensor)\n",
        "\n",
        "# Visualize the model graph using torchviz\n",
        "make_dot(output, params=dict(model.named_parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mwpg3ZKxBD8K",
        "outputId": "01134f3e-0a8d-4868-db90-4abac4ec4de8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x7fcff43782b0>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check the weighted F1 score of the test set"
      ],
      "metadata": {
        "id": "I2pVHqbXAQYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights_normalized = get_weighted_for_ce(y_train)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights_normalized.to(device))\n",
        "\n",
        "train_loader, val_loader, test_loader = get_loader(train_set, val_set, test_set, train_batch_size=64)\n",
        "test_loss, test_acc, test_recall,test_precision,test_f1 = eval_epoch(model, criterion, test_loader)"
      ],
      "metadata": {
        "id": "xGfTTcM7l4cG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f' weight recall score of the best model on test set is {test_recall : .4f}')\n",
        "print(f' weight precision score of the best model on test set is {test_precision : .4f}')\n",
        "print(f' weight f1 score of the best model on test set is {test_f1 : .4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7BMZrru_Qei",
        "outputId": "e127df76-b3f4-40d5-c38c-4bfbb96a9108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " weight recall score of the best model on test set is  0.9794\n",
            " weight precision score of the best model on test set is  0.9963\n",
            " weight f1 score of the best model on test set is  0.9876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update test score\n",
        "benchmark.iloc[28,-3:] = [test_recall, test_precision, test_f1]"
      ],
      "metadata": {
        "id": "jbz___MeAcKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark.iloc[[0,28]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "u5ZdBt7IBCiq",
        "outputId": "56249668-2325-4191-8a0b-a7d14857e4da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       model_name                                     hyperparameter  \\\n",
              "0   zero_baseline                                            seed=42   \n",
              "28    deep_rescnn  {'weight_decay': 0.01, 'learning_rate': 0.0006...   \n",
              "\n",
              "    best_epoch  best_train_cost  best_val_cost  best_train_recall  \\\n",
              "0            1              NaN            NaN           0.827732   \n",
              "28          71         0.104476       1.420522           0.987573   \n",
              "\n",
              "    best_train_precision  best_train_f1  best_val_recall  best_val_precision  \\\n",
              "0               0.685140       0.749716         0.827722            0.685123   \n",
              "28              0.993976       0.990042         0.980218            0.982213   \n",
              "\n",
              "    best_val_f1 best_test_recall best_test_precision best_test_f1  \n",
              "0      0.749702         0.827608            0.684935     0.749543  \n",
              "28     0.980881         0.979353            0.996322     0.987624  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-258fadb9-3311-40f1-ac48-d7cfe42ba0a0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>hyperparameter</th>\n",
              "      <th>best_epoch</th>\n",
              "      <th>best_train_cost</th>\n",
              "      <th>best_val_cost</th>\n",
              "      <th>best_train_recall</th>\n",
              "      <th>best_train_precision</th>\n",
              "      <th>best_train_f1</th>\n",
              "      <th>best_val_recall</th>\n",
              "      <th>best_val_precision</th>\n",
              "      <th>best_val_f1</th>\n",
              "      <th>best_test_recall</th>\n",
              "      <th>best_test_precision</th>\n",
              "      <th>best_test_f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>zero_baseline</td>\n",
              "      <td>seed=42</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.827732</td>\n",
              "      <td>0.685140</td>\n",
              "      <td>0.749716</td>\n",
              "      <td>0.827722</td>\n",
              "      <td>0.685123</td>\n",
              "      <td>0.749702</td>\n",
              "      <td>0.827608</td>\n",
              "      <td>0.684935</td>\n",
              "      <td>0.749543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>deep_rescnn</td>\n",
              "      <td>{'weight_decay': 0.01, 'learning_rate': 0.0006...</td>\n",
              "      <td>71</td>\n",
              "      <td>0.104476</td>\n",
              "      <td>1.420522</td>\n",
              "      <td>0.987573</td>\n",
              "      <td>0.993976</td>\n",
              "      <td>0.990042</td>\n",
              "      <td>0.980218</td>\n",
              "      <td>0.982213</td>\n",
              "      <td>0.980881</td>\n",
              "      <td>0.979353</td>\n",
              "      <td>0.996322</td>\n",
              "      <td>0.987624</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-258fadb9-3311-40f1-ac48-d7cfe42ba0a0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-258fadb9-3311-40f1-ac48-d7cfe42ba0a0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-258fadb9-3311-40f1-ac48-d7cfe42ba0a0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/99dac6621f6ae8c4/data_table.js\";\n\n      window.createDataTable({\n        data: [[{\n            'v': 0,\n            'f': \"0\",\n        },\n\"zero_baseline\",\n\"seed=42\",\n{\n            'v': 1,\n            'f': \"1\",\n        },\n{\n            'v': NaN,\n            'f': \"NaN\",\n        },\n{\n            'v': NaN,\n            'f': \"NaN\",\n        },\n{\n            'v': 0.8277316683164547,\n            'f': \"0.8277316683164547\",\n        },\n{\n            'v': 0.6851397147339414,\n            'f': \"0.6851397147339414\",\n        },\n{\n            'v': 0.7497158654202581,\n            'f': \"0.7497158654202581\",\n        },\n{\n            'v': 0.8277216866919457,\n            'f': \"0.8277216866919457\",\n        },\n{\n            'v': 0.6851231906201596,\n            'f': \"0.6851231906201596\",\n        },\n{\n            'v': 0.7497018781455581,\n            'f': \"0.7497018781455581\",\n        },\n{\n            'v': 0.8276082587246483,\n            'f': \"0.8276082587246483\",\n        },\n{\n            'v': 0.6849354299092444,\n            'f': \"0.6849354299092444\",\n        },\n{\n            'v': 0.7495429358446977,\n            'f': \"0.7495429358446977\",\n        }],\n [{\n            'v': 28,\n            'f': \"28\",\n        },\n\"deep_rescnn\",\n\"{'weight_decay': 0.01, 'learning_rate': 0.0006333475413534536, 'batch_size': 64}\",\n{\n            'v': 71,\n            'f': \"71\",\n        },\n{\n            'v': 0.10447575792283194,\n            'f': \"0.10447575792283194\",\n        },\n{\n            'v': 1.42052245612251,\n            'f': \"1.42052245612251\",\n        },\n{\n            'v': 0.9875732886621488,\n            'f': \"0.9875732886621488\",\n        },\n{\n            'v': 0.9939755655516386,\n            'f': \"0.9939755655516386\",\n        },\n{\n            'v': 0.9900418781026511,\n            'f': \"0.9900418781026511\",\n        },\n{\n            'v': 0.9802183745260177,\n            'f': \"0.9802183745260177\",\n        },\n{\n            'v': 0.9822134032318967,\n            'f': \"0.9822134032318967\",\n        },\n{\n            'v': 0.9808812996680006,\n            'f': \"0.9808812996680006\",\n        },\n{\n            'v': 0.9793531883793166,\n            'f': \"0.9793531883793166\",\n        },\n{\n            'v': 0.996322382745144,\n            'f': \"0.996322382745144\",\n        },\n{\n            'v': 0.9876244913260027,\n            'f': \"0.9876244913260027\",\n        }]],\n        columns: [[\"number\", \"index\"], [\"string\", \"model_name\"], [\"string\", \"hyperparameter\"], [\"number\", \"best_epoch\"], [\"number\", \"best_train_cost\"], [\"number\", \"best_val_cost\"], [\"number\", \"best_train_recall\"], [\"number\", \"best_train_precision\"], [\"number\", \"best_train_f1\"], [\"number\", \"best_val_recall\"], [\"number\", \"best_val_precision\"], [\"number\", \"best_val_f1\"], [\"number\", \"best_test_recall\"], [\"number\", \"best_test_precision\"], [\"number\", \"best_test_f1\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: \"0\",\n      });\n    "
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clearly, we can see that our best model is surpass the performance compared to the zero baseline. This indicate that our training is success\n",
        "\n"
      ],
      "metadata": {
        "id": "-fwVYQcdBQDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#benchmark.to_csv('/content/drive/MyDrive/arrhythmia_classification/benchmark.csv',index=False)"
      ],
      "metadata": {
        "id": "rgRVBfAaBA4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion matrix"
      ],
      "metadata": {
        "id": "Iwzd2LaQAT7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix plotter\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def cm_plotter(model,loader,set_name = 'train'):\n",
        "\n",
        "    preds_all = []\n",
        "    targets_all = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for data, target in loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            target = torch.argmax(target, dim=1)\n",
        "\n",
        "            output = model(data)\n",
        "            output = F.softmax(output, dim=1)\n",
        "            _, preds = torch.max(output, 1)\n",
        "\n",
        "            # append preds of each batch\n",
        "            preds_all.append(preds)\n",
        "            targets_all.append(target)\n",
        "\n",
        "\n",
        "    preds_all = torch.cat(preds_all, dim=0)\n",
        "    targets_all = torch.cat(targets_all, dim=0)\n",
        "\n",
        "    conf_mat = confusion_matrix(targets_all.data.cpu().numpy(), preds_all.cpu().numpy())\n",
        "    class_total = np.sum(conf_mat, axis=1)\n",
        "    conf_mat_percent = conf_mat / class_total[:, np.newaxis] * 100\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    heatmap = sns.heatmap(conf_mat_percent, annot=True, fmt='.2f',\n",
        "                      xticklabels=['N (0)', 'S (1)', 'V (2)', 'F (3)', 'Q (4)'], \n",
        "                      yticklabels=['N (0)', 'S (1)', 'V (2)', 'F (3)', 'Q (4)'],\n",
        "                      cmap=\"Blues\")\n",
        "    cbar = heatmap.collections[0].colorbar\n",
        "    cbar.set_label('Percentage (%)')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.title(f'Confusion matrix of {set_name} set')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "nzEw9BmcBdsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for set_,loader_ in zip(['train','val','test'],[train_loader,val_loader,test_loader]):\n",
        "    cm_plotter(model,loader_, set_)\n",
        "    print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9Xhh4of9FpIy",
        "outputId": "6b10aa9c-488e-452b-8212-6b65468e739c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall that\n",
        "\n",
        "| Key | Category | Annotations |\n",
        "| --- | --- | --- |\n",
        "| 0 | N | Normal |\n",
        "| 1 | S | Supra-ventricular premature |\n",
        "| 2 | V | Ventricular escape |\n",
        "| 3 | F | Fusion of ventricular and normal |\n",
        "| 4| Q | Unclassifiable |\n",
        "\n",
        "\n",
        "According to the following confusion matrix, it seems like the model is overfitting to the class F (3), sicne the score on the training set is 100% correct, while on both val and test set is not exceed 90. The reason behind this might be the number of samples for this class is extremely low, so the model cannot do well. In future, it is a good idea to increase more data on this class, so we can improve the performance of the model\n",
        "\n",
        "What's also share in the common for val and test set is that\n",
        "1. the model often predicts S as Normal (~10%)\n",
        "1. the model often predicts F as Normal (~5%)\n",
        "1. the model often predicts F as V (~‡∏∏‡∏∏6%) [the pattern of them might be too similar)\n",
        "\n",
        "Hopefully, this confusion matrix can give us the direction of how could we improve in the next phrase."
      ],
      "metadata": {
        "id": "2yG2I0SqHWNj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Demonstration of prediction"
      ],
      "metadata": {
        "id": "3vesejtHKYnS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Demonstrate how the output of each of test set"
      ],
      "metadata": {
        "id": "E8gR4UvZnro4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The range of test set **\n",
        "\n",
        "class 0 (normal): start - 18117\n",
        "\n",
        "Class 1 (supra): 18118 - 18673 \n",
        "\n",
        "Class 2 (ventracular) : 18674 - 20121\n",
        "\n",
        "Class 3 (Fusion + Normal) : 20122 - 20283\n",
        "\n",
        "Class 4 (Fusion + Normal) : 20284 - end"
      ],
      "metadata": {
        "id": "qLqIYtBqnEGY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Demonstrate how to predict the input from each set, and also some random generated input with does not satisfy the shape (1,1,187)"
      ],
      "metadata": {
        "id": "tkU2XtKwD7VA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "map_dct = {0:'normal',\n",
        "           1:'Supra-ventricular premature',\n",
        "           2:'Ventricular escape',\n",
        "           3:'Fusion of ventricular and normal',\n",
        "           4:'unclassifiable'}\n",
        "\n",
        "def predict(model, data, map_dct = map_dct):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(data)\n",
        "        prob = F.softmax(output, dim=1)\n",
        "        pred = torch.argmax(prob, dim=1)\n",
        "        pred = map_dct[pred.item()]\n",
        "        prob = prob.max()\n",
        "\n",
        "    return prob, pred"
      ],
      "metadata": {
        "id": "YK9DBtAFkm83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = 0 #@param {type:\"slider\", min:0, max:2909, step:1}\n",
        "set_ = val_set #@param [\"train_set\", \"val_set\", \"test_set\"] {type:\"raw\"}\n",
        "\n",
        "def predict_on_set(index,set_ = set_, map_dct = map_dct):\n",
        "\n",
        "    data = set_[index]\n",
        "\n",
        "    # X\n",
        "    X = data[0].to(device)\n",
        "\n",
        "    # Y_t\n",
        "    target = data[1].argmax().item()\n",
        "    target = map_dct[target]\n",
        "\n",
        "    plt.plot(X.cpu()[0])\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel(\"Amplitude\")\n",
        "    plt.title(f\"Truth : {target}\")\n",
        "    plt.show()\n",
        "\n",
        "    # Y_pred\n",
        "    prob, pred = predict(model,X.unsqueeze(0))\n",
        "    print(f'predict this as class {pred} with probability {prob}')\n",
        "\n",
        "# Try predict\n",
        "predict_on_set(index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "RS8HZgF5DdqQ",
        "outputId": "e1508769-0de0-42f9-e7aa-010c7b470712"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predict this as class normal with probability 0.9998453855514526\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "B6puIDQIEAyW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we can predict on the generated data which may or may not have the same shape"
      ],
      "metadata": {
        "id": "9aaUAx6o8Jpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(X,fix_seq_len = 187):\n",
        "    \"\"\"\n",
        "    Fill to make the input tensor satisfy with tensor shape (1,1,187) bu padding or truncate (last)\n",
        "    \"\"\"\n",
        "    seq_len = X.shape[2]\n",
        "\n",
        "    if seq_len < fix_seq_len:\n",
        "        diff = fix_seq_len - seq_len\n",
        "        X = torch.nn.functional.pad(X, (0, diff)) #pad the sample\n",
        "\n",
        "    elif seq_len > fix_seq_len:\n",
        "        X = X[:, :, :fix_seq_len] # truncate-last on the sample\n",
        "    \n",
        "    assert X.shape == (1,1,187)\n",
        "    return X"
      ],
      "metadata": {
        "id": "09tZP6Ts79bI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def predict_unknown(data=None):\n",
        "    if data is None:\n",
        "        random_len = random.randrange(1,187)\n",
        "        data = torch.rand(1,1,random_len)\n",
        "\n",
        "    processed_data = preprocess(data)\n",
        "    processed_data = processed_data.to(device)\n",
        "\n",
        "    plt.plot(processed_data.cpu()[0][0],color=\"red\")\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel(\"Amplitude\")\n",
        "    plt.title(f\"Truth : unknown\")\n",
        "    plt.show()\n",
        "\n",
        "    prob, pred = predict(model,processed_data)\n",
        "    print(f'predict this as class {pred} with probability {prob}')"
      ],
      "metadata": {
        "id": "fbj4BPG9-RsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try random\n",
        "# Always expect positive, sine it is unusual to have this fluctuate\n",
        "predict_unknown()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "O5-cnukQ-3qQ",
        "outputId": "0e7faf01-63d3-4080-b471-2d989a7cbd67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predict this as class normal with probability 0.8956060409545898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = test_set[100][0]\n",
        "x = x[:,:100] # random cut the first 100 timestep\n",
        "\n",
        "std = 0.02\n",
        "noise = torch.randn(x.shape) * std\n",
        "noisy_x = x + noise\n",
        "\n",
        "# Try on noisy real data\n",
        "predict_unknown(noisy_x.unsqueeze(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "vEKGGhdZAHsh",
        "outputId": "05bd2f0b-e5c6-4c78-8aef-9bd34bd9889e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predict this as class Supra-ventricular premature with probability 0.9786847233772278\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚è≠ Deployment"
      ],
      "metadata": {
        "id": "kJX8BdKbl1LZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The deployment of the trained model can have significant business impact in the medical field, particularly in the early detection and diagnosis of arrhythmia. By integrating the model into a system that connects with an ECG heartbeat pulse detector, the system can quickly classify ECG signals and provide early alerts for patients who have abnormal heart rhythms.\n",
        "\n",
        "To ensure the accuracy and reliability of the system, it will undergo thorough review and testing by medical professionals before being deployed in a clinical setting. By deploying this system, healthcare providers can potentially reduce the number of patients who suffer from undetected arrhythmia, leading to better health outcomes and potentially saving lives.\n",
        "\n",
        "Furthermore, the model can also potentially reduce healthcare costs by minimizing the need for invasive procedures and hospitalizations, as early detection and treatment can prevent the progression of arrhythmia to more severe conditions. Overall, the deployment of this model has the potential to significantly improve patient outcomes and enhance the efficiency of healthcare delivery."
      ],
      "metadata": {
        "id": "QN7ElgTul4sW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, since we don't have those hardwares, and we may need to test a quick deployment, we can do as the following"
      ],
      "metadata": {
        "id": "198uRTfJKLEe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://i.imgur.com/KggnB1x.png)"
      ],
      "metadata": {
        "id": "2z-8YtOT_8gc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is my proposal for deploying the project in real-life, despite my limitations in obtaining the actual ECG heart signal. Instead, I plan to develop a Flask API server that can receive data from an ECG machine, and then notify the patient's caregiver, doctor, or nurse. Although I won't be able to perform preprocessing in real-time, I will assume that the data has already been preprocessed as outlined in the research paper (with the exception of zero-padding) which involves approximately 7 steps.\n",
        "\n",
        "\n",
        "The Flask API is hosted here : https://ecg-heartbeat-ai.onrender.com\n",
        "\n",
        "The repository which set up the api can be found here : https://github.com/saranpan/ECG-Heartbeat-classifier\n"
      ],
      "metadata": {
        "id": "bQJwwnCw9t21"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 2 ways to obtain the output given the heartbeat signal data: POST and GET.\n",
        "\n",
        "Although POST is more efficient, but for simplicity, I am also going to demonstrate using GET method too"
      ],
      "metadata": {
        "id": "GEXYv_tFHvgD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GET Method"
      ],
      "metadata": {
        "id": "jYXIfUVPHwxD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://github.com/saranpan/ECG-Heartbeat-classifier/raw/main/images/demonstrate_AR.gif?raw=true)"
      ],
      "metadata": {
        "id": "Oq9n8R7sK8Vc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "( Not a typical heartbeat signal due to too short heartbeat sequence, but this is for a simplicity )"
      ],
      "metadata": {
        "id": "eweNu5dBRkab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppose you have a heartbeat signal with length 149 timestep (already preprocessed), you can type like the following pattern : \n",
        "`https://ecg-heartbeat-ai.onrender.com/predict?beat_input=[1,0.9642248749732971,...,0.26575809717178345]`\n",
        "\n",
        "lazy to type ? just go to this [link](https://ecg-heartbeat-ai.onrender.com/predict?beat_input=[1.0,0.9642248749732971,0.7614991664886475,0.4906303286552429,0.2674616575241089,0.13287904858589172,0.061328791081905365,0.047700170427560806,0.030664395540952682,0.03407154977321625,0.05110732465982437,0.0528109036386013,0.0528109036386013,0.05962521210312843,0.063032366335392,0.0528109036386013,0.05621805787086487,0.0528109036386013,0.04429301619529724,0.03577512875199318,0.03747870400547981,0.02214650809764862,0.015332197770476341,0.020442930981516838,0.015332197770476341,0.0,0.003407154930755496,0.013628619723021984,0.013628619723021984,0.011925042606890202,0.027257239446043968,0.030664395540952682,0.04429301619529724,0.047700170427560806,0.06643952429294586,0.07666099071502686,0.09028960764408112,0.10902895778417587,0.12776830792427063,0.13969334959983826,0.14821124076843262,0.17035774886608124,0.17546848952770233,0.1737648993730545,0.19080068171024323,0.19080068171024323,0.18228279054164886,0.17717206478118896,0.19761499762535095,0.18568995594978333,0.18739353120326996,0.19080068171024323,0.19080068171024323,0.1890971064567566,0.19591140747070312,0.20442929863929749,0.20613287389278412,0.20102214813232422,0.20954003930091858,0.20102214813232422,0.20102214813232422,0.19931857287883759,0.20613287389278412,0.20102214813232422,0.20613287389278412,0.20783644914627075,0.2112436145544052,0.20783644914627075,0.20783644914627075,0.20954003930091858,0.2112436145544052,0.20102214813232422,0.20613287389278412,0.21294718980789185,0.2112436145544052,0.20102214813232422,0.20954003930091858,0.20783644914627075,0.20272572338581085,0.20613287389278412,0.22316865622997284,0.21465076506137848,0.20783644914627075,0.20954003930091858,0.21976150572299957,0.20613287389278412,0.2112436145544052,0.21805791556835175,0.21805791556835175,0.20783644914627075,0.21976150572299957,0.21465076506137848,0.21294718980789185,0.20442929863929749,0.2163543403148651,0.21976150572299957,0.22487223148345947,0.22316865622997284,0.23850084841251373,0.24531516432762146,0.24872231483459473,0.24531516432762146,0.2538330554962158,0.24020442366600037,0.23339012265205383,0.2214650809764862,0.21805791556835175,0.20272572338581085,0.20272572338581085,0.19761499762535095,0.18739353120326996,0.1737648993730545,0.18228279054164886,0.1788756400346756,0.1686541736125946,0.17206132411956787,0.1890971064567566,0.19250425696372986,0.20102214813232422,0.20783644914627075,0.21294718980789185,0.20783644914627075,0.21805791556835175,0.22316865622997284,0.2163543403148651,0.21976150572299957,0.22487223148345947,0.21294718980789185,0.18057921528816223,0.14821124076843262,0.1788756400346756,0.2214650809764862,0.25553661584854126,0.34582623839378357,0.4991482198238373,0.48040884733200073,0.36456558108329773,0.2793866991996765,0.24872231483459473,0.24361158907413483,0.24020442366600037,0.2367972731590271,0.2538330554962158,0.24531516432762146,0.25042590498924255,0.252129465341568,0.2589437961578369,0.2538330554962158,0.26575809717178345])\n",
        "\n",
        "\n",
        "When you click this link, you will be redirected to the output which is in form of dictionary like\n",
        "\n",
        "`{\"Class\":\"Ventricular escape\",\"Probability\":0.999957799911499}`"
      ],
      "metadata": {
        "id": "KKdlN2F7-5S1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## POST Method\n",
        "\n",
        "Since it's hard to read due to too long sequence, you can use POST method shown as the following"
      ],
      "metadata": {
        "id": "MhDAxJ6QHML0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# I know it's painful to see this data\n",
        "# This data is one of the data in the test set (which have its label as Ventricular escape)\n",
        "\n",
        "beat_input = [1.0,0.9642248749732971,0.7614991664886475,0.4906303286552429,0.2674616575241089,\n",
        "              0.13287904858589172,0.061328791081905365,0.047700170427560806,0.030664395540952682,\n",
        "              0.03407154977321625,0.05110732465982437,0.0528109036386013,0.0528109036386013,0.05962521210312843,\n",
        "              0.063032366335392,0.0528109036386013,0.05621805787086487,0.0528109036386013,0.04429301619529724,\n",
        "              0.03577512875199318,0.03747870400547981,0.02214650809764862,0.015332197770476341,0.020442930981516838,\n",
        "              0.015332197770476341,0.0,0.003407154930755496,0.013628619723021984,0.013628619723021984,0.011925042606890202,\n",
        "              0.027257239446043968,0.030664395540952682,0.04429301619529724,0.047700170427560806,0.06643952429294586,\n",
        "              0.07666099071502686,0.09028960764408112,0.10902895778417587,0.12776830792427063,0.13969334959983826,\n",
        "              0.14821124076843262,0.17035774886608124,0.17546848952770233,0.1737648993730545,0.19080068171024323,\n",
        "              0.19080068171024323,0.18228279054164886,0.17717206478118896,0.19761499762535095,0.18568995594978333,\n",
        "              0.18739353120326996,0.19080068171024323,0.19080068171024323,0.1890971064567566,0.19591140747070312,\n",
        "              0.20442929863929749,0.20613287389278412,0.20102214813232422,0.20954003930091858,0.20102214813232422,\n",
        "              0.20102214813232422,0.19931857287883759,0.20613287389278412,0.20102214813232422,0.20613287389278412,\n",
        "              0.20783644914627075,0.2112436145544052,0.20783644914627075,0.20783644914627075,0.20954003930091858,\n",
        "              0.2112436145544052,0.20102214813232422,0.20613287389278412,0.21294718980789185,0.2112436145544052,\n",
        "              0.20102214813232422,0.20954003930091858,0.20783644914627075,0.20272572338581085,0.20613287389278412,\n",
        "              0.22316865622997284,0.21465076506137848,0.20783644914627075,0.20954003930091858,0.21976150572299957,\n",
        "              0.20613287389278412,0.2112436145544052,0.21805791556835175,0.21805791556835175,0.20783644914627075,\n",
        "              0.21976150572299957,0.21465076506137848,0.21294718980789185,0.20442929863929749,0.2163543403148651,\n",
        "              0.21976150572299957,0.22487223148345947,0.22316865622997284,0.23850084841251373,0.24531516432762146,\n",
        "              0.24872231483459473,0.24531516432762146,0.2538330554962158,0.24020442366600037,0.23339012265205383,\n",
        "              0.2214650809764862,0.21805791556835175,0.20272572338581085,0.20272572338581085,0.19761499762535095,\n",
        "              0.18739353120326996,0.1737648993730545,0.18228279054164886,0.1788756400346756,0.1686541736125946,\n",
        "              0.17206132411956787,0.1890971064567566,0.19250425696372986,0.20102214813232422,0.20783644914627075,\n",
        "              0.21294718980789185,0.20783644914627075,0.21805791556835175,0.22316865622997284,0.2163543403148651,\n",
        "              0.21976150572299957,0.22487223148345947,0.21294718980789185,0.18057921528816223,0.14821124076843262,\n",
        "              0.1788756400346756,0.2214650809764862,0.25553661584854126,0.34582623839378357,0.4991482198238373,\n",
        "              0.48040884733200073,0.36456558108329773,0.2793866991996765,0.24872231483459473,0.24361158907413483,\n",
        "              0.24020442366600037,0.2367972731590271,0.2538330554962158,0.24531516432762146,0.25042590498924255,\n",
        "              0.252129465341568,0.2589437961578369,0.2538330554962158,0.26575809717178345]"
      ],
      "metadata": {
        "id": "7RcUPdlQGLuk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Demonstrate How to POST using Python\n",
        "import requests\n",
        "\n",
        "# Make sure to turn list into string first [0.1,0.12] -> '[0.1,0.12]'\n",
        "url = 'https://ecg-heartbeat-ai.onrender.com/predict_ar'\n",
        "input_json = {'beat_input': str(beat_input)}\n",
        "\n",
        "x = requests.post(url, json = input_json)\n",
        "print(x.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34UyY58-LOwL",
        "outputId": "4a8721d4-9924-495e-e165-03dba744e9d4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"Class\":\"Ventricular escape\",\"Probability\":0.999957799911499}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "O6D7oN51Tjxr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's it, this is how we can do to obtain the output given heartbeat signal sequence"
      ],
      "metadata": {
        "id": "HAkE8265TkP5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have a real test case for this task, which the data is actually from the test set, you can check out here : https://github.com/saranpan/ECG-Heartbeat-classifier/blob/main/real_test_case_ar.txt, at the end of the data, you will the actual label of that"
      ],
      "metadata": {
        "id": "RWndJo-7B14V"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}